"""
ç»Ÿä¸€SSE (Server-Sent Events) ç®¡ç†æœåŠ¡
æ”¯æŒå¤šé¢‘é“ã€å¤šå®¢æˆ·ç«¯ã€çº¿ç¨‹å®‰å…¨çš„å®æ—¶äº‹ä»¶æ¨é€

ä½¿ç”¨åœºæ™¯ï¼š
1. æ¨¡å‹ä¸‹è½½è¿›åº¦æ¨é€ï¼ˆé¢‘é“ï¼šmodelsï¼‰
2. è½¬å½•ä»»åŠ¡è¿›åº¦æ¨é€ï¼ˆé¢‘é“ï¼šjob:{job_id}ï¼‰
3. è½¬å½•æ–‡å­—æµå¼è¾“å‡ºï¼ˆé¢‘é“ï¼šjob:{job_id}ï¼‰

æ ¸å¿ƒåŸåˆ™ï¼š
- å•é€šé“åŸåˆ™ï¼šæ¯ä¸ªèµ„æºåªå»ºç«‹ä¸€ä¸ªSSEè¿æ¥
- è½»é‡æ¨é€åŸåˆ™ï¼šåªæ¨é€å°æ•°æ®å’Œä¿¡å·ï¼Œå¤§æ•°æ®ç”¨HTTP GET
- é‡è¿å³å…¨é‡ï¼šæ–­çº¿é‡è¿åï¼Œæ¨é€initial_stateï¼Œå®¢æˆ·ç«¯å…¨é‡æ‹‰å–
- çº¿ç¨‹å®‰å…¨ï¼šæ”¯æŒä»åå°çº¿ç¨‹å¹¿æ’­æ¶ˆæ¯åˆ°å¼‚æ­¥äº‹ä»¶å¾ªç¯
"""

import asyncio
import json
import logging
import time
from typing import Dict, List, Optional, Callable
from collections import defaultdict
from fastapi import Request

logger = logging.getLogger(__name__)


class SSEManager:
    """ç»Ÿä¸€SSEè¿æ¥ç®¡ç†å™¨"""

    def __init__(self, heartbeat_interval: int = 10, max_queue_size: int = 1000):
        """
        åˆå§‹åŒ–SSEç®¡ç†å™¨

        Args:
            heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
            max_queue_size: æ¯ä¸ªè¿æ¥çš„æ¶ˆæ¯é˜Ÿåˆ—æœ€å¤§å®¹é‡
        """
        # è¿æ¥æ± ï¼š{channel_id: [queue1, queue2, ...]}
        self.connections: Dict[str, List[asyncio.Queue]] = defaultdict(list)

        # é…ç½®
        self.heartbeat_interval = heartbeat_interval
        self.max_queue_size = max_queue_size

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_connections = 0
        self.total_messages_sent = 0

        # ä¸»äº‹ä»¶å¾ªç¯å¼•ç”¨ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶è®¾ç½®ï¼‰
        self.loop: Optional[asyncio.AbstractEventLoop] = None

        logger.info(f"âœ… SSEç®¡ç†å™¨å·²åˆå§‹åŒ– (å¿ƒè·³: {heartbeat_interval}s, é˜Ÿåˆ—: {max_queue_size})")

    async def subscribe(
        self,
        channel_id: str,
        request: Request,
        initial_state_callback: Optional[Callable] = None
    ):
        """
        è®¢é˜…æŒ‡å®šé¢‘é“çš„SSEäº‹ä»¶æµ

        Args:
            channel_id: é¢‘é“IDï¼ˆå¦‚ "models", "job:abc123"ï¼‰
            request: FastAPIè¯·æ±‚å¯¹è±¡
            initial_state_callback: åˆå§‹çŠ¶æ€å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼Œç”¨äºæ¨é€initial_stateï¼‰

        Yields:
            SSEæ ¼å¼çš„æ¶ˆæ¯å­—ç¬¦ä¸²
        """
        # åˆ›å»ºæ­¤è¿æ¥çš„ä¸“ç”¨é˜Ÿåˆ—
        event_queue = asyncio.Queue(maxsize=self.max_queue_size)
        self.connections[channel_id].append(event_queue)
        self.total_connections += 1

        connection_id = f"{channel_id}#{len(self.connections[channel_id])}"

        try:
            logger.info(f"âœ… SSEè¿æ¥å·²å»ºç«‹: {connection_id} (é¢‘é“: {channel_id}, æ€»è¿æ¥: {self._get_total_active_connections()})")

            # 1. å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
            yield self._format_sse("connected", {
                "channel_id": channel_id,
                "message": "SSEè¿æ¥å·²å»ºç«‹",
                "timestamp": time.time()
            })

            # 2. å‘é€åˆå§‹çŠ¶æ€ï¼ˆå¦‚æœæä¾›äº†å›è°ƒï¼‰
            if initial_state_callback:
                try:
                    initial_state = initial_state_callback()
                    if initial_state:
                        yield self._format_sse("initial_state", initial_state)
                        logger.debug(f"ğŸ“¤ å‘é€åˆå§‹çŠ¶æ€: {connection_id}")
                except Exception as e:
                    logger.error(f"è·å–åˆå§‹çŠ¶æ€å¤±è´¥: {e}")

            # 3. æŒç»­æ¨é€æ¶ˆæ¯
            heartbeat_counter = 0
            while True:
                # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æ–­å¼€
                if await request.is_disconnected():
                    logger.info(f"âš ï¸ å®¢æˆ·ç«¯å·²æ–­å¼€: {connection_id}")
                    break

                try:
                    # ç­‰å¾…æ–°æ¶ˆæ¯ï¼ˆè¶…æ—¶åå‘é€å¿ƒè·³ï¼‰
                    message = await asyncio.wait_for(
                        event_queue.get(),
                        timeout=self.heartbeat_interval
                    )

                    # å‘é€äº‹ä»¶
                    logger.info(f"ğŸ“¨ subscribeå–åˆ°æ¶ˆæ¯ï¼Œå‡†å¤‡yield: {channel_id}/{message['event']}")
                    formatted = self._format_sse(message["event"], message["data"])
                    logger.info(f"ğŸ“¨ yieldæ¶ˆæ¯: {formatted[:100]}...")
                    yield formatted
                    self.total_messages_sent += 1

                except asyncio.TimeoutError:
                    # è¶…æ—¶ï¼Œå‘é€å¿ƒè·³
                    heartbeat_counter += 1
                    yield self._format_sse("ping", {
                        "timestamp": time.time(),
                        "count": heartbeat_counter
                    })

        except asyncio.CancelledError:
            logger.info(f"ğŸ”Œ SSEè¿æ¥è¢«å–æ¶ˆ: {connection_id}")
        except Exception as e:
            logger.error(f"âŒ SSEé”™è¯¯: {connection_id} - {e}")
        finally:
            # æ¸…ç†è¿æ¥
            try:
                self.connections[channel_id].remove(event_queue)
                if not self.connections[channel_id]:
                    del self.connections[channel_id]
                logger.info(f"ğŸ”Œ SSEè¿æ¥å·²æ–­å¼€: {connection_id} (å‰©ä½™è¿æ¥: {self._get_total_active_connections()})")
            except (ValueError, KeyError):
                pass

    async def broadcast(self, channel_id: str, event: str, data: dict):
        """
        å‘æŒ‡å®šé¢‘é“çš„æ‰€æœ‰è®¢é˜…è€…å¹¿æ’­æ¶ˆæ¯ï¼ˆå¼‚æ­¥å®‰å…¨ï¼‰

        Args:
            channel_id: é¢‘é“ID
            event: äº‹ä»¶ç±»å‹ï¼ˆå¦‚ "progress", "fragment", "signal"ï¼‰
            data: äº‹ä»¶æ•°æ®ï¼ˆå­—å…¸ï¼‰
        """
        logger.info(f"ğŸ“¥ broadcastè¢«è°ƒç”¨: {channel_id}/{event}, è¿æ¥æ•°: {len(self.connections.get(channel_id, []))}")

        if channel_id not in self.connections:
            logger.warning(f"é¢‘é“æ— è¿æ¥ï¼Œè·³è¿‡å¹¿æ’­: {channel_id}")
            return

        message = {
            "event": event,
            "data": data
        }

        success_count = 0
        failed_count = 0

        for queue in self.connections[channel_id][:]:  # ä½¿ç”¨åˆ‡ç‰‡é¿å…éå†æ—¶ä¿®æ”¹
            try:
                # æ£€æŸ¥é˜Ÿåˆ—å®¹é‡ï¼Œé¿å…é˜»å¡
                if queue.qsize() >= self.max_queue_size * 0.95:
                    # é˜Ÿåˆ—æ¥è¿‘æ»¡ï¼Œè·³è¿‡æ­¤æ¬¡æ›´æ–°
                    failed_count += 1
                    logger.warning(f"é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æ›´æ–°: {channel_id}")
                    continue

                # éé˜»å¡æ”¾å…¥é˜Ÿåˆ—
                queue.put_nowait(message)
                success_count += 1
                logger.info(f"âœ… æ¶ˆæ¯å·²æ”¾å…¥é˜Ÿåˆ—: {channel_id}/{event}, é˜Ÿåˆ—å¤§å°: {queue.qsize()}")

            except asyncio.QueueFull:
                failed_count += 1
                logger.warning(f"é˜Ÿåˆ—æ»¡ï¼Œæ”¾å…¥å¤±è´¥: {channel_id}")
            except Exception as e:
                failed_count += 1
                logger.error(f"å¹¿æ’­å¤±è´¥: {channel_id} - {e}")

        if success_count > 0:
            logger.info(f"ğŸ“¤ å¹¿æ’­å®Œæˆ: {channel_id} - {event} (æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count})")

    def set_event_loop(self, loop: asyncio.AbstractEventLoop):
        """
        è®¾ç½®ä¸»äº‹ä»¶å¾ªç¯å¼•ç”¨ï¼ˆåœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨ï¼‰

        Args:
            loop: uvicorn/FastAPI çš„ä¸»äº‹ä»¶å¾ªç¯
        """
        self.loop = loop
        logger.info("âœ… SSEç®¡ç†å™¨å·²ç»‘å®šä¸»äº‹ä»¶å¾ªç¯")

    def broadcast_sync(self, channel_id: str, event: str, data: dict):
        """
        ä»åŒæ­¥ä¸Šä¸‹æ–‡ï¼ˆåå°çº¿ç¨‹ï¼‰å¹¿æ’­æ¶ˆæ¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰

        ç”¨äºä»åå°çº¿ç¨‹ï¼ˆå¦‚è½¬å½•ä»»åŠ¡ã€æ¨¡å‹ä¸‹è½½ä»»åŠ¡ï¼‰å‘SSEæ¨é€æ¶ˆæ¯

        Args:
            channel_id: é¢‘é“ID
            event: äº‹ä»¶ç±»å‹
            data: äº‹ä»¶æ•°æ®

        æ³¨æ„ï¼šæ­¤æ–¹æ³•ä¾èµ–äºåœ¨åº”ç”¨å¯åŠ¨æ—¶è®¾ç½®çš„ä¸»äº‹ä»¶å¾ªç¯
        """
        # ä¼˜å…ˆä½¿ç”¨é¢„å…ˆä¿å­˜çš„ä¸»äº‹ä»¶å¾ªç¯
        loop = self.loop

        if loop is None:
            logger.warning(f"SSEä¸»äº‹ä»¶å¾ªç¯æœªè®¾ç½®ï¼Œè·³è¿‡æ¨é€: {channel_id}/{event}")
            # å›é€€ï¼šå°è¯•è·å–äº‹ä»¶å¾ªç¯ï¼ˆå¯èƒ½ä¸å¯é ï¼‰
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_closed():
                        logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œæ— æ³•æ¨é€SSEæ¶ˆæ¯")
                        return
                except Exception:
                    logger.warning("æ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œè·³è¿‡SSEæ¨é€")
                    return

        if loop is None or loop.is_closed():
            logger.warning("äº‹ä»¶å¾ªç¯ä¸å¯ç”¨ï¼Œè·³è¿‡SSEæ¨é€")
            return

        # æ£€æŸ¥é¢‘é“æ˜¯å¦æœ‰è¿æ¥
        if channel_id not in self.connections or not self.connections[channel_id]:
            logger.info(f"é¢‘é“æ— æ´»è·ƒè¿æ¥ï¼Œè·³è¿‡æ¨é€: {channel_id}")
            return

        # ä½¿ç”¨ run_coroutine_threadsafe ä»åå°çº¿ç¨‹å®‰å…¨åœ°è°ƒåº¦åç¨‹
        try:
            future = asyncio.run_coroutine_threadsafe(
                self.broadcast(channel_id, event, data),
                loop
            )
            # è®°å½•æˆåŠŸè°ƒåº¦
            logger.info(f"ğŸ“¤ SSEæ¶ˆæ¯å·²è°ƒåº¦: {channel_id}/{event}")
        except Exception as e:
            logger.warning(f"SSEæ¨é€è°ƒåº¦å¤±è´¥: {e}")

    def _format_sse(self, event: str, data: dict) -> str:
        """
        æ ¼å¼åŒ–ä¸ºæ ‡å‡†SSEæ¶ˆæ¯æ ¼å¼

        Args:
            event: äº‹ä»¶åç§°
            data: æ•°æ®å­—å…¸

        Returns:
            SSEæ ¼å¼å­—ç¬¦ä¸²: "event: xxx\ndata: {...}\n\n"
        """
        json_data = json.dumps(data, ensure_ascii=False)
        return f"event: {event}\ndata: {json_data}\n\n"

    def _get_total_active_connections(self) -> int:
        """è·å–å½“å‰æ´»è·ƒè¿æ¥æ€»æ•°"""
        return sum(len(queues) for queues in self.connections.values())

    def get_channel_stats(self, channel_id: str) -> Dict:
        """
        è·å–æŒ‡å®šé¢‘é“çš„ç»Ÿè®¡ä¿¡æ¯

        Args:
            channel_id: é¢‘é“ID

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if channel_id not in self.connections:
            return {
                "channel_id": channel_id,
                "active_connections": 0,
                "exists": False
            }

        queues = self.connections[channel_id]
        return {
            "channel_id": channel_id,
            "active_connections": len(queues),
            "queue_sizes": [q.qsize() for q in queues],
            "exists": True
        }

    def get_global_stats(self) -> Dict:
        """
        è·å–å…¨å±€ç»Ÿè®¡ä¿¡æ¯

        Returns:
            å…¨å±€ç»Ÿè®¡å­—å…¸
        """
        return {
            "total_channels": len(self.connections),
            "total_connections": self._get_total_active_connections(),
            "total_messages_sent": self.total_messages_sent,
            "channels": list(self.connections.keys())
        }


# ========== å•ä¾‹æ¨¡å¼ ==========

_sse_manager_instance: Optional[SSEManager] = None


def get_sse_manager() -> SSEManager:
    """
    è·å–SSEç®¡ç†å™¨å•ä¾‹

    Returns:
        SSEManager: SSEç®¡ç†å™¨å®ä¾‹
    """
    global _sse_manager_instance
    if _sse_manager_instance is None:
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°ï¼ˆå¦‚æœéœ€è¦ï¼‰
        from core.config import config
        heartbeat_interval = getattr(config, 'SSE_HEARTBEAT_INTERVAL', 10)
        max_queue_size = getattr(config, 'SSE_MAX_QUEUE_SIZE', 1000)

        _sse_manager_instance = SSEManager(
            heartbeat_interval=heartbeat_interval,
            max_queue_size=max_queue_size
        )
    return _sse_manager_instance
