"""
è½¬å½•å¤„ç†æœåŠ¡
æ•´åˆäº†processor.pyå’ŒåŸtranscription_service.pyçš„æ‰€æœ‰åŠŸèƒ½
"""
import os, subprocess, uuid, threading, json, math, gc, logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from enum import Enum
from dataclasses import dataclass, field
from collections import OrderedDict  # æ–°å¢å¯¼å…¥
from pydub import AudioSegment, silence
from app.services.whisper_service import get_whisper_service, load_audio as whisper_load_audio
from app.services.config_adapter import ConfigAdapter
# ä»æ–°æ¶æ„å¯¼å…¥ VAD é…ç½®ï¼ˆ2025-12-17 ç»Ÿä¸€é…ç½®å®šä¹‰ï¼‰
from app.services.audio.vad_service import VADConfig, VADMethod, get_vad_service
from app.services.audio.chunk_engine import ChunkEngine, AudioChunk
import torch
import shutil
import psutil
import numpy as np


class ProcessingMode(Enum):
    """
    å¤„ç†æ¨¡å¼æšä¸¾
    ç”¨äºæ™ºèƒ½å†³ç­–ä½¿ç”¨å†…å­˜æ¨¡å¼è¿˜æ˜¯ç¡¬ç›˜æ¨¡å¼è¿›è¡ŒéŸ³é¢‘å¤„ç†

    æ³¨æ„ï¼šDISK æ¨¡å¼ï¼ˆç¡¬ç›˜åˆ†æ®µï¼‰å·²åºŸå¼ƒï¼Œä»…ä¿ç•™ MEMORY æ¨¡å¼
    """
    MEMORY = "memory"  # å†…å­˜æ¨¡å¼ï¼ˆé»˜è®¤ï¼Œé«˜æ€§èƒ½ï¼‰
    DISK = "disk"      # ç¡¬ç›˜æ¨¡å¼ï¼ˆå·²åºŸå¼ƒï¼Œä»…ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼‰


class BreakToGlobalSeparation(Exception):
    """ç†”æ–­å¼‚å¸¸ï¼šè§¦å‘æ—¶éœ€è¦å‡çº§ä¸ºå…¨å±€äººå£°åˆ†ç¦»æ¨¡å¼"""
    pass


@dataclass
class CircuitBreakerState:
    """
    ç†”æ–­å™¨çŠ¶æ€ï¼ˆæ”¯æŒæ¨¡å‹å‡çº§ï¼‰

    ç”¨äºç›‘æ§è½¬å½•è´¨é‡ï¼Œå½“å¤§é‡æ®µè½éœ€è¦é‡è¯•æ—¶ï¼š
    1. ä¼˜å…ˆå°è¯•å‡çº§æ¨¡å‹ï¼ˆå¦‚æœå…è®¸ä¸”æœªè¾¾ä¸Šé™ï¼‰
    2. æ— æ³•å‡çº§æ—¶æ‰è§¦å‘ç†”æ–­
    """
    consecutive_retries: int = 0        # è¿ç»­é‡è¯•è®¡æ•°
    total_retries: int = 0              # æ€»é‡è¯•æ¬¡æ•°
    total_segments: int = 0             # æ€»æ®µè½æ•°
    processed_segments: int = 0         # å·²å¤„ç†æ®µè½æ•°

    # === Phase 3: å‡çº§è·Ÿè¸ª ===
    escalation_count: int = 0                           # å·²å‡çº§æ¬¡æ•°
    current_model: Optional[str] = None                 # å½“å‰ä½¿ç”¨çš„æ¨¡å‹
    escalation_history: List[str] = field(default_factory=list)  # å‡çº§å†å²

    def record_retry(self):
        """è®°å½•ä¸€æ¬¡é‡è¯•"""
        self.consecutive_retries += 1
        self.total_retries += 1

    def record_success(self):
        """è®°å½•ä¸€æ¬¡æˆåŠŸï¼ˆé‡ç½®è¿ç»­è®¡æ•°ï¼‰"""
        self.consecutive_retries = 0
        self.processed_segments += 1

    def record_escalation(self, new_model: str):
        """
        è®°å½•ä¸€æ¬¡æ¨¡å‹å‡çº§

        Args:
            new_model: å‡çº§åçš„æ¨¡å‹åç§°
        """
        if self.current_model:
            self.escalation_history.append(f"{self.current_model} -> {new_model}")
        self.current_model = new_model
        self.escalation_count += 1
        # å‡çº§åé‡ç½®è¿ç»­é‡è¯•è®¡æ•°ï¼Œç»™æ–°æ¨¡å‹æœºä¼š
        self.consecutive_retries = 0

    def should_escalate(self, demucs_settings) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å‡çº§æ¨¡å‹ï¼ˆä¼˜å…ˆäºç†”æ–­ï¼‰

        å‡çº§æ¡ä»¶ï¼š
        1. å…è®¸è‡ªåŠ¨å‡çº§ (auto_escalation=True)
        2. æœªè¾¾åˆ°æœ€å¤§å‡çº§æ¬¡æ•°
        3. æ»¡è¶³ç†”æ–­æ¡ä»¶ï¼ˆè¿ç»­é‡è¯•æˆ–æ¯”ä¾‹è¿‡é«˜ï¼‰

        Args:
            demucs_settings: Demucsé…ç½®å¯¹è±¡

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥å‡çº§æ¨¡å‹
        """
        if not demucs_settings.auto_escalation:
            return False

        if self.escalation_count >= demucs_settings.max_escalations:
            return False

        # æ»¡è¶³ç†”æ–­æ¡ä»¶æ—¶ï¼Œä¼˜å…ˆå‡çº§
        return self._check_break_condition(demucs_settings)

    def should_break(self, demucs_settings) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘ç†”æ–­

        æ³¨æ„ï¼šåªæœ‰åœ¨æ— æ³•å‡çº§æ—¶æ‰è§¦å‘ç†”æ–­

        Args:
            demucs_settings: Demucsé…ç½®å¯¹è±¡

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥è§¦å‘ç†”æ–­
        """
        if not demucs_settings.circuit_breaker_enabled:
            return False

        # å¦‚æœè¿˜èƒ½å‡çº§ï¼Œä¸è§¦å‘ç†”æ–­
        if self.should_escalate(demucs_settings):
            return False

        return self._check_break_condition(demucs_settings)

    def _check_break_condition(self, demucs_settings) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ»¡è¶³ç†”æ–­/å‡çº§æ¡ä»¶

        ç†”æ–­æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³è§¦å‘ï¼‰ï¼š
        1. è¿ç»­ N ä¸ª segment éƒ½è§¦å‘é‡è¯•ï¼ˆé»˜è®¤N=3ï¼‰
        2. æ€»é‡è¯•æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼ï¼ˆé»˜è®¤20%ï¼‰

        Args:
            demucs_settings: Demucsé…ç½®å¯¹è±¡

        Returns:
            bool: Trueè¡¨ç¤ºæ»¡è¶³ç†”æ–­/å‡çº§æ¡ä»¶
        """
        # æ¡ä»¶1ï¼šè¿ç»­é‡è¯•æ¬¡æ•°
        if self.consecutive_retries >= demucs_settings.consecutive_threshold:
            return True

        # æ¡ä»¶2ï¼šæ€»é‡è¯•æ¯”ä¾‹ï¼ˆè‡³å°‘å¤„ç†5ä¸ªsegmentåæ‰æ£€æŸ¥ï¼‰
        if self.processed_segments >= 5:
            retry_ratio = self.total_retries / self.processed_segments
            if retry_ratio >= demucs_settings.ratio_threshold:
                return True

        return False

    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ‰©å±•ï¼‰"""
        return {
            "consecutive_retries": self.consecutive_retries,
            "total_retries": self.total_retries,
            "total_segments": self.total_segments,
            "processed_segments": self.processed_segments,
            "retry_ratio": self.total_retries / max(1, self.processed_segments),
            # Phase 3 æ–°å¢
            "escalation_count": self.escalation_count,
            "current_model": self.current_model,
            "escalation_history": self.escalation_history,
        }


class CircuitBreakAction(Enum):
    """ç†”æ–­åçš„å¤„ç†åŠ¨ä½œ"""
    CONTINUE = "continue"           # ç»§ç»­å¤„ç†ï¼Œæ ‡è®°é—®é¢˜æ®µè½
    FALLBACK_ORIGINAL = "fallback"  # é™çº§ä½¿ç”¨åŸå§‹éŸ³é¢‘
    FAIL = "fail"                   # ä»»åŠ¡å¤±è´¥
    PAUSE = "pause"                 # æš‚åœç­‰å¾…äººå·¥ä»‹å…¥


class CircuitBreakHandler:
    """
    ç†”æ–­å¼‚å¸¸å¤„ç†å™¨

    è´Ÿè´£åœ¨ç†”æ–­è§¦å‘æ—¶æ‰§è¡Œç”¨æˆ·é…ç½®çš„å¤„ç†ç­–ç•¥
    """

    def __init__(self, job: "JobState", settings):
        """
        åˆå§‹åŒ–ç†”æ–­å¤„ç†å™¨

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            settings: DemucsSettings é…ç½®å¯¹è±¡
        """
        self.job = job
        self.settings = settings
        self.logger = logging.getLogger(__name__)
        self.problem_segments: List[int] = []  # è®°å½•é—®é¢˜æ®µè½ç´¢å¼•

    def handle(
        self,
        breaker_state: CircuitBreakerState,
        current_segment_idx: int,
        sse_manager = None
    ) -> CircuitBreakAction:
        """
        å¤„ç†ç†”æ–­å¼‚å¸¸

        Args:
            breaker_state: ç†”æ–­å™¨çŠ¶æ€
            current_segment_idx: å½“å‰æ®µè½ç´¢å¼•
            sse_manager: SSEç®¡ç†å™¨ï¼ˆç”¨äºæ¨é€äº‹ä»¶ï¼‰

        Returns:
            CircuitBreakAction: å¤„ç†åŠ¨ä½œ
        """
        action_str = self.settings.on_break

        # è§£æå¤„ç†åŠ¨ä½œ
        try:
            action = CircuitBreakAction(action_str)
        except ValueError:
            # å¦‚æœé…ç½®å€¼æ— æ•ˆï¼Œé»˜è®¤ä½¿ç”¨ CONTINUE
            self.logger.warning(f"æ— æ•ˆçš„ç†”æ–­å¤„ç†ç­–ç•¥: {action_str}ï¼Œä½¿ç”¨é»˜è®¤å€¼ continue")
            action = CircuitBreakAction.CONTINUE

        # è®°å½•é—®é¢˜æ®µè½
        self.problem_segments.append(current_segment_idx)

        # æ¨é€ SSE äº‹ä»¶
        if sse_manager:
            self._push_circuit_break_event(breaker_state, action, sse_manager)

        # æ ¹æ®ç­–ç•¥æ‰§è¡Œæ“ä½œ
        if action == CircuitBreakAction.FAIL:
            self.logger.error(
                f"ç†”æ–­è§¦å‘ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚é—®é¢˜æ®µè½: {self.problem_segments}"
            )
            raise BreakToGlobalSeparation(
                f"ç†”æ–­è§¦å‘ï¼Œä»»åŠ¡ç»ˆæ­¢ã€‚é—®é¢˜æ®µè½: {self.problem_segments}"
            )

        elif action == CircuitBreakAction.PAUSE:
            self.logger.warning(
                f"ç†”æ–­è§¦å‘ï¼Œç­‰å¾…äººå·¥ä»‹å…¥ã€‚é—®é¢˜æ®µè½: {self.problem_segments}"
            )
            self.job.paused = True
            self.job.status = "paused"
            self.job.message = f"ç†”æ–­è§¦å‘ï¼Œç­‰å¾…äººå·¥ä»‹å…¥ã€‚é—®é¢˜æ®µè½: {self.problem_segments}"
            raise BreakToGlobalSeparation(self.job.message)

        else:  # CONTINUE æˆ– FALLBACK_ORIGINAL
            self.logger.warning(
                f"ç†”æ–­è§¦å‘ï¼Œé‡‡ç”¨ {action.value} ç­–ç•¥ç»§ç»­å¤„ç†ã€‚"
                f"é—®é¢˜æ®µè½: {self.problem_segments}"
            )

        return action

    def get_problem_report(self) -> Dict:
        """
        è·å–é—®é¢˜æŠ¥å‘Š

        Returns:
            åŒ…å«é—®é¢˜ç»Ÿè®¡å’Œå»ºè®®çš„å­—å…¸
        """
        return {
            "total_problem_segments": len(self.problem_segments),
            "problem_indices": self.problem_segments,
            "suggestion": self._get_suggestion()
        }

    def _get_suggestion(self) -> str:
        """
        æ ¹æ®é—®é¢˜æ®µè½æ•°é‡ç»™å‡ºå»ºè®®

        Returns:
            å»ºè®®æ–‡æœ¬
        """
        count = len(self.problem_segments)
        if count == 0:
            return "æ‰€æœ‰æ®µè½å¤„ç†æ­£å¸¸"
        elif count <= 3:
            return "å°‘é‡æ®µè½å¯èƒ½éœ€è¦æ‰‹åŠ¨è°ƒæ•´æ—¶é—´è½´"
        elif count <= 10:
            return "å»ºè®®æ£€æŸ¥è¿™äº›æ®µè½çš„å­—å¹•å‡†ç¡®æ€§"
        else:
            return "å¤§é‡æ®µè½æœ‰é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨æ›´é«˜è´¨é‡çš„æ¨¡å‹é‡æ–°å¤„ç†"

    def _push_circuit_break_event(
        self,
        state: CircuitBreakerState,
        action: CircuitBreakAction,
        sse_manager
    ):
        """
        æ¨é€ç†”æ–­å¤„ç†äº‹ä»¶

        Args:
            state: ç†”æ–­å™¨çŠ¶æ€
            action: å¤„ç†åŠ¨ä½œ
            sse_manager: SSEç®¡ç†å™¨
        """
        try:
            sse_manager.push_event(
                self.job.job_id,
                "circuit_breaker_handled",
                {
                    "action": action.value,
                    "problem_segments": self.problem_segments,
                    "stats": state.get_stats(),
                    "suggestion": self._get_suggestion()
                }
            )
        except Exception as e:
            self.logger.debug(f"SSEæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")


from app.models.job_models import JobSettings, JobState
from app.models.hardware_models import HardwareInfo, OptimizationConfig
from app.services.hardware_service import get_hardware_detector, get_hardware_optimizer
from app.services.cpu_affinity_service import CPUAffinityManager, CPUAffinityConfig
from app.services.job_index_service import get_job_index_service
from app.core.config import config  # å¯¼å…¥ç»Ÿä¸€é…ç½®

# å…¨å±€æ¨¡å‹ç¼“å­˜ (æŒ‰ (model, compute_type, device) é”®)
_model_cache: Dict[Tuple[str, str, str], object] = {}


_model_lock = threading.Lock()


class TranscriptionService:
    """
    è½¬å½•å¤„ç†æœåŠ¡
    æ•´åˆäº†æ‰€æœ‰è½¬å½•ç›¸å…³åŠŸèƒ½
    """

    def __init__(self, jobs_root: str):
        """
        åˆå§‹åŒ–è½¬å½•æœåŠ¡

        Args:
            jobs_root: ä»»åŠ¡å·¥ä½œç›®å½•æ ¹è·¯å¾„
        """
        self.jobs_root = Path(jobs_root)
        self.jobs_root.mkdir(parents=True, exist_ok=True)

        self.jobs: Dict[str, JobState] = {}
        self.lock = threading.Lock()
        self.logger = logging.getLogger(__name__)

        # é›†æˆCPUäº²å’Œæ€§ç®¡ç†å™¨
        self.cpu_manager = CPUAffinityManager()

        # é›†æˆç¡¬ä»¶æ£€æµ‹
        self.hardware_detector = get_hardware_detector()
        self.hardware_optimizer = get_hardware_optimizer()
        self._hardware_info: Optional[HardwareInfo] = None
        self._optimization_config: Optional[OptimizationConfig] = None

        # é›†æˆä»»åŠ¡ç´¢å¼•æœåŠ¡
        self.job_index = get_job_index_service(jobs_root)
        # å¯åŠ¨æ—¶æ¸…ç†æ— æ•ˆæ˜ å°„
        self.job_index.cleanup_invalid_mappings()

        # é›†æˆSSEç®¡ç†å™¨ï¼ˆç”¨äºå®æ—¶è¿›åº¦æ¨é€ï¼‰
        from app.services.sse_service import get_sse_manager
        self.sse_manager = get_sse_manager()
        self.logger.info("SSEç®¡ç†å™¨å·²é›†æˆ")

        # åˆå§‹åŒ–æ–°æ¶æ„ Pipelineï¼ˆ2025-12-17 æ¶æ„æ”¹é€ ï¼‰
        from app.pipelines.audio_processing_pipeline import AudioProcessingPipeline
        from app.pipelines.async_dual_pipeline import AsyncDualPipeline

        self.audio_pipeline = None  # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç­‰ç¡¬ä»¶æ£€æµ‹å®Œæˆ
        self.transcription_pipeline = None  # å»¶è¿Ÿåˆå§‹åŒ–ï¼Œç­‰ç¡¬ä»¶æ£€æµ‹å®Œæˆ
        self.logger.info("Pipeline æ¶æ„å·²å‡†å¤‡")

        # è®°å½•CPUä¿¡æ¯
        sys_info = self.cpu_manager.get_system_info()
        if sys_info.get('supported', False):
            self.logger.info(
                f" CPUä¿¡æ¯: {sys_info['logical_cores']}ä¸ªé€»è¾‘æ ¸å¿ƒ, "
                f"{sys_info.get('physical_cores', '?')}ä¸ªç‰©ç†æ ¸å¿ƒ, "
                f"å¹³å°: {sys_info.get('platform', '?')}"
            )
        else:
            self.logger.warning("CPUäº²å’Œæ€§åŠŸèƒ½ä¸å¯ç”¨")

        # æ‰§è¡Œç¡¬ä»¶æ£€æµ‹
        self._detect_hardware()

        # å¯åŠ¨æ—¶æ‰«æå¹¶åŠ è½½æ‰€æœ‰ä»»åŠ¡ï¼ˆä¿®å¤é‡å¯åæ— æ³•æ‰“å¼€æ—§ä»»åŠ¡çš„é—®é¢˜ï¼‰
        self._load_all_jobs_from_disk()

    def _detect_hardware(self):
        """æ‰§è¡Œç¡¬ä»¶æ£€æµ‹å¹¶ç”Ÿæˆä¼˜åŒ–é…ç½®"""
        try:
            self.logger.info("å¼€å§‹ç¡¬ä»¶æ£€æµ‹...")
            self._hardware_info = self.hardware_detector.detect()
            self._optimization_config = self.hardware_optimizer.get_optimization_config(self._hardware_info)

            # è®°å½•æ£€æµ‹ç»“æœ
            hw = self._hardware_info
            opt = self._optimization_config
            self.logger.info(f"ç¡¬ä»¶æ£€æµ‹å®ŒæˆGPU: {'' if hw.cuda_available else ''}, "
                           f"CPU: {hw.cpu_cores}æ ¸/{hw.cpu_threads}çº¿ç¨‹, "
                           f"å†…å­˜: {hw.memory_total_mb}MB, "
                           f"ä¼˜åŒ–é…ç½®: batch={opt.batch_size}, device={opt.recommended_device}")

            # ç¡¬ä»¶æ£€æµ‹å®Œæˆåï¼Œåˆå§‹åŒ– Pipeline
            self._initialize_pipelines()
        except Exception as e:
            self.logger.error(f"ç¡¬ä»¶æ£€æµ‹å¤±è´¥: {e}")

    def _initialize_pipelines(self):
        """
        åˆå§‹åŒ–æ–°æ¶æ„ Pipelineï¼ˆ2025-12-17 æ¶æ„æ”¹é€ ï¼‰

        èŒè´£ï¼šç»„è£… - æ ¹æ®ç¡¬ä»¶é…ç½®åˆå§‹åŒ– AudioProcessingPipeline å’Œ AsyncDualPipeline
        """
        try:
            from app.pipelines.audio_processing_pipeline import (
                AudioProcessingPipeline,
                AudioProcessingConfig
            )
            from app.pipelines.async_dual_pipeline import AsyncDualPipeline

            # åˆå§‹åŒ–éŸ³é¢‘å¤„ç†æµæ°´çº¿
            audio_config = AudioProcessingConfig(
                vad_config=VADConfig(),  # ä½¿ç”¨é»˜è®¤ VAD é…ç½®
                enable_demucs=True,
                auto_strategy=True
            )
            self.audio_pipeline = AudioProcessingPipeline(
                config=audio_config,
                logger=self.logger
            )

            # åˆå§‹åŒ–è½¬å½•æµæ°´çº¿
            self.transcription_pipeline = AsyncDualPipeline(
                job_id="",  # æ¯æ¬¡å¤„ç†æ—¶åŠ¨æ€è®¾ç½®
                sse_manager=self.sse_manager,
                logger=self.logger
            )

            self.logger.info("Pipeline åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"Pipeline åˆå§‹åŒ–å¤±è´¥: {e}")
            self.audio_pipeline = None
            self.transcription_pipeline = None

    async def _run_pipeline_v2(self, job: JobState):
        """
        æ–°æ¶æ„ Pipeline å…¥å£æ–¹æ³•ï¼ˆ2025-12-17 æ¶æ„æ”¹é€ ï¼‰

        èŒè´£ï¼š
        1. è§¦å‘ï¼šæ¥æ”¶ä»»åŠ¡ï¼Œä¼ ç»™ Pipeline
        2. æ”¶å°¾ï¼šæ‹¿åˆ°ç»“æœï¼Œç”Ÿæˆ SRT æ–‡ä»¶

        æ³¨æ„ï¼šæ­¤æ–¹æ³•æ˜¯ç®€åŒ–ç‰ˆï¼Œæš‚ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€ä»»åŠ¡çŠ¶æ€ç®¡ç†ç­‰å¤æ‚åŠŸèƒ½
        è¿™äº›åŠŸèƒ½å°†åœ¨åç»­é˜¶æ®µé€æ­¥é›†æˆ

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        try:
            # æ£€æŸ¥ Pipeline æ˜¯å¦åˆå§‹åŒ–
            if not self.audio_pipeline or not self.transcription_pipeline:
                raise RuntimeError("Pipeline æœªåˆå§‹åŒ–")

            job_dir = Path(job.dir)
            input_path = job_dir / job.filename

            # ==========================================
            # é˜¶æ®µ 1: éŸ³é¢‘å‰å¤„ç†ï¼ˆAudioProcessingPipelineï¼‰
            # ==========================================
            self._update_progress(job, 'audio_processing', 0, 'éŸ³é¢‘å¤„ç†ä¸­...')

            # è°ƒç”¨éŸ³é¢‘å¤„ç†æµæ°´çº¿
            audio_result = await self.audio_pipeline.process(
                video_path=str(input_path),
                progress_callback=lambda p: self._update_progress(
                    job, 'audio_processing', p, f'éŸ³é¢‘å¤„ç†ä¸­ {int(p*100)}%'
                )
            )

            chunks = audio_result.chunks
            job.total = len(chunks)
            self.logger.info(f"éŸ³é¢‘å¤„ç†å®Œæˆ: {len(chunks)} ä¸ª Chunk")

            # ==========================================
            # é˜¶æ®µ 2: å¼‚æ­¥åŒæµè½¬å½•ï¼ˆAsyncDualPipelineï¼‰
            # ==========================================
            self._update_progress(job, 'transcription', 0, 'è½¬å½•ä¸­...')

            # æ›´æ–° Pipeline çš„ job_id
            self.transcription_pipeline.job_id = job.job_id

            # è°ƒç”¨è½¬å½•æµæ°´çº¿
            final_sentences = await self.transcription_pipeline.run(
                chunks=chunks,
                job_settings=job.settings
            )

            self.logger.info(f"è½¬å½•å®Œæˆ: {len(final_sentences)} ä¸ªå¥å­")

            # ==========================================
            # é˜¶æ®µ 3: ç”Ÿæˆ SRT æ–‡ä»¶ï¼ˆæ”¶å°¾ï¼‰
            # ==========================================
            self._update_progress(job, 'finalize', 0, 'ç”Ÿæˆå­—å¹•æ–‡ä»¶...')

            srt_path = job_dir / f"{Path(job.filename).stem}.srt"
            self._generate_srt_from_sentences(final_sentences, srt_path)

            job.srt_path = str(srt_path)
            job.status = 'completed'
            job.message = 'è½¬å½•å®Œæˆ'
            job.progress = 100

            self.logger.info(f"ä»»åŠ¡å®Œæˆ: {job.job_id}")

        except Exception as e:
            self.logger.error(f"Pipeline æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            job.status = 'failed'
            job.error = str(e)
            job.message = f'å¤±è´¥: {str(e)}'
            raise

    def _generate_srt_from_sentences(self, sentences: List, output_path: Path):
        """
        ä»å¥å­åˆ—è¡¨ç”Ÿæˆ SRT æ–‡ä»¶

        Args:
            sentences: å¥å­åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
        """
        srt_content = []

        for i, sentence in enumerate(sentences, 1):
            start = self._format_srt_timestamp(sentence.start)
            end = self._format_srt_timestamp(sentence.end)
            text = sentence.text

            srt_content.append(f"{i}\n{start} --> {end}\n{text}\n")

        output_path.write_text('\n'.join(srt_content), encoding='utf-8')
        self.logger.info(f"SRT æ–‡ä»¶å·²ç”Ÿæˆ: {output_path}")

    def _format_srt_timestamp(self, seconds: float) -> str:
        """
        æ ¼å¼åŒ– SRT æ—¶é—´æˆ³

        Args:
            seconds: ç§’æ•°

        Returns:
            SRT æ ¼å¼æ—¶é—´æˆ³ (HH:MM:SS,mmm)
        """
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)

        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def _load_all_jobs_from_disk(self):
        """
        å¯åŠ¨æ—¶æ‰«æå¹¶åŠ è½½æ‰€æœ‰ä»»åŠ¡åˆ°å†…å­˜ï¼ˆä¿®å¤é‡å¯åæ— æ³•æ‰“å¼€æ—§ä»»åŠ¡çš„é—®é¢˜ï¼‰

        è¿™ä¸ªæ–¹æ³•ä¼šæ‰«æ jobs ç›®å½•ä¸­çš„æ‰€æœ‰ä»»åŠ¡ï¼Œå¹¶åŠ è½½åˆ°å†…å­˜ä¸­ï¼Œ
        é¿å…é‡å¯åå› ä¸ºå†…å­˜ä¸ºç©ºå¯¼è‡´æ— æ³•è®¿é—®æ—§ä»»åŠ¡
        """
        try:
            loaded_count = 0
            for job_dir in self.jobs_root.iterdir():
                if not job_dir.is_dir():
                    continue

                job_id = job_dir.name
                if job_id in self.jobs:
                    # å·²åŠ è½½ï¼Œè·³è¿‡
                    continue

                # å°è¯•åŠ è½½ä»»åŠ¡
                job = self.get_job(job_id)
                if job:
                    loaded_count += 1

            if loaded_count > 0:
                self.logger.info(f"å¯åŠ¨æ—¶å·²åŠ è½½ {loaded_count} ä¸ªå†å²ä»»åŠ¡åˆ°å†…å­˜")
        except Exception as e:
            self.logger.error(f"åŠ è½½å†å²ä»»åŠ¡å¤±è´¥: {e}")
    
    def get_hardware_info(self) -> Optional[HardwareInfo]:
        """è·å–ç¡¬ä»¶ä¿¡æ¯"""
        return self._hardware_info
    
    def get_optimization_config(self) -> Optional[OptimizationConfig]:
        """è·å–ä¼˜åŒ–é…ç½®"""  
        return self._optimization_config
    
    def get_optimized_job_settings(self, base_settings: Optional[JobSettings] = None) -> JobSettings:
        """è·å–åŸºäºç¡¬ä»¶ä¼˜åŒ–çš„ä»»åŠ¡è®¾ç½®"""
        # ä½¿ç”¨ç¡¬ä»¶ä¼˜åŒ–é…ç½®ä½œä¸ºé»˜è®¤å€¼
        if self._optimization_config:
            optimized = JobSettings(
                model=base_settings.model if base_settings else "medium",
                compute_type=base_settings.compute_type if base_settings else "float16",
                device=self._optimization_config.recommended_device,
                batch_size=self._optimization_config.batch_size,
                word_timestamps=base_settings.word_timestamps if base_settings else False
            )
            return optimized
        
        # å¦‚æœæ²¡æœ‰ç¡¬ä»¶ä¿¡æ¯ï¼Œä½¿ç”¨ä¼ å…¥çš„è®¾ç½®æˆ–é»˜è®¤è®¾ç½®
        return base_settings or JobSettings()

    def create_job(
        self,
        filename: str,
        src_path: str,
        settings: JobSettings,
        job_id: Optional[str] = None
    ) -> JobState:
        """
        åˆ›å»ºè½¬å½•ä»»åŠ¡

        Args:
            filename: æ–‡ä»¶å
            src_path: æºæ–‡ä»¶è·¯å¾„
            settings: ä»»åŠ¡è®¾ç½®
            job_id: ä»»åŠ¡IDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰

        Returns:
            JobState: åˆ›å»ºçš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_id = job_id or uuid.uuid4().hex
        job_dir = self.jobs_root / job_id
        job_dir.mkdir(parents=True, exist_ok=True)

        dest_path = job_dir / filename

        # å¤åˆ¶æ–‡ä»¶åˆ°ä»»åŠ¡ç›®å½•
        if os.path.abspath(src_path) != os.path.abspath(dest_path):
            try:
                shutil.copyfile(src_path, dest_path)
                self.logger.debug(f"æ–‡ä»¶å·²å¤åˆ¶: {src_path} -> {dest_path}")
            except Exception as e:
                self.logger.warning(f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {e}")

        # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
        job = JobState(
            job_id=job_id,
            filename=filename,
            dir=str(job_dir),
            input_path=src_path,
            settings=settings,
            status="uploaded",
            phase="pending",
            message="æ–‡ä»¶å·²ä¸Šä¼ "
        )

        with self.lock:
            self.jobs[job_id] = job

        # æ·»åŠ æ–‡ä»¶è·¯å¾„åˆ°ä»»åŠ¡IDçš„æ˜ å°„
        self.job_index.add_mapping(src_path, job_id)

        # æŒä¹…åŒ–ä»»åŠ¡å…ƒä¿¡æ¯ï¼ˆé‡å¯åå¯æ¢å¤ï¼‰
        self.save_job_meta(job)

        # ç«‹å³å¼‚æ­¥æå–éŸ³é¢‘ï¼Œç¡®ä¿å‰ç«¯èƒ½åŠ è½½æ³¢å½¢å›¾ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        audio_path = job_dir / 'audio.wav'
        if not audio_path.exists():
            self.logger.info(f"[{job_id}] å¯åŠ¨åå°éŸ³é¢‘æå–...")
            import threading

            def extract_audio_for_waveform():
                """åå°æå–éŸ³é¢‘ä¾›æ³¢å½¢å›¾ä½¿ç”¨"""
                try:
                    import librosa
                    import soundfile as sf
                    audio_array, sr = librosa.load(str(dest_path), sr=16000, mono=True)
                    sf.write(str(audio_path), audio_array, sr)
                    self.logger.info(f"[{job_id}] éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
                except Exception as e:
                    self.logger.error(f"[{job_id}] éŸ³é¢‘æå–å¤±è´¥: {e}")

            threading.Thread(
                target=extract_audio_for_waveform,
                daemon=True,
                name=f"AudioExtract-{job_id[:8]}"
            ).start()
        else:
            self.logger.debug(f"[{job_id}] éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡æå–")

        self.logger.info(f"ä»»åŠ¡å·²åˆ›å»º: {job_id} - {filename}")
        return job

    def save_job_meta(self, job: JobState) -> bool:
        """
        ä¿å­˜ä»»åŠ¡å…ƒä¿¡æ¯åˆ° job_meta.jsonï¼ˆç”¨äºé‡å¯åæ¢å¤ï¼‰

        ä½¿ç”¨åŸå­å†™å…¥ç¡®ä¿æ–­ç”µå®‰å…¨ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†renameæ›¿æ¢

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            bool: æ˜¯å¦æˆåŠŸä¿å­˜
        """
        job_dir = Path(job.dir)
        meta_file = job_dir / "job_meta.json"

        try:
            job_dir.mkdir(parents=True, exist_ok=True)

            # åŸå­å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œå†renameæ›¿æ¢
            temp_file = meta_file.with_suffix(".tmp")
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(job.to_meta_dict(), f, indent=2, ensure_ascii=False)

            # åŸå­æ›¿æ¢
            temp_file.replace(meta_file)
            self.logger.debug(f"ä»»åŠ¡å…ƒä¿¡æ¯å·²ä¿å­˜: {job.job_id}")
            return True
        except Exception as e:
            self.logger.error(f"ä¿å­˜ä»»åŠ¡å…ƒä¿¡æ¯å¤±è´¥ {job.job_id}: {e}")
            return False

    def load_job_meta(self, job_id: str) -> Optional[JobState]:
        """
        ä» job_meta.json åŠ è½½ä»»åŠ¡å…ƒä¿¡æ¯

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: æ¢å¤çš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_dir = self.jobs_root / job_id
        meta_file = job_dir / "job_meta.json"

        if not meta_file.exists():
            return None

        try:
            with open(meta_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            job = JobState.from_meta_dict(data)

            # ç¡®ä¿ dir è·¯å¾„æ­£ç¡®ï¼ˆå¯èƒ½å› ä¸ºé¡¹ç›®è¿ç§»è€Œæ”¹å˜ï¼‰
            job.dir = str(job_dir)

            self.logger.debug(f"ä» job_meta.json åŠ è½½ä»»åŠ¡: {job_id}")
            return job
        except Exception as e:
            self.logger.error(f"åŠ è½½ä»»åŠ¡å…ƒä¿¡æ¯å¤±è´¥ {job_id}: {e}")
            return None

    def get_job(self, job_id: str) -> Optional[JobState]:
        """
        è·å–ä»»åŠ¡çŠ¶æ€

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼Œä¸å­˜åœ¨åˆ™è¿”å›None
        """
        with self.lock:
            # é¦–å…ˆä»å†…å­˜ä¸­æŸ¥æ‰¾
            if job_id in self.jobs:
                return self.jobs[job_id]

        # å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•ä» jobs ç›®å½•è¯»å–ï¼ˆä¿®å¤é‡å¯åæ— æ³•æ‰“å¼€æ—§ä»»åŠ¡çš„é—®é¢˜ï¼‰
        job_dir = self.jobs_root / job_id
        if not job_dir.exists():
            return None

        try:
            # ä¼˜å…ˆä» job_meta.json åŠ è½½ï¼ˆåŒ…å«å®Œæ•´çš„ä»»åŠ¡çŠ¶æ€ï¼‰
            job = self.load_job_meta(job_id)
            if job:
                # ç¼“å­˜åˆ°å†…å­˜
                with self.lock:
                    self.jobs[job_id] = job
                self.logger.info(f"ä» job_meta.json æ¢å¤ä»»åŠ¡: {job_id}")
                return job

            # é™çº§ï¼šä»ç›®å½•æ–‡ä»¶æ¨æ–­çŠ¶æ€ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            # å°è¯•æ‰¾åˆ°åŸå§‹æ–‡ä»¶
            filename = "æœªçŸ¥æ–‡ä»¶"
            input_path = None

            # ä»ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘/éŸ³é¢‘æ–‡ä»¶
            for ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.mp3', '.wav', '.m4a']:
                matches = list(job_dir.glob(f"*{ext}"))
                if matches:
                    filename = matches[0].name
                    input_path = str(matches[0])
                    break

            # æ£€æŸ¥æ˜¯å¦æœ‰ SRT æ–‡ä»¶ï¼ˆè¡¨ç¤ºå·²å®Œæˆï¼‰
            srt_files = list(job_dir.glob("*.srt"))
            is_finished = len(srt_files) > 0

            # åˆ›å»º JobState å¯¹è±¡
            job = JobState(
                job_id=job_id,
                filename=filename,
                dir=str(job_dir),
                input_path=input_path,
                status='finished' if is_finished else 'processing',
                phase='editing' if is_finished else 'transcribing',
                progress=100 if is_finished else 0,
                message='å·²å®Œæˆ' if is_finished else 'å¤„ç†ä¸­',
                srt_path=str(srt_files[0]) if srt_files else None
            )

            # å°è¯•ä» checkpoint è·å–æ›´è¯¦ç»†çš„ä¿¡æ¯
            checkpoint_path = job_dir / "checkpoint.json"
            if checkpoint_path.exists():
                try:
                    with open(checkpoint_path, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)
                        total_segments = checkpoint_data.get('total_segments', 0)
                        processed_indices = checkpoint_data.get('processed_indices', [])
                        if total_segments > 0:
                            job.progress = min((len(processed_indices) / total_segments) * 100, 100)
                        job.phase = checkpoint_data.get('phase', 'transcribing')
                        job.language = checkpoint_data.get('language')
                        # ä»checkpointæ¢å¤segments
                        if 'unaligned_results' in checkpoint_data:
                            job.segments = checkpoint_data['unaligned_results']
                except Exception as e:
                    self.logger.warning(f"è¯»å–checkpointå¤±è´¥ {checkpoint_path}: {e}")

            # ç¼“å­˜åˆ°å†…å­˜
            with self.lock:
                self.jobs[job_id] = job

            # åŒæ—¶ä¿å­˜ job_meta.json ä»¥ä¾¿ä¸‹æ¬¡ç›´æ¥åŠ è½½
            self.save_job_meta(job)

            self.logger.info(f"ä»ç£ç›˜æ¢å¤ä»»åŠ¡ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰: {job_id}")
            return job

        except Exception as e:
            self.logger.error(f"ä»ç£ç›˜è¯»å–ä»»åŠ¡å¤±è´¥ {job_id}: {e}")
            return None

    def scan_incomplete_jobs(self) -> List[Dict]:
        """
        æ‰«ææ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆæœ‰checkpoint.jsonçš„ä»»åŠ¡ï¼‰

        Returns:
            List[Dict]: æœªå®Œæˆä»»åŠ¡åˆ—è¡¨
        """
        incomplete_jobs = []

        try:
            # éå†æ‰€æœ‰ä»»åŠ¡ç›®å½•
            for job_dir in self.jobs_root.iterdir():
                if not job_dir.is_dir():
                    continue

                checkpoint_path = job_dir / "checkpoint.json"
                if not checkpoint_path.exists():
                    continue

                try:
                    # åŠ è½½æ£€æŸ¥ç‚¹æ•°æ®
                    with open(checkpoint_path, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)

                    job_id = checkpoint_data.get('job_id') or job_dir.name
                    total_segments = checkpoint_data.get('total_segments', 0)
                    processed_indices = checkpoint_data.get('processed_indices', [])
                    processed_count = len(processed_indices)

                    # è®¡ç®—è¿›åº¦
                    if total_segments > 0:
                        progress = (processed_count / total_segments) * 100
                    else:
                        progress = 0

                    # ä»ç´¢å¼•ä¸­æŸ¥æ‰¾æ–‡ä»¶å
                    file_path = self.job_index.get_file_path(job_id)
                    filename = os.path.basename(file_path) if file_path else "æœªçŸ¥æ–‡ä»¶"

                    incomplete_jobs.append({
                        'job_id': job_id,
                        'filename': filename,
                        'file_path': file_path,  # æ·»åŠ æ–‡ä»¶è·¯å¾„
                        'progress': round(progress, 2),
                        'processed_segments': processed_count,
                        'total_segments': total_segments,
                        'phase': checkpoint_data.get('phase', 'unknown'),
                        'dir': str(job_dir)
                    })

                except Exception as e:
                    self.logger.warning(f"è¯»å–æ£€æŸ¥ç‚¹å¤±è´¥ {checkpoint_path}: {e}")
                    continue

            self.logger.info(f"æ‰«æåˆ° {len(incomplete_jobs)} ä¸ªæœªå®Œæˆä»»åŠ¡")
            return incomplete_jobs

        except Exception as e:
            self.logger.error(f"æ‰«ææœªå®Œæˆä»»åŠ¡å¤±è´¥: {e}")
            return []

    def restore_job_from_checkpoint(self, job_id: str) -> Optional[JobState]:
        """
        ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡çŠ¶æ€ï¼ˆæ—  checkpoint æ—¶ä»å¤´å¼€å§‹ï¼‰

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            Optional[JobState]: æ¢å¤çš„ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        job_dir = self.jobs_root / job_id
        if not job_dir.exists():
            return None

        # å°è¯•åŠ è½½ checkpointï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
        checkpoint = self._load_checkpoint(job_dir)

        try:
            # æŸ¥æ‰¾åŸæ–‡ä»¶
            filename = "unknown"
            input_path = None

            # ä»ç›®å½•ä¸­æŸ¥æ‰¾è§†é¢‘/éŸ³é¢‘æ–‡ä»¶
            for ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv', '.wmv', '.mp3', '.wav', '.m4a']:
                matches = list(job_dir.glob(f"*{ext}"))
                if matches:
                    filename = matches[0].name
                    input_path = str(matches[0])
                    break

            if not input_path:
                self.logger.warning(f"æ— æ³•æ‰¾åˆ°ä»»åŠ¡ {job_id} çš„è¾“å…¥æ–‡ä»¶")
                return None

            # åˆ›å»ºé»˜è®¤çš„CPUäº²å’Œæ€§é…ç½®
            from app.services.cpu_affinity_service import CPUAffinityConfig
            default_cpu_config = CPUAffinityConfig(
                enabled=True,
                strategy="auto",
                custom_cores=None,
                exclude_cores=None
            )

            # æ ¹æ®æ˜¯å¦æœ‰ checkpoint å†³å®šæ¢å¤çŠ¶æ€
            if checkpoint:
                # æœ‰ checkpointï¼Œä»æ–­ç‚¹æ¢å¤
                phase = checkpoint.get('phase', 'pending')
                total_segments = checkpoint.get('total_segments', 0)
                processed_indices = checkpoint.get('processed_indices', [])
                processed = len(processed_indices)
                progress = round((processed / max(1, total_segments)) * 100, 2)
                message = f"å·²æš‚åœ ({processed}/{total_segments}æ®µ)"
                self.logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡: {job_id}")
            else:
                # æ—  checkpointï¼Œä»å¤´å¼€å§‹
                phase = 'pending'
                total_segments = 0
                processed = 0
                progress = 0
                message = "ç¨‹åºé‡å¯ï¼Œä»»åŠ¡å°†ä»å¤´å¼€å§‹"
                self.logger.info(f"æ— æ£€æŸ¥ç‚¹ï¼Œä»»åŠ¡å°†ä»å¤´å¼€å§‹: {job_id}")

            # åˆ›å»ºä»»åŠ¡çŠ¶æ€å¯¹è±¡
            job = JobState(
                job_id=job_id,
                filename=filename,
                dir=str(job_dir),
                input_path=input_path,
                settings=JobSettings(cpu_affinity=default_cpu_config),
                status="paused",
                phase=phase,
                message=message,
                total=total_segments,
                processed=processed,
                progress=progress
            )

            with self.lock:
                self.jobs[job_id] = job

            return job

        except Exception as e:
            self.logger.error(f"ä»æ£€æŸ¥ç‚¹æ¢å¤ä»»åŠ¡å¤±è´¥: {e}")
            return None

    def check_file_checkpoint(self, file_path: str) -> Optional[Dict]:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å¯ç”¨çš„æ–­ç‚¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Optional[Dict]: æ–­ç‚¹ä¿¡æ¯ï¼Œæ— æ–­ç‚¹åˆ™è¿”å›None
        """
        # ä»ç´¢å¼•ä¸­æŸ¥æ‰¾ä»»åŠ¡ID
        job_id = self.job_index.get_job_id(file_path)
        if not job_id:
            return None

        # æ£€æŸ¥ä»»åŠ¡ç›®å½•å’Œcheckpointæ˜¯å¦å­˜åœ¨
        job_dir = self.jobs_root / job_id
        if not job_dir.exists():
            # æ¸…ç†æ— æ•ˆæ˜ å°„
            self.job_index.remove_mapping(file_path)
            return None

        checkpoint = self._load_checkpoint(job_dir)
        if not checkpoint:
            return None

        # è¿”å›æ–­ç‚¹ä¿¡æ¯
        total_segments = checkpoint.get('total_segments', 0)
        processed_indices = checkpoint.get('processed_indices', [])
        processed_count = len(processed_indices)

        if total_segments > 0:
            progress = (processed_count / total_segments) * 100
        else:
            progress = 0

        return {
            'job_id': job_id,
            'progress': round(progress, 2),
            'processed_segments': processed_count,
            'total_segments': total_segments,
            'phase': checkpoint.get('phase', 'unknown'),
            'can_resume': True
        }

    def start_job(self, job_id: str):
        """
        å¯åŠ¨è½¬å½•ä»»åŠ¡ï¼ˆV2.2: åºŸå¼ƒï¼Œç”±é˜Ÿåˆ—æœåŠ¡è°ƒç”¨_run_pipelineï¼‰

        æ³¨æ„: æ­¤æ–¹æ³•ä¿ç•™æ˜¯ä¸ºäº†å‘åå…¼å®¹ï¼Œä½†ä¸å†è‡ªåŠ¨åˆ›å»ºçº¿ç¨‹

        Args:
            job_id: ä»»åŠ¡ID
        """
        #  å…³é”®æ”¹åŠ¨: ä¸å†è‡ªåŠ¨åˆ›å»ºçº¿ç¨‹ï¼Œç”±é˜Ÿåˆ—æœåŠ¡ç»Ÿä¸€ç®¡ç†
        # åŸæœ‰ä»£ç :
        # threading.Thread(target=self._run_pipeline, args=(job,), daemon=True).start()

        # æ–°é€»è¾‘: åªæ›´æ–°çŠ¶æ€ï¼Œå®é™…æ‰§è¡Œç”±é˜Ÿåˆ—æœåŠ¡æ§åˆ¶
        job = self.get_job(job_id)
        if not job:
            self.logger.warning(f"ä»»åŠ¡æœªæ‰¾åˆ°: {job_id}")
            return

        if job.status not in ("uploaded", "failed", "paused", "created"):
            self.logger.warning(f"ä»»åŠ¡æ— æ³•å¯åŠ¨: {job_id}, çŠ¶æ€: {job.status}")
            return

        job.canceled = False
        job.paused = False
        job.error = None
        # çŠ¶æ€ç”±é˜Ÿåˆ—æœåŠ¡è®¾ç½®ï¼Œè¿™é‡Œä¸æ”¹

        self.logger.warning(f"start_jobå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨é˜Ÿåˆ—æœåŠ¡: {job_id}")

    def pause_job(self, job_id: str) -> bool:
        """
        æš‚åœè½¬å½•ä»»åŠ¡ï¼ˆä¿å­˜æ–­ç‚¹ï¼‰

        Args:
            job_id: ä»»åŠ¡ID

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®æš‚åœæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.paused = True
        job.message = "æš‚åœä¸­..."
        self.logger.info(f"â¸ï¸ ä»»åŠ¡æš‚åœè¯·æ±‚: {job_id}")
        return True

    def cancel_job(self, job_id: str, delete_data: bool = False) -> bool:
        """
        å–æ¶ˆè½¬å½•ä»»åŠ¡

        Args:
            job_id: ä»»åŠ¡ID
            delete_data: æ˜¯å¦åˆ é™¤ä»»åŠ¡æ•°æ®

        Returns:
            bool: æ˜¯å¦æˆåŠŸè®¾ç½®å–æ¶ˆæ ‡å¿—
        """
        job = self.get_job(job_id)
        if not job:
            return False

        job.canceled = True
        job.message = "å–æ¶ˆä¸­..."
        self.logger.info(f"ğŸ›‘ ä»»åŠ¡å–æ¶ˆè¯·æ±‚: {job_id}, åˆ é™¤æ•°æ®: {delete_data}")

        # å¦‚æœéœ€è¦åˆ é™¤æ•°æ®
        if delete_data:
            try:
                job_dir = Path(job.dir)
                # ç§»é™¤æ–‡ä»¶è·¯å¾„æ˜ å°„
                if job.input_path:
                    self.job_index.remove_mapping(job.input_path)

                if job_dir.exists():
                    # åˆ é™¤æ•´ä¸ªä»»åŠ¡ç›®å½•
                    shutil.rmtree(job_dir)
                    self.logger.info(f"å·²åˆ é™¤ä»»åŠ¡æ•°æ®: {job_id}")
                    # ä»å†…å­˜ä¸­ç§»é™¤ä»»åŠ¡
                    with self.lock:
                        if job_id in self.jobs:
                            del self.jobs[job_id]
            except Exception as e:
                self.logger.error(f"åˆ é™¤ä»»åŠ¡æ•°æ®å¤±è´¥: {e}")

        return True

    def _update_progress(
        self,
        job: JobState,
        phase: str,
        phase_ratio: float,
        message: str = ""
    ):
        """
        æ›´æ–°ä»»åŠ¡è¿›åº¦

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            phase: å½“å‰é˜¶æ®µ (extract/split/transcribe/srt)
            phase_ratio: å½“å‰é˜¶æ®µå®Œæˆæ¯”ä¾‹ (0.0-1.0)
            message: è¿›åº¦æ¶ˆæ¯
        """
        job.phase = phase

        # è®¡ç®—é˜¶æ®µå†…è¿›åº¦ï¼ˆ0-100ï¼Œä¿ç•™1ä½å°æ•°ï¼‰
        job.phase_percent = round(max(0.0, min(1.0, phase_ratio)) * 100, 1)

        # ä½¿ç”¨é…ç½®ä¸­çš„è¿›åº¦æƒé‡
        phase_weights = config.PHASE_WEIGHTS
        total_weight = config.TOTAL_WEIGHT

        # è®¡ç®—ç´¯è®¡è¿›åº¦
        done_weight = 0
        for p, w in phase_weights.items():
            if p == phase:
                break
            done_weight += w

        current_weight = phase_weights.get(phase, 0) * max(0.0, min(1.0, phase_ratio))
        # æ”¹ä¸º1ä½å°æ•°
        job.progress = round((done_weight + current_weight) / total_weight * 100, 1)

        if message:
            job.message = message

        # æ¨é€SSEè¿›åº¦æ›´æ–°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        self._push_sse_progress(job)

    def _push_sse_progress(self, job: JobState):
        """
        æ¨é€SSEè¿›åº¦æ›´æ–°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        åŒæ—¶æ¨é€åˆ°å•ä»»åŠ¡é¢‘é“å’Œå…¨å±€é¢‘é“ï¼Œç¡®ä¿ TaskMonitor å®æ—¶æ›´æ–°

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        try:
            # åŠ¨æ€è·å–SSEç®¡ç†å™¨ï¼ˆç¡®ä¿è·å–åˆ°å·²è®¾ç½®loopçš„å®ä¾‹ï¼‰
            from app.services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            # 1. æ¨é€åˆ°å•ä»»åŠ¡é¢‘é“ï¼ˆEditorView ä½¿ç”¨ï¼‰
            channel_id = f"job:{job.job_id}"
            progress_data = {
                "job_id": job.job_id,
                "phase": job.phase,
                "percent": job.progress,
                "phase_percent": job.phase_percent,  # æ–°å¢ï¼šé˜¶æ®µå†…è¿›åº¦
                "message": job.message,
                "status": job.status,
                "processed": job.processed,
                "total": job.total,
                "language": job.language or ""
            }
            sse_manager.broadcast_sync(channel_id, "progress.overall", progress_data)

            # 2. æ¨é€åˆ°å…¨å±€é¢‘é“ï¼ˆTaskMonitor ä½¿ç”¨ï¼‰
            global_progress_data = {
                "id": job.job_id,  # å…¨å±€é¢‘é“ä½¿ç”¨ "id"
                "percent": job.progress,
                "phase_percent": job.phase_percent,  # æ–°å¢ï¼šé˜¶æ®µå†…è¿›åº¦
                "message": job.message,
                "status": job.status,
                "phase": job.phase,
                "processed": job.processed,
                "total": job.total
            }
            sse_manager.broadcast_sync("global", "job_progress", global_progress_data)

        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSEæ¨é€å¤±è´¥: {e}")

    def _push_sse_signal(self, job: JobState, signal_code: str, message: str = ""):
        """
        æ¨é€SSEä¿¡å·äº‹ä»¶ï¼ˆç”¨äºå…³é”®èŠ‚ç‚¹é€šçŸ¥ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            signal_code: ä¿¡å·ä»£ç ï¼ˆå¦‚ "job_complete", "job_failed", "job_canceled"ï¼‰
            message: é™„åŠ æ¶ˆæ¯
        """
        try:
            # åŠ¨æ€è·å–SSEç®¡ç†å™¨ï¼ˆç¡®ä¿è·å–åˆ°å·²è®¾ç½®loopçš„å®ä¾‹ï¼‰
            from app.services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"
            sse_manager.broadcast_sync(
                channel_id,
                f"signal.{signal_code}",
                {
                    "job_id": job.job_id,
                    "signal": signal_code,
                    "message": message or job.message,
                    "status": job.status,
                    "percent": job.progress
                }
            )
        except Exception as e:
            self.logger.debug(f"SSEä¿¡å·æ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _trigger_media_post_process(self, job_id: str):
        """
        å¼‚æ­¥è§¦å‘åª’ä½“é¢„å¤„ç†ï¼ˆè½¬å½•å®Œæˆåè°ƒç”¨ï¼‰
        ç”Ÿæˆæ³¢å½¢å³°å€¼ã€è§†é¢‘ç¼©ç•¥å›¾ã€Proxyè§†é¢‘ç­‰ï¼Œä¸ºç¼–è¾‘å™¨åšå‡†å¤‡

        Args:
            job_id: ä»»åŠ¡ID
        """
        try:
            import asyncio
            import aiohttp

            async def do_post_process():
                """å¼‚æ­¥æ‰§è¡Œé¢„å¤„ç†è¯·æ±‚"""
                try:
                    # è°ƒç”¨åª’ä½“é¢„å¤„ç†æ¥å£
                    async with aiohttp.ClientSession() as session:
                        url = f"http://127.0.0.1:8000/api/media/{job_id}/post-process"
                        async with session.post(url, timeout=aiohttp.ClientTimeout(total=300)) as resp:
                            if resp.status == 200:
                                result = await resp.json()
                                self.logger.info(f"åª’ä½“é¢„å¤„ç†å®Œæˆ: peaks={result.get('peaks')}, thumbnails={result.get('thumbnails')}, proxy={result.get('proxy')}")
                            else:
                                self.logger.warning(f"åª’ä½“é¢„å¤„ç†è¯·æ±‚å¤±è´¥: {resp.status}")
                except asyncio.TimeoutError:
                    self.logger.warning(f"åª’ä½“é¢„å¤„ç†è¶…æ—¶: {job_id}")
                except Exception as e:
                    self.logger.warning(f"åª’ä½“é¢„å¤„ç†å¼‚å¸¸: {e}")

            # å°è¯•åœ¨ç°æœ‰äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ
            try:
                loop = asyncio.get_running_loop()
                asyncio.ensure_future(do_post_process(), loop=loop)
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çº¿ç¨‹æ‰§è¡Œ
                import threading
                def run_in_thread():
                    asyncio.run(do_post_process())
                thread = threading.Thread(target=run_in_thread, daemon=True)
                thread.start()

            self.logger.info(f"å·²è§¦å‘åª’ä½“é¢„å¤„ç†ä»»åŠ¡: {job_id}")

            # è§¦å‘ 720p é«˜æ¸…è½¬ç ï¼ˆé˜Ÿåˆ—ç©ºé—²æ—¶æ‰§è¡Œï¼‰
            self._trigger_720p_transcode_if_idle(job_id)

        except Exception as e:
            # é¢„å¤„ç†å¤±è´¥ä¸å½±å“è½¬å½•ç»“æœ
            self.logger.warning(f"è§¦å‘åª’ä½“é¢„å¤„ç†å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _trigger_720p_transcode_if_idle(self, job_id: str):
        """
        åœ¨è½¬å½•å®Œæˆåè§¦å‘ 720p é«˜æ¸…è½¬ç ï¼ˆä»…åœ¨é˜Ÿåˆ—ç©ºé—²æ—¶ï¼‰

        ç­–ç•¥:
        1. æ£€æŸ¥è§†é¢‘æ˜¯å¦éœ€è¦è½¬ç ï¼ˆH.265 ç­‰ï¼‰
        2. æ£€æŸ¥è½¬å½•é˜Ÿåˆ—æ˜¯å¦ç©ºé—²
        3. å¦‚æœç©ºé—²ï¼Œç«‹å³å¯åŠ¨ 720p è½¬ç 
        4. å¦‚æœé˜Ÿåˆ—æœ‰ä»»åŠ¡ï¼Œå»¶è¿Ÿè§¦å‘ï¼ˆä½¿ç”¨ä½ä¼˜å…ˆçº§ï¼‰
        """
        try:
            from pathlib import Path
            from app.core.config import config
            from app.services.media_prep_service import get_media_prep_service

            self.logger.info(f"[720p] å¼€å§‹æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘720pè½¬ç : {job_id}")

            job_dir = config.JOBS_DIR / job_id
            if not job_dir.exists():
                self.logger.info(f"[720p] ä»»åŠ¡ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡: {job_id}")
                return

            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
            video_file = None
            video_exts = ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.webm', '.flv', '.m4v']
            for file in job_dir.iterdir():
                if file.is_file() and file.suffix.lower() in video_exts:
                    video_file = file
                    break

            if not video_file:
                self.logger.info(f"[720p] æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ï¼Œè·³è¿‡: {job_id}")
                return

            self.logger.info(f"[720p] æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_file.name}")

            # ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶åï¼šproxy_720p.mp4
            proxy_720p = job_dir / "proxy_720p.mp4"

            # 720p å·²å­˜åœ¨åˆ™è·³è¿‡
            if proxy_720p.exists():
                self.logger.info(f"[720p] å·²å­˜åœ¨ï¼Œè·³è¿‡: {job_id}")
                return

            media_prep = get_media_prep_service()

            # æ£€æŸ¥ 720p æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
            proxy_status = media_prep.get_proxy_status(job_id)
            if proxy_status and proxy_status.get("status") in ["queued", "processing", "completed"]:
                self.logger.info(f"[720p] ä»»åŠ¡å·²å­˜åœ¨æˆ–å®Œæˆï¼ˆçŠ¶æ€={proxy_status.get('status')}ï¼‰ï¼Œè·³è¿‡: {job_id}")
                return

            # æ£€æŸ¥ 360p é¢„è§ˆæ˜¯å¦å·²å®Œæˆï¼ˆå¿…é¡»å…ˆæœ‰360pæ‰èƒ½å¯åŠ¨720pï¼‰
            # ä¿®å¤ï¼šä¼˜å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå› ä¸ºå†…å­˜çŠ¶æ€å¯èƒ½åœ¨æœåŠ¡é‡å¯åä¸¢å¤±
            preview_360p = job_dir / "preview_360p.mp4"

            # æ–‡ä»¶å­˜åœ¨å³è®¤ä¸º360på·²å®Œæˆï¼ˆå†…å­˜çŠ¶æ€å¯èƒ½ä¸¢å¤±ï¼‰
            if preview_360p.exists():
                preview_completed = True
                self.logger.debug(f"[720p] 360pæ–‡ä»¶å­˜åœ¨ï¼Œè®¤ä¸ºå·²å®Œæˆ: {job_id}")
            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ£€æŸ¥å†…å­˜çŠ¶æ€ï¼ˆå¯èƒ½æ­£åœ¨è½¬ç ä¸­ï¼‰
                preview_status = media_prep.get_preview_status(job_id)
                preview_completed = preview_status and preview_status.get("status") == "completed"

            if not preview_completed:
                self.logger.info(f"[720p] 360pé¢„è§ˆæœªå®Œæˆï¼Œè·³è¿‡720pè½¬ç : {job_id}")
                return

            # æ£€æŸ¥è½¬å½•é˜Ÿåˆ—æ˜¯å¦ç©ºé—²
            queue_idle = self._is_transcription_queue_idle()
            self.logger.info(f"[720p] é˜Ÿåˆ—ç©ºé—²çŠ¶æ€: {queue_idle}")

            if queue_idle:
                # é˜Ÿåˆ—ç©ºé—²ï¼Œç«‹å³å¯åŠ¨ï¼ˆæ­£å¸¸ä¼˜å…ˆçº§ï¼‰
                self.logger.info(f"[720p] é˜Ÿåˆ—ç©ºé—²ï¼Œç«‹å³å¯åŠ¨è½¬ç : {job_id}")
                success = media_prep.enqueue_proxy(job_id, video_file, proxy_720p, priority=10)
                self.logger.info(f"[720p] å…¥é˜Ÿç»“æœ: {success}")
            else:
                # é˜Ÿåˆ—ç¹å¿™ï¼Œä½¿ç”¨ä½ä¼˜å…ˆçº§ï¼ˆç‹¬ç«‹è¿›ç¨‹æ¨¡å¼ï¼‰
                self.logger.info(f"[720p] é˜Ÿåˆ—ç¹å¿™ï¼Œä½ä¼˜å…ˆçº§æ’é˜Ÿ: {job_id}")
                success = media_prep.enqueue_proxy(job_id, video_file, proxy_720p, priority=1)
                self.logger.info(f"[720p] å…¥é˜Ÿç»“æœ: {success}")

        except Exception as e:
            self.logger.warning(f"[720p] è§¦å‘è½¬ç å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _is_transcription_queue_idle(self) -> bool:
        """æ£€æŸ¥è½¬å½•ä»»åŠ¡é˜Ÿåˆ—æ˜¯å¦ç©ºé—²"""
        try:
            from app.services.job_queue_service import get_job_queue

            job_queue = get_job_queue()
            if not job_queue:
                return True

            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨å¤„ç†æˆ–ç­‰å¾…çš„ä»»åŠ¡
            active_jobs = [
                j for j in job_queue.jobs.values()
                if j.status in ['pending', 'processing', 'queued']
            ]

            return len(active_jobs) == 0

        except Exception as e:
            self.logger.debug(f"æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {e}")
            return True  # é»˜è®¤è®¤ä¸ºç©ºé—²

    def _push_sse_segment(self, job: JobState, segment_result: dict, processed: int, total: int):
        """
        æ¨é€å•ä¸ªsegmentçš„è½¬å½•ç»“æœï¼ˆæµå¼è¾“å‡ºï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            segment_result: å•ä¸ªsegmentçš„è½¬å½•ç»“æœï¼ˆæœªå¯¹é½ï¼‰
            processed: å·²å¤„ç†çš„segmentæ•°é‡
            total: æ€»segmentæ•°é‡
        """
        try:
            # åŠ¨æ€è·å–SSEç®¡ç†å™¨
            from app.services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"
            sse_manager.broadcast_sync(
                channel_id,
                "subtitle.segment",
                {
                    "segment_index": segment_result.get('segment_index', 0),
                    "segments": segment_result.get('segments', []),
                    "language": segment_result.get('language', job.language),
                    "progress": {
                        "processed": processed,
                        "total": total,
                        "percentage": round(processed / max(1, total) * 100, 2)
                    }
                }
            )
            self.logger.debug(f"æ¨é€segment #{segment_result.get('segment_index', 0)} è½¬å½•ç»“æœ")
        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSE segmentæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _push_sse_aligned(self, job: JobState, aligned_results: List[Dict]):
        """
        æ¨é€å¯¹é½å®Œæˆäº‹ä»¶ï¼ˆæµå¼è¾“å‡ºï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            aligned_results: å¯¹é½åçš„ç»“æœåˆ—è¡¨
        """
        try:
            # åŠ¨æ€è·å–SSEç®¡ç†å™¨
            from app.services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"

            # æå–å¯¹é½åçš„segments
            segments = []
            word_segments = []
            if aligned_results and len(aligned_results) > 0:
                segments = aligned_results[0].get('segments', [])
                word_segments = aligned_results[0].get('word_segments', [])

            sse_manager.broadcast_sync(
                channel_id,
                "subtitle.aligned",
                {
                    "segments": segments,
                    "word_segments": word_segments,
                    "message": "å¯¹é½å®Œæˆ"
                }
            )
            self.logger.info(f"æ¨é€å¯¹é½å®Œæˆäº‹ä»¶ï¼Œå…± {len(segments)} æ¡å­—å¹•")
        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“è½¬å½•æµç¨‹
            self.logger.debug(f"SSE alignedæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _save_checkpoint(self, job_dir: Path, data: dict, job: JobState):
        """
        åŸå­æ€§ä¿å­˜æ£€æŸ¥ç‚¹
        ä½¿ç”¨"å†™ä¸´æ—¶æ–‡ä»¶ -> é‡å‘½å"ç­–ç•¥ï¼Œç¡®ä¿æ–‡ä»¶è¦ä¹ˆå®Œæ•´å†™å…¥ï¼Œè¦ä¹ˆä¿æŒåŸæ ·

        Args:
            job_dir: ä»»åŠ¡ç›®å½•
            data: æ£€æŸ¥ç‚¹æ•°æ®
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼ˆç”¨äºè·å–settingsï¼‰
        """
        # æ·»åŠ åŸå§‹è®¾ç½®åˆ°checkpointï¼ˆç”¨äºæ ¡éªŒå‚æ•°å…¼å®¹æ€§ï¼‰
        # ä½¿ç”¨ ConfigAdapter ç»Ÿä¸€æ–°æ—§é…ç½®
        demucs_strategy = ConfigAdapter.get_demucs_strategy(job.settings)
        data["original_settings"] = {
            "model": job.settings.model,
            "device": job.settings.device,
            "word_timestamps": job.settings.word_timestamps,
            "compute_type": job.settings.compute_type,
            "batch_size": job.settings.batch_size,
            "demucs": {
                "enabled": ConfigAdapter.is_demucs_enabled(job.settings),
                "mode": demucs_strategy,
            }
        }

        # ç¡®ä¿ demucs å­—æ®µå­˜åœ¨ï¼ˆå‘åå…¼å®¹ï¼‰
        if "demucs" not in data:
            data["demucs"] = {
                "enabled": ConfigAdapter.is_demucs_enabled(job.settings),
                "mode": demucs_strategy,
                "bgm_level": "none",
                "bgm_ratios": [],
                "global_separation_done": False,
                "vocals_path": None,
                "circuit_breaker": None,
                "retry_triggered": False
            }

        checkpoint_path = job_dir / "checkpoint.json"
        temp_path = checkpoint_path.with_suffix(".tmp")

        try:
            # 1. å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            # 2. åŸå­æ›¿æ¢ï¼ˆWindows/Linux/macOS å‡æ”¯æŒï¼‰
            # å¦‚æœç¨‹åºåœ¨è¿™é‡Œå´©æºƒï¼Œcheckpoint.json ä¾ç„¶æ˜¯æ—§ç‰ˆæœ¬ï¼Œä¸ä¼šæŸå
            os.replace(temp_path, checkpoint_path)

            # 3. åŒæ­¥ä¿å­˜ä»»åŠ¡å…ƒä¿¡æ¯ï¼ˆç”¨äºé‡å¯åæ¢å¤ä»»åŠ¡çŠ¶æ€ï¼‰
            # è¿™æ ·æ¯æ¬¡ä¿å­˜æ£€æŸ¥ç‚¹æ—¶ï¼Œä»»åŠ¡çš„è¿›åº¦å’ŒçŠ¶æ€éƒ½ä¼šè¢«æŒä¹…åŒ–
            self.save_job_meta(job)

        except Exception as e:
            self.logger.error(f"ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            # ä¿å­˜å¤±è´¥ä¸åº”ä¸­æ–­ä¸»æµç¨‹ï¼Œä»…è®°å½•æ—¥å¿—

    def _load_checkpoint(self, job_dir: Path) -> Optional[dict]:
        """
        åŠ è½½æ£€æŸ¥ç‚¹ï¼Œå¦‚æœæ–‡ä»¶æŸååˆ™è¿”å› None

        Args:
            job_dir: ä»»åŠ¡ç›®å½•

        Returns:
            Optional[dict]: æ£€æŸ¥ç‚¹æ•°æ®ï¼Œä¸å­˜åœ¨æˆ–æŸååˆ™è¿”å› None
        """
        checkpoint_path = job_dir / "checkpoint.json"
        if not checkpoint_path.exists():
            return None

        try:
            with open(checkpoint_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError) as e:
            self.logger.warning(f"æ£€æŸ¥ç‚¹æ–‡ä»¶æŸåï¼Œå°†é‡æ–°å¼€å§‹ä»»åŠ¡: {checkpoint_path} - {e}")
            return None

    def _flush_checkpoint_after_split(
        self,
        job_dir: Path,
        job: JobState,
        segments: List[Dict],
        processing_mode: ProcessingMode,
        demucs_state: Dict = None
    ):
        """
        åˆ†æ®µå®Œæˆåå¼ºåˆ¶åˆ·æ–°checkpointï¼ˆç¡®ä¿æ–­ç‚¹ç»­ä¼ ä¸€è‡´æ€§ï¼‰

        è¿™æ˜¯æ–­ç‚¹ç»­ä¼ çš„å…³é”®èŠ‚ç‚¹ï¼
        åªæœ‰åˆ†æ®µå…ƒæ•°æ®è¢«æŒä¹…åŒ–åï¼Œåç»­çš„è½¬å½•ç´¢å¼•æ‰æœ‰æ„ä¹‰ã€‚

        Args:
            job_dir: ä»»åŠ¡ç›®å½•
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            segments: åˆ†æ®µå…ƒæ•°æ®åˆ—è¡¨
            processing_mode: å½“å‰å¤„ç†æ¨¡å¼
            demucs_state: DemucsçŠ¶æ€æ•°æ®ï¼ˆå¯é€‰ï¼‰
        """
        import time

        checkpoint_data = {
            "job_id": job.job_id,
            "phase": "split_complete",  # æ˜ç¡®æ ‡è®°åˆ†æ®µå®Œæˆ
            "processing_mode": processing_mode.value,  # è®°å½•æ¨¡å¼
            "total_segments": len(segments),
            "processed_indices": [],
            "segments": segments,
            "unaligned_results": [],
            "timestamp": time.time()  # æ—¶é—´æˆ³ç”¨äºè°ƒè¯•
        }

        # æ·»åŠ  demucs çŠ¶æ€ï¼ˆå¦‚æœæä¾›ï¼‰
        if demucs_state:
            checkpoint_data["demucs"] = demucs_state

        # å¼ºåˆ¶åŒæ­¥å†™å…¥ï¼ˆç¡®ä¿æ•°æ®è½ç›˜ï¼‰
        self._save_checkpoint(job_dir, checkpoint_data, job)

        # éªŒè¯å†™å…¥æˆåŠŸ
        saved_checkpoint = self._load_checkpoint(job_dir)
        if saved_checkpoint is None:
            raise RuntimeError("checkpoint write verification failed: file not readable")

        if saved_checkpoint.get('phase') != 'split_complete':
            raise RuntimeError("checkpoint write verification failed: phase mismatch")

        if len(saved_checkpoint.get('segments', [])) != len(segments):
            raise RuntimeError("checkpoint write verification failed: segments count mismatch")

        self.logger.info(f"checkpoint flushed and verified after split (mode: {processing_mode.value}, segments: {len(segments)})")

    def _run_pipeline(self, job: JobState):
        """
        æ‰§è¡Œè½¬å½•å¤„ç†ç®¡é“ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
        """
        # åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®
        cpu_applied = False
        if job.settings.cpu_affinity and job.settings.cpu_affinity.enabled:
            cpu_applied = self.cpu_manager.apply_cpu_affinity(
                job.settings.cpu_affinity
            )
            if cpu_applied:
                self.logger.info(f"ğŸ“Œ ä»»åŠ¡ {job.job_id} å·²åº”ç”¨CPUäº²å’Œæ€§è®¾ç½®")

        try:
            # æ£€æŸ¥å–æ¶ˆå’Œæš‚åœæ ‡å¿—
            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                return

            if job.paused:
                job.status = 'paused'
                job.message = 'å·²æš‚åœ'
                self.logger.info(f"â¸ï¸ ä»»åŠ¡å·²æš‚åœ: {job.job_id}")
                return

            job_dir = Path(job.dir)
            input_path = job_dir / job.filename
            audio_path = job_dir / 'audio.wav'

            # ==========================================
            # 1. å°è¯•æ¢å¤çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­ä¼ æ ¸å¿ƒï¼‰
            # ==========================================
            checkpoint = self._load_checkpoint(job_dir)

            # åˆå§‹åŒ–å†…å­˜çŠ¶æ€
            processed_indices = set()
            unaligned_results = []  # æœªå¯¹é½çš„è½¬å½•ç»“æœ
            current_segments = []

            if checkpoint:
                self.logger.info(f"å‘ç°æ£€æŸ¥ç‚¹ï¼Œä» {checkpoint.get('phase', 'unknown')} é˜¶æ®µæ¢å¤")
                # æ¢å¤æ•°æ®åˆ°å†…å­˜
                processed_indices = set(checkpoint.get('processed_indices', []))

                # ã€å…¼å®¹æ€§å¤„ç†ã€‘æ”¯æŒæ—§æ ¼å¼checkpoint
                if 'unaligned_results' in checkpoint:
                    # æ–°æ ¼å¼ï¼šunaligned_resultså­—æ®µ
                    unaligned_results = checkpoint.get('unaligned_results', [])
                    self.logger.info("æ£€æµ‹åˆ°æ–°æ ¼å¼checkpointï¼ˆæœªå¯¹é½ç»“æœï¼‰")
                elif 'results' in checkpoint:
                    # æ—§æ ¼å¼ï¼šresultså­—æ®µï¼ˆå·²å¯¹é½ï¼‰
                    self.logger.warning("æ£€æµ‹åˆ°æ—§ç‰ˆcheckpointæ ¼å¼ï¼Œå°†ç›´æ¥ä½¿ç”¨å·²å¯¹é½ç»“æœ")
                    # å°†æ—§æ ¼å¼è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼ˆè·³è¿‡å¯¹é½é˜¶æ®µï¼‰
                    # è¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬ç›´æ¥ä½¿ç”¨resultsä½œä¸ºæœ€ç»ˆç»“æœ
                    pass

                current_segments = checkpoint.get('segments', [])
                # æ¢å¤ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
                job.total = checkpoint.get('total_segments', 0)
                job.processed = len(processed_indices)
                self.logger.info(f"å·²å¤„ç† {job.processed}/{job.total} æ®µ")

            # ==========================================
            # 2. é˜¶æ®µ1: æå–éŸ³é¢‘
            # ==========================================
            # åªæœ‰å½“éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ–è€…ä»å¤´å¼€å§‹æ—¶ï¼Œæ‰æ‰§è¡Œæå–
            if not audio_path.exists() or (checkpoint is None):
                self._update_progress(job, 'extract', 0, 'æå–éŸ³é¢‘ä¸­')
                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                if not self._extract_audio(str(input_path), str(audio_path)):
                    raise RuntimeError('FFmpeg æå–éŸ³é¢‘å¤±è´¥')

                self._update_progress(job, 'extract', 1, 'éŸ³é¢‘æå–å®Œæˆ')
            else:
                self.logger.info("è·³è¿‡éŸ³é¢‘æå–ï¼Œä½¿ç”¨å·²æœ‰æ–‡ä»¶")

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 2. é˜¶æ®µ2: BGMæ£€æµ‹ï¼ˆå¯é€‰ï¼‰
            # ==========================================
            from app.services.demucs_service import BGMLevel

            bgm_level = BGMLevel.NONE
            bgm_ratios = []
            # ä½¿ç”¨é…ç½®é€‚é…å™¨è·å– Demucs ç­–ç•¥ï¼ˆä¿®å¤ç›´é€šæ¨¡å¼ä¸ç”Ÿæ•ˆçš„é—®é¢˜ï¼‰
            demucs_strategy = ConfigAdapter.get_demucs_strategy(job.settings)
            demucs_settings = job.settings.demucs  # ä¿ç•™æ—§ç‰ˆå¯¹è±¡ç”¨äºç­–ç•¥è§£æå™¨

            # ä»checkpointæ¢å¤BGMæ£€æµ‹ç»“æœ
            if checkpoint and 'demucs' in checkpoint:
                demucs_state = checkpoint['demucs']
                bgm_level_str = demucs_state.get('bgm_level', 'none')
                bgm_level = BGMLevel(bgm_level_str)
                bgm_ratios = demucs_state.get('bgm_ratios', [])
                self.logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤BGMæ£€æµ‹ç»“æœ: {bgm_level.value}")
            else:
                # æ‰§è¡ŒBGMæ£€æµ‹ï¼ˆå¦‚æœå¯ç”¨ä¸”æ¨¡å¼éœ€è¦ï¼‰
                if demucs_strategy in ["auto", "force_on"]:
                    bgm_level, bgm_ratios = self._detect_bgm(str(audio_path), job)
                    self.logger.info(f"BGMæ£€æµ‹å®Œæˆ: {bgm_level.value}")

                    # å¦‚æœ BGM æ£€æµ‹ç»“æœä¸º NONEï¼Œç«‹å³å¸è½½ Demucs æ¨¡å‹é‡Šæ”¾æ˜¾å­˜
                    if bgm_level == BGMLevel.NONE:
                        from app.services.demucs_service import get_demucs_service
                        demucs_service = get_demucs_service()
                        if demucs_service.is_model_loaded():
                            self.logger.info("BGM æ£€æµ‹ä¸º NONEï¼Œå¸è½½ Demucs æ¨¡å‹é‡Šæ”¾æ˜¾å­˜")
                            demucs_service.unload_model()

            # ==========================================
            # 3. é˜¶æ®µ3: å…¨å±€äººå£°åˆ†ç¦»ï¼ˆä½¿ç”¨åˆ†çº§ç­–ç•¥ï¼‰
            # ==========================================
            use_vocals = False
            vocals_path = None
            separation_strategy = None

            # åªæœ‰å¯ç”¨ Demucs æ—¶æ‰ç”Ÿæˆåˆ†ç¦»ç­–ç•¥ï¼ˆä½¿ç”¨é…ç½®é€‚é…å™¨åˆ¤æ–­ï¼‰
            if demucs_strategy != "off":
                # ã€æ–°å¢ã€‘ä½¿ç”¨ç­–ç•¥è§£æå™¨å†³å®šåˆ†ç¦»ç­–ç•¥
                from app.services.demucs_service import SeparationStrategyResolver, get_demucs_service
                strategy_resolver = SeparationStrategyResolver(demucs_settings)
                separation_strategy = strategy_resolver.resolve(bgm_level)

                # æ¨é€åˆ†ç¦»ç­–ç•¥SSEäº‹ä»¶
                self._push_sse_separation_strategy(job, separation_strategy)

                self.logger.info(
                    f"åˆ†ç¦»ç­–ç•¥: should_separate={separation_strategy.should_separate}, "
                    f"model={separation_strategy.initial_model}, "
                    f"reason={separation_strategy.reason}"
                )

            # ä»checkpointæ¢å¤åˆ†ç¦»çŠ¶æ€
            if checkpoint and 'demucs' in checkpoint:
                demucs_state = checkpoint['demucs']
                if demucs_state.get('global_separation_done'):
                    vocals_path = demucs_state.get('vocals_path')
                    use_vocals = True
                    self.logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼šä½¿ç”¨å·²åˆ†ç¦»çš„äººå£° {vocals_path}")

            # å¦‚æœç­–ç•¥è¦æ±‚åˆ†ç¦»ä¸”å°šæœªå®Œæˆ
            if separation_strategy and separation_strategy.should_separate and not use_vocals:
                # ã€å…³é”®ã€‘æ ¹æ®ç­–ç•¥é€‰æ‹©æ¨¡å‹
                from app.services.demucs_service import get_demucs_service
                demucs_service = get_demucs_service()
                demucs_service.set_model_for_strategy(separation_strategy)

                vocals_path = self._separate_vocals_global(str(audio_path), job)
                use_vocals = True
                self.logger.info(f"å…¨å±€äººå£°åˆ†ç¦»å®Œæˆ: {vocals_path} (æ¨¡å‹: {separation_strategy.initial_model})")

            # å†³å®šåç»­ä½¿ç”¨å“ªä¸ªéŸ³é¢‘æ–‡ä»¶
            active_audio_path = Path(vocals_path) if use_vocals else audio_path

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 4. é˜¶æ®µ1.5: æ™ºèƒ½æ¨¡å¼å†³ç­–
            # ==========================================
            processing_mode = None
            audio_array = None  # å†…å­˜æ¨¡å¼ä¸‹çš„éŸ³é¢‘æ•°ç»„

            # ä»checkpointæ¢å¤æ¨¡å¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if checkpoint and 'processing_mode' in checkpoint:
                mode_value = checkpoint['processing_mode']
                processing_mode = ProcessingMode(mode_value)
                self.logger.info(f"ä»æ£€æŸ¥ç‚¹æ¢å¤å¤„ç†æ¨¡å¼: {processing_mode.value}")

            # å¦‚æœæ²¡æœ‰æ£€æŸ¥ç‚¹æˆ–æ²¡æœ‰æ¨¡å¼ä¿¡æ¯ï¼Œè¿›è¡Œæ™ºèƒ½å†³ç­–
            if processing_mode is None:
                processing_mode = self._decide_processing_mode(str(active_audio_path), job)
                self.logger.info(f"æ™ºèƒ½é€‰æ‹©å¤„ç†æ¨¡å¼: {processing_mode.value}")

            # ==========================================
            # 5. é˜¶æ®µ1.6: éŸ³é¢‘åŠ è½½ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
            # ==========================================
            if processing_mode == ProcessingMode.MEMORY:
                # å†…å­˜æ¨¡å¼ï¼šå°è¯•åŠ è½½å®Œæ•´éŸ³é¢‘åˆ°å†…å­˜ï¼ˆä½¿ç”¨å¯èƒ½åˆ†ç¦»åçš„éŸ³é¢‘ï¼‰
                try:
                    audio_array = self._safe_load_audio(str(active_audio_path), job)
                    self.logger.info("éŸ³é¢‘å·²åŠ è½½åˆ°å†…å­˜ï¼ˆå†…å­˜æ¨¡å¼ï¼‰")
                except RuntimeError as e:
                    # åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°ç¡¬ç›˜æ¨¡å¼
                    self.logger.warning(f"å†…å­˜åŠ è½½å¤±è´¥ï¼Œé™çº§åˆ°ç¡¬ç›˜æ¨¡å¼: {e}")
                    processing_mode = ProcessingMode.DISK
                    audio_array = None

            # ==========================================
            # 6. é˜¶æ®µ2: æ™ºèƒ½åˆ†æ®µï¼ˆæ¨¡å¼æ„ŸçŸ¥ï¼‰
            # ==========================================
            # å¦‚æœæ£€æŸ¥ç‚¹é‡Œæ²¡æœ‰åˆ†æ®µä¿¡æ¯ï¼Œè¯´æ˜ä¸Šæ¬¡æ²¡è·‘åˆ°åˆ†æ®µå®Œæˆ
            if not current_segments:
                self._update_progress(job, 'split', 0, 'éŸ³é¢‘åˆ†æ®µä¸­')

                # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†æ®µæ–¹æ³•
                if processing_mode == ProcessingMode.MEMORY and audio_array is not None:
                    # å†…å­˜æ¨¡å¼ï¼šVADåˆ†æ®µï¼ˆä¸äº§ç”Ÿç£ç›˜IOï¼‰
                    self.logger.info("ä½¿ç”¨å†…å­˜VADåˆ†æ®µï¼ˆé«˜æ€§èƒ½æ¨¡å¼ï¼‰")
                    from app.services.transcription_service import VADConfig
                    current_segments = self._split_audio_in_memory(
                        audio_array,
                        sr=16000,
                        vad_config=VADConfig()  # ä½¿ç”¨é»˜è®¤Silero VAD
                    )
                else:
                    # ç¡¬ç›˜æ¨¡å¼ï¼šä¼ ç»Ÿpydubåˆ†æ®µï¼ˆä½¿ç”¨å¯èƒ½åˆ†ç¦»åçš„éŸ³é¢‘ï¼‰
                    self.logger.info("ä½¿ç”¨ç¡¬ç›˜åˆ†æ®µï¼ˆç¨³å®šæ¨¡å¼ï¼‰")
                    current_segments = self._split_audio_to_disk(str(active_audio_path))

                if job.canceled:
                    raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                job.segments = current_segments
                job.total = len(current_segments)
                self._update_progress(job, 'split', 1, f'åˆ†æ®µå®Œæˆ å…±{job.total}æ®µ')

                # ã€å…³é”®åŸ‹ç‚¹1ã€‘åˆ†æ®µå®Œæˆåå¼ºåˆ¶åˆ·æ–°checkpointï¼ˆä½¿ç”¨æ–°æ–¹æ³•ï¼ŒåŒ…å«demucsçŠ¶æ€ï¼‰
                self._flush_checkpoint_after_split(
                    job_dir,
                    job,
                    current_segments,
                    processing_mode,
                    demucs_state={
                        "enabled": demucs_settings.enabled,
                        "mode": demucs_settings.mode,
                        "bgm_level": bgm_level.value,
                        "bgm_ratios": bgm_ratios,
                        "global_separation_done": use_vocals,
                        "vocals_path": str(vocals_path) if vocals_path else None,
                        "used_model": separation_strategy.initial_model if separation_strategy else None,
                        "circuit_breaker": None,
                        "retry_triggered": False
                    }
                )
                self.logger.info("æ£€æŸ¥ç‚¹å·²å¼ºåˆ¶åˆ·æ–°: åˆ†æ®µå®Œæˆï¼ˆå«demucsçŠ¶æ€ï¼‰")
            else:
                self.logger.info(f"è·³è¿‡åˆ†æ®µï¼Œä½¿ç”¨æ£€æŸ¥ç‚¹æ•°æ®ï¼ˆå…±{len(current_segments)}æ®µï¼‰")
                job.segments = current_segments  # æ¢å¤åˆ° job å¯¹è±¡
                job.total = len(current_segments)

            # ==========================================
            # 6. é˜¶æ®µ3: è½¬å½•å¤„ç†ï¼ˆåŒæ¨¡å¼ç»Ÿä¸€å¾ªç¯ + Demucsç†”æ–­ï¼‰
            # ==========================================
            self._update_progress(job, 'transcribe', 0, 'åŠ è½½æ¨¡å‹ä¸­')
            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            model = self._get_model(job.settings, job)

            # è¿‡æ»¤å‡ºéœ€è¦å¤„ç†çš„æ®µ
            todo_segments = [
                seg for i, seg in enumerate(current_segments)
                if i not in processed_indices
            ]

            self.logger.info(f"å‰©ä½™ {len(todo_segments)}/{len(current_segments)} æ®µéœ€è¦è½¬å½•")
            self.logger.info(f"å¤„ç†æ¨¡å¼: {processing_mode.value}")

            # åˆå§‹åŒ–ç†”æ–­å™¨ï¼ˆå¦‚æœå¯ç”¨ä¸”å¤„äºæŒ‰éœ€åˆ†ç¦»æ¨¡å¼ï¼‰
            circuit_breaker = None
            demucs_settings = job.settings.demucs
            if (demucs_settings.enabled and
                demucs_settings.mode in ["auto", "on_demand"] and
                not use_vocals):  # åªæœ‰åœ¨æœªè¿›è¡Œå…¨å±€åˆ†ç¦»æ—¶æ‰å¯ç”¨ç†”æ–­
                circuit_breaker = CircuitBreakerState()
                circuit_breaker.total_segments = len(current_segments)
                self.logger.info("ç†”æ–­æœºåˆ¶å·²å¯ç”¨")

            try:
                for idx, seg in enumerate(current_segments):
                    # å¦‚æœå·²ç»åœ¨ processed_indices é‡Œï¼Œç›´æ¥è·³è¿‡
                    if idx in processed_indices:
                        self.logger.debug(f"â­ï¸ è·³è¿‡å·²å¤„ç†æ®µ {idx}")
                        continue

                    # æ£€æŸ¥å–æ¶ˆå’Œæš‚åœæ ‡å¿—
                    if job.canceled:
                        raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                    if job.paused:
                        raise RuntimeError('ä»»åŠ¡å·²æš‚åœ')

                    # ã€å†…å­˜ç›‘æ§ã€‘å®šæœŸæ£€æŸ¥å†…å­˜çŠ¶æ€ï¼ˆæ¯10æ®µæ£€æŸ¥ä¸€æ¬¡ï¼‰
                    if idx % 10 == 0 and processing_mode == ProcessingMode.MEMORY:
                        if not self._check_memory_during_transcription(job):
                            # å†…å­˜ä¸¥é‡ä¸è¶³ï¼Œä»»åŠ¡å·²æš‚åœ
                            raise RuntimeError('å†…å­˜ä¸è¶³ï¼Œä»»åŠ¡å·²æš‚åœ')

                    ratio = len(processed_indices) / max(1, len(current_segments))
                    self._update_progress(
                        job,
                        'transcribe',
                        ratio,
                        f'è½¬å½• {len(processed_indices)+1}/{len(current_segments)}'
                    )

                    # ç¡®ä¿segmentæœ‰indexå­—æ®µ
                    if 'index' not in seg:
                        seg['index'] = idx

                    # ã€ç»Ÿä¸€å…¥å£ã€‘ä½¿ç”¨å¸¦é‡è¯•çš„è½¬å½•æ–¹æ³•ï¼ˆæ”¯æŒç†”æ–­ï¼‰
                    if circuit_breaker:
                        # å¯ç”¨ç†”æ–­æ¨¡å¼ï¼šä½¿ç”¨ _transcribe_segment_with_retry
                        seg_result = self._transcribe_segment_with_retry(
                            seg,
                            model,
                            job,
                            audio_array=audio_array,
                            circuit_breaker=circuit_breaker
                        )
                    else:
                        # æœªå¯ç”¨ç†”æ–­ï¼šä½¿ç”¨åŸå§‹æ–¹æ³•
                        seg_result = self._transcribe_segment(
                            seg,
                            model,
                            job,
                            audio_array=audio_array
                        )

                    # --- æ›´æ–°å†…å­˜çŠ¶æ€ ---
                    if seg_result:
                        unaligned_results.append(seg_result)
                    processed_indices.add(idx)
                    job.processed = len(processed_indices)

                    # --- æ›´æ–°è¿›åº¦æ¡ ---
                    progress = len(processed_indices) / len(current_segments)
                    self._update_progress(
                        job,
                        'transcribe',
                        progress,
                        f'è½¬å½•ä¸­ {len(processed_indices)}/{len(current_segments)}'
                    )

                    # ã€æµå¼è¾“å‡ºã€‘ç«‹å³æ¨é€å•ä¸ªsegmentçš„è½¬å½•ç»“æœ
                    if seg_result:
                        self._push_sse_segment(job, seg_result, len(processed_indices), len(current_segments))

                    # ã€å…³é”®åŸ‹ç‚¹2ã€‘æ¯å¤„ç†ä¸€æ®µä¿å­˜ä¸€æ¬¡ï¼ˆä¿å­˜æœªå¯¹é½ç»“æœï¼‰
                    checkpoint_data = {
                        "job_id": job.job_id,
                        "phase": "transcribe",
                        "processing_mode": processing_mode.value,  # ä¿å­˜æ¨¡å¼ä¿¡æ¯
                        "total_segments": len(current_segments),
                        "processed_indices": list(processed_indices),  # setè½¬list
                        "segments": current_segments,
                        "unaligned_results": unaligned_results  # ä¿å­˜æœªå¯¹é½ç»“æœ
                    }
                    self._save_checkpoint(job_dir, checkpoint_data, job)
                    self.logger.debug(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {len(processed_indices)}/{len(current_segments)}")

                self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆ')

            except BreakToGlobalSeparation as e:
                # ç†”æ–­è§¦å‘ï¼šå‡çº§æ¨¡å‹å¹¶æ‰§è¡Œå…¨å±€äººå£°åˆ†ç¦»
                self.logger.warning(f"ç†”æ–­è§¦å‘: {e}")

                # æ¨é€ SSE äº‹ä»¶
                self._push_sse_circuit_breaker_triggered(job, circuit_breaker)

                # ã€æ–°å¢ã€‘æ£€æŸ¥æ˜¯å¦å…è®¸æ¨¡å‹å‡çº§
                if separation_strategy and separation_strategy.allow_escalation:
                    # å‡çº§åˆ° fallback æ¨¡å‹
                    fallback = separation_strategy.fallback_model
                    if fallback:
                        self.logger.info(f"æ¨¡å‹å‡çº§: {separation_strategy.initial_model} â†’ {fallback}")
                        from app.services.demucs_service import get_demucs_service
                        demucs_service = get_demucs_service()
                        demucs_service.set_model(fallback)

                        # æ¨é€æ¨¡å‹å‡çº§äº‹ä»¶
                        self._push_sse_model_escalated(
                            job,
                            separation_strategy.initial_model,
                            fallback,
                            "ç†”æ–­è§¦å‘ï¼Œå‡çº§åˆ°å…œåº•æ¨¡å‹",
                            circuit_breaker
                        )

                # æ‰§è¡Œå…¨å±€äººå£°åˆ†ç¦»ï¼ˆä½¿ç”¨å‡çº§åçš„æ¨¡å‹ï¼‰
                self.logger.info("å¼€å§‹æ‰§è¡Œå…¨å±€äººå£°åˆ†ç¦»ï¼ˆç†”æ–­å‡çº§ï¼‰...")
                vocals_path = self._separate_vocals_global(str(audio_path), job)

                # æ›´æ–° active_audio_path
                active_audio_path = Path(vocals_path)

                # é‡æ–°åŠ è½½åˆ†ç¦»åçš„éŸ³é¢‘
                if processing_mode == ProcessingMode.MEMORY:
                    self.logger.info("é‡æ–°åŠ è½½åˆ†ç¦»åçš„éŸ³é¢‘åˆ°å†…å­˜...")
                    audio_array = self._safe_load_audio(str(active_audio_path), job)

                # é‡ç½®çŠ¶æ€ï¼Œç»§ç»­å¤„ç†å‰©ä½™æ®µè½
                self.logger.info("ç»§ç»­å¤„ç†å‰©ä½™æ®µè½ï¼ˆä½¿ç”¨åˆ†ç¦»åçš„éŸ³é¢‘ï¼‰...")

                # ç¦ç”¨ç†”æ–­å™¨ï¼ˆé¿å…äºŒæ¬¡è§¦å‘ï¼‰
                circuit_breaker = None

                # ç»§ç»­è½¬å½•å‰©ä½™æ®µè½
                for idx, seg in enumerate(current_segments):
                    if idx in processed_indices:
                        continue

                    if job.canceled:
                        raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

                    if job.paused:
                        raise RuntimeError('ä»»åŠ¡å·²æš‚åœ')

                    # ç¡®ä¿segmentæœ‰indexå­—æ®µ
                    if 'index' not in seg:
                        seg['index'] = idx

                    # ä½¿ç”¨åˆ†ç¦»åçš„éŸ³é¢‘è½¬å½•
                    seg_result = self._transcribe_segment(
                        seg,
                        model,
                        job,
                        audio_array=audio_array
                    )

                    if seg_result:
                        unaligned_results.append(seg_result)
                    processed_indices.add(idx)
                    job.processed = len(processed_indices)

                    progress = len(processed_indices) / len(current_segments)
                    self._update_progress(
                        job,
                        'transcribe',
                        progress,
                        f'è½¬å½•ä¸­ï¼ˆå·²å‡çº§ï¼‰ {len(processed_indices)}/{len(current_segments)}'
                    )

                    if seg_result:
                        self._push_sse_segment(job, seg_result, len(processed_indices), len(current_segments))

                    # ä¿å­˜checkpoint
                    checkpoint_data = {
                        "job_id": job.job_id,
                        "phase": "transcribe",
                        "processing_mode": processing_mode.value,
                        "total_segments": len(current_segments),
                        "processed_indices": list(processed_indices),
                        "segments": current_segments,
                        "unaligned_results": unaligned_results
                    }
                    self._save_checkpoint(job_dir, checkpoint_data, job)

                self._update_progress(job, 'transcribe', 1, 'è½¬å½•å®Œæˆï¼ˆç†”æ–­åï¼‰')

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 7. é˜¶æ®µ4: æ‰¹æ¬¡å¯¹é½ï¼ˆä½¿ç”¨æ‰¹æ¬¡å¯¹é½+SSEè¿›åº¦æ¨é€ï¼‰
            # ==========================================
            self._update_progress(job, 'align', 0, 'å‡†å¤‡å¯¹é½...')

            # æ ¹æ®å¤„ç†æ¨¡å¼é€‰æ‹©éŸ³é¢‘æº
            if processing_mode == ProcessingMode.MEMORY and audio_array is not None:
                # å†…å­˜æ¨¡å¼ï¼šå¤ç”¨å†…å­˜æ•°ç»„ï¼ˆé¿å…é‡æ–°åŠ è½½ï¼‰
                audio_source = audio_array
                self.logger.info("å¯¹é½é˜¶æ®µï¼šå¤ç”¨å†…å­˜éŸ³é¢‘æ•°ç»„")
            else:
                # ç¡¬ç›˜æ¨¡å¼ï¼šä¼ é€’éŸ³é¢‘æ–‡ä»¶è·¯å¾„
                audio_source = str(audio_path)
                self.logger.info("å¯¹é½é˜¶æ®µï¼šä»ç£ç›˜åŠ è½½éŸ³é¢‘")

            # ä½¿ç”¨æ‰¹æ¬¡å¯¹é½æ–¹æ³•ï¼ˆæ”¯æŒSSEè¿›åº¦æ¨é€ï¼‰
            aligned_results = self._align_all_results_batched(
                unaligned_results,
                job,
                audio_source,
                processing_mode
            )

            # ã€æµå¼è¾“å‡ºã€‘æ¨é€å¯¹é½å®Œæˆäº‹ä»¶
            self._push_sse_aligned(job, aligned_results)

            if job.canceled:
                raise RuntimeError('ä»»åŠ¡å·²å–æ¶ˆ')

            # ==========================================
            # 6. é˜¶æ®µ5: ç”ŸæˆSRT
            # ==========================================
            base_name = os.path.splitext(job.filename)[0]
            srt_path = job_dir / f'{base_name}.srt'
            self._update_progress(job, 'srt', 0, 'å†™å…¥ SRT...')
            self._generate_srt(
                aligned_results,
                str(srt_path),
                job.settings.word_timestamps
            )
            self._update_progress(job, 'srt', 1, 'å¤„ç†å®Œæˆ')

            job.srt_path = str(srt_path)

            # ã€æ¸…ç†ã€‘ä»»åŠ¡æˆåŠŸå®Œæˆåï¼Œåˆ é™¤ checkpoint
            try:
                checkpoint_file = job_dir / "checkpoint.json"
                checkpoint_file.unlink(missing_ok=True)
                self.logger.info("æ£€æŸ¥ç‚¹å·²æ¸…ç†")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

            if job.canceled:
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                # æ¨é€å–æ¶ˆä¿¡å·
                self._push_sse_signal(job, "job_canceled", "ä»»åŠ¡å·²å–æ¶ˆ")
            else:
                job.status = 'finished'
                job.message = 'å®Œæˆ'
                self.logger.info(f"ä»»åŠ¡å®Œæˆ: {job.job_id}")
                # æ¨é€å®Œæˆä¿¡å·
                self._push_sse_signal(job, "job_complete", "è½¬å½•å®Œæˆ")

                # å¼‚æ­¥è§¦å‘åª’ä½“é¢„å¤„ç†ï¼ˆç”Ÿæˆæ³¢å½¢ã€ç¼©ç•¥å›¾ç­‰ï¼Œä¸ºç¼–è¾‘å™¨åšå‡†å¤‡ï¼‰
                self._trigger_media_post_process(job.job_id)

        except Exception as e:
            if job.canceled and 'å–æ¶ˆ' in str(e):
                job.status = 'canceled'
                job.message = 'å·²å–æ¶ˆ'
                self.logger.info(f"ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆ: {job.job_id}")
                # æ¨é€å–æ¶ˆä¿¡å·
                self._push_sse_signal(job, "job_canceled", "ä»»åŠ¡å·²å–æ¶ˆ")
            elif job.paused and 'æš‚åœ' in str(e):
                job.status = 'paused'
                job.message = 'å·²æš‚åœ'
                self.logger.info(f"â¸ï¸ ä»»åŠ¡å·²æš‚åœ: {job.job_id}")
                # æ¨é€æš‚åœä¿¡å·
                self._push_sse_signal(job, "job_paused", "ä»»åŠ¡å·²æš‚åœ")
            else:
                job.status = 'failed'
                job.message = f'å¤±è´¥: {e}'
                job.error = str(e)
                self.logger.error(f"ä»»åŠ¡å¤±è´¥: {job.job_id} - {e}", exc_info=True)
                # æ¨é€å¤±è´¥ä¿¡å·
                self._push_sse_signal(job, "job_failed", f"ä»»åŠ¡å¤±è´¥: {e}")

        finally:
            # æ¢å¤CPUäº²å’Œæ€§è®¾ç½®
            if cpu_applied:
                restored = self.cpu_manager.restore_cpu_affinity()
                if restored:
                    self.logger.info(f"ä»»åŠ¡ {job.job_id} å·²æ¢å¤CPUäº²å’Œæ€§è®¾ç½®")

            # é‡Šæ”¾å†…å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    # ========== æ ¸å¿ƒå¤„ç†æ–¹æ³• ==========

    def _get_audio_duration(self, audio_path: str) -> float:
        """
        è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            # æ–¹æ³•1: ä½¿ç”¨pydubï¼ˆç²¾ç¡®ä½†è¾ƒæ…¢ï¼‰
            audio = AudioSegment.from_wav(audio_path)
            duration = len(audio) / 1000.0
            self.logger.debug(f"éŸ³é¢‘æ—¶é•¿ï¼ˆpydubï¼‰: {duration:.1f}ç§’")
            return duration
        except Exception as e:
            self.logger.warning(f"pydubè·å–æ—¶é•¿å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ä¼°ç®—: {e}")
            # æ–¹æ³•2: æ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—ï¼ˆ16kHz, 16bit, mono â‰ˆ 32KB/ç§’ï¼‰
            try:
                file_size = os.path.getsize(audio_path)
                duration = file_size / 32000
                self.logger.debug(f"éŸ³é¢‘æ—¶é•¿ï¼ˆä¼°ç®—ï¼‰: {duration:.1f}ç§’")
                return duration
            except Exception as e2:
                self.logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e2}")
                return 0.0

    def _decide_processing_mode(self, audio_path: str, job: JobState) -> ProcessingMode:
        """
        æ™ºèƒ½å†³ç­–å¤„ç†æ¨¡å¼ï¼ˆå†…å­˜æ¨¡å¼ vs ç¡¬ç›˜æ¨¡å¼ï¼‰

        å†³ç­–é€»è¾‘ï¼š
        1. ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚
        2. æ£€æµ‹ç³»ç»Ÿå¯ç”¨å†…å­˜
        3. é¢„ç•™å®‰å…¨ä½™é‡ï¼ˆæ¨¡å‹ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
        4. å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            ProcessingMode: å¤„ç†æ¨¡å¼
        """
        # è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        audio_duration_sec = self._get_audio_duration(audio_path)

        # ä¼°ç®—éŸ³é¢‘å†…å­˜éœ€æ±‚ (16kHz, float32)
        # å…¬å¼: duration * 16000 * 4 bytes
        estimated_audio_mb = (audio_duration_sec * 16000 * 4) / (1024 * 1024)

        # é¢„ç•™é¢å¤–å†…å­˜ï¼ˆæ¨¡å‹åŠ è½½ã€VADå¤„ç†ã€è½¬å½•ä¸­é—´å˜é‡ç­‰ï¼‰
        # ä¿å®ˆä¼°è®¡ï¼šéŸ³é¢‘å†…å­˜çš„2å€ + 500MBåŸºç¡€å¼€é”€
        total_estimated_mb = estimated_audio_mb * 2 + 500

        # è·å–ç³»ç»Ÿå¯ç”¨å†…å­˜
        mem_info = psutil.virtual_memory()
        available_mb = mem_info.available / (1024 * 1024)
        total_mb = mem_info.total / (1024 * 1024)

        # å®‰å…¨é˜ˆå€¼ï¼šåŠ¨æ€è®¡ç®—ï¼Œç»¼åˆè€ƒè™‘å¤šç§å› ç´ 
        # 1. åŸºç¡€ä¿ç•™ï¼š2GBï¼ˆä¿è¯ç³»ç»ŸåŸºæœ¬è¿è¡Œï¼‰
        # 2. åŠ¨æ€ä¿ç•™ï¼šå¯ç”¨å†…å­˜çš„10%ï¼ˆè€Œéæ€»å†…å­˜çš„20%ï¼Œé¿å…è¿‡åº¦ä¿å®ˆï¼‰
        # 3. æœ€å¤§ä¿ç•™ä¸Šé™ï¼š4GBï¼ˆé¿å…åœ¨å¤§å†…å­˜ç³»ç»Ÿä¸Šè¿‡åº¦ä¿ç•™ï¼‰
        base_reserve_mb = 2048
        dynamic_reserve_mb = available_mb * 0.1
        safety_reserve_mb = min(base_reserve_mb + dynamic_reserve_mb, 4096)
        usable_mb = available_mb - safety_reserve_mb

        self.logger.info(f"å†…å­˜è¯„ä¼°:")
        self.logger.info(f"éŸ³é¢‘æ—¶é•¿: {audio_duration_sec/60:.1f}åˆ†é’Ÿ")
        self.logger.info(f"é¢„ä¼°éœ€æ±‚: {total_estimated_mb:.0f}MB")
        self.logger.info(f"å¯ç”¨å†…å­˜: {available_mb:.0f}MB")
        self.logger.info(f"å®‰å…¨ä½™é‡: {safety_reserve_mb:.0f}MB")
        self.logger.info(f"å¯ç”¨äºå¤„ç†: {usable_mb:.0f}MB")

        # å†³ç­–
        if usable_mb >= total_estimated_mb:
            self.logger.info("é€‰æ‹©ã€å†…å­˜æ¨¡å¼ã€‘- å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼")
            job.message = "å†…å­˜å……è¶³ï¼Œä½¿ç”¨é«˜æ€§èƒ½æ¨¡å¼"
            return ProcessingMode.MEMORY
        else:
            self.logger.warning(f"é€‰æ‹©ã€ç¡¬ç›˜æ¨¡å¼ã€‘- å†…å­˜ä¸è¶³ï¼ˆéœ€è¦{total_estimated_mb:.0f}MBï¼Œå¯ç”¨{usable_mb:.0f}MBï¼‰")
            job.message = "å†…å­˜å—é™ï¼Œä½¿ç”¨ç¨³å®šæ¨¡å¼"
            return ProcessingMode.DISK

    def _safe_load_audio(self, audio_path: str, job: JobState) -> np.ndarray:
        """
        å®‰å…¨åŠ è½½éŸ³é¢‘åˆ°å†…å­˜ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰

        ç”¨äºå†…å­˜æ¨¡å¼ä¸‹å°†å®Œæ•´éŸ³é¢‘ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¸­ã€‚
        åŒ…å«åŠ è½½éªŒè¯å’Œè¯¦ç»†çš„å¼‚å¸¸å¤„ç†ï¼ŒåŠ è½½å¤±è´¥æ—¶æŠ›å‡ºRuntimeErrorè§¦å‘é™çº§ã€‚

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡ï¼ˆç”¨äºæ›´æ–°çŠ¶æ€æ¶ˆæ¯ï¼‰

        Returns:
            np.ndarray: éŸ³é¢‘æ•°ç»„ï¼ˆfloat32, 16kHzé‡‡æ ·ç‡ï¼‰

        Raises:
            RuntimeError: éŸ³é¢‘åŠ è½½å¤±è´¥æ—¶æŠ›å‡ºï¼Œè°ƒç”¨æ–¹å¯æ®æ­¤è§¦å‘ç¡¬ç›˜æ¨¡å¼é™çº§
        """
        try:
            self.logger.info(f"åŠ è½½éŸ³é¢‘åˆ°å†…å­˜: {audio_path}")
            # ä½¿ç”¨ whisper_service æä¾›çš„ load_audio å‡½æ•°åŠ è½½éŸ³é¢‘
            audio_array = whisper_load_audio(audio_path)

            # éªŒè¯åŠ è½½ç»“æœ
            if audio_array is None or len(audio_array) == 0:
                raise ValueError("éŸ³é¢‘æ•°ç»„ä¸ºç©º")

            # è®°å½•åŠ è½½ä¿¡æ¯
            duration_sec = len(audio_array) / 16000
            memory_mb = audio_array.nbytes / (1024 * 1024)
            # Audio loaded: {duration_sec/60:.1f}åˆ†é’Ÿ")
            self.logger.info(f"å†…å­˜å ç”¨: {memory_mb:.1f}MB")
            self.logger.info(f"é‡‡æ ·ç‚¹æ•°: {len(audio_array):,}")

            return audio_array

        except MemoryError as e:
            self.logger.error(f"å†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½éŸ³é¢‘: {e}")
            job.message = "å†…å­˜ä¸è¶³ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ç¡¬ç›˜æ¨¡å¼"
            raise RuntimeError(f"å†…å­˜ä¸è¶³: {e}")

        except Exception as e:
            self.logger.error(f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            job.message = f"éŸ³é¢‘åŠ è½½å¤±è´¥: {e}"
            raise RuntimeError(f"éŸ³é¢‘åŠ è½½å¤±è´¥ï¼ˆå¯èƒ½æ–‡ä»¶æŸåï¼‰: {e}")

    # ==========================================
    # Demucs äººå£°åˆ†ç¦»ç›¸å…³æ–¹æ³•
    # ==========================================

    def _detect_bgm(self, audio_path: str, job: JobState):
        """
        æ‰§è¡ŒBGMæ£€æµ‹ï¼Œæ›´æ–°è¿›åº¦
        
        ã€v2.1 é‡æ„ã€‘ä½¿ç”¨é¢‘è°±åˆ†è¯Šæ›¿ä»£æ—§çš„åˆ†ä½æ•°é‡‡æ · + Demucs æ£€æµ‹
        æ–°æ–¹æ³•ï¼šçº¯é¢‘è°±ç‰¹å¾åˆ†æï¼Œæ— éœ€è¿è¡Œ Demucsï¼Œé€Ÿåº¦æ›´å¿«ä¸”æ›´å‡†ç¡®

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            Tuple[BGMLevel, List[float]]: (BGMå¼ºåº¦çº§åˆ«, å„é‡‡æ ·ç‚¹çš„éŸ³ä¹å¾—åˆ†åˆ—è¡¨)
        """
        from app.services.demucs_service import BGMLevel
        from app.services.audio_spectrum_classifier import get_spectrum_classifier
        import librosa

        self._update_progress(job, 'bgm_detect', 0, 'BGMæ£€æµ‹ä¸­ï¼ˆé¢‘è°±åˆ†è¯Šï¼‰...')

        try:
            # åŠ è½½éŸ³é¢‘
            audio_array, sr = librosa.load(audio_path, sr=16000)
            
            # ä½¿ç”¨é¢‘è°±åˆ†è¯Šå™¨è¿›è¡Œå¿«é€Ÿå…¨å±€é¢„åˆ¤
            spectrum_classifier = get_spectrum_classifier()
            level_str, avg_score = spectrum_classifier.quick_global_diagnosis(
                audio_array, sr=sr, sample_duration=10.0
            )
            
            # è½¬æ¢ä¸º BGMLevel æšä¸¾
            level_map = {
                "none": BGMLevel.NONE,
                "light": BGMLevel.LIGHT,
                "heavy": BGMLevel.HEAVY,
                "unknown": BGMLevel.LIGHT  # unknown ä¿å®ˆå¤„ç†ä¸º light
            }
            level = level_map.get(level_str, BGMLevel.LIGHT)
            
            # æ„é€ å…¼å®¹çš„ ratios åˆ—è¡¨ï¼ˆç”¨äºæ—¥å¿—å’Œ SSEï¼‰
            # é¢‘è°±åˆ†è¯Šè¿”å›çš„æ˜¯éŸ³ä¹å¾—åˆ†ï¼Œè¿™é‡Œç”¨ avg_score å¡«å……
            ratios = [avg_score, avg_score, avg_score]

            self._update_progress(job, 'bgm_detect', 1, f'BGMæ£€æµ‹å®Œæˆ: {level.value}')

            # æ¨é€SSEäº‹ä»¶
            self._push_sse_bgm_detected(job, level, ratios)

            self.logger.info(
                f"BGMæ£€æµ‹ç»“æœï¼ˆé¢‘è°±åˆ†è¯Šï¼‰: {level.value}, "
                f"éŸ³ä¹å¾—åˆ†={avg_score:.2f}"
            )

            return level, ratios

        except Exception as e:
            self.logger.warning(f"BGMæ£€æµ‹å¤±è´¥ï¼Œå°†è·³è¿‡Demucs: {e}")
            # å¤±è´¥æ—¶è¿”å› NONE çº§åˆ«ï¼Œä¸å½±å“ä¸»æµç¨‹
            from app.services.demucs_service import BGMLevel
            return BGMLevel.NONE, []
    
    def _detect_bgm_legacy(self, audio_path: str, job: JobState):
        """
        [å·²åºŸå¼ƒ] æ‰§è¡ŒBGMæ£€æµ‹ï¼ˆæ—§ç‰ˆï¼šåˆ†ä½æ•°é‡‡æ · + Demucs æ£€æµ‹ï¼‰
        
        âš ï¸ æ­¤æ–¹æ³•å·²åºŸå¼ƒï¼Œä¿ç•™ä¾›å‚è€ƒå’Œå›é€€ä½¿ç”¨
        é—®é¢˜ï¼šDemucs åˆ†ç¦»æ®‹å·®çº¦ 1-3%ï¼Œå¯¼è‡´çº¯äººå£°ä¹Ÿè¢«è¯¯åˆ¤ä¸º light
        
        æ–°æ–¹æ³•è¯·ä½¿ç”¨ _detect_bgm()ï¼ˆé¢‘è°±åˆ†è¯Šç‰ˆæœ¬ï¼‰

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            Tuple[BGMLevel, List[float]]: (BGMå¼ºåº¦çº§åˆ«, å„é‡‡æ ·ç‚¹çš„BGMæ¯”ä¾‹åˆ—è¡¨)
        """
        from app.services.demucs_service import get_demucs_service, BGMLevel

        self._update_progress(job, 'bgm_detect', 0, 'BGMæ£€æµ‹ä¸­...')

        try:
            demucs = get_demucs_service()

            # æ‰§è¡ŒBGMæ£€æµ‹ï¼ˆæ—§ç‰ˆï¼šåˆ†ä½æ•°é‡‡æ ·ï¼‰
            level, ratios = demucs.detect_background_music_level(audio_path)

            self._update_progress(job, 'bgm_detect', 1, f'BGMæ£€æµ‹å®Œæˆ: {level.value}')

            # æ¨é€SSEäº‹ä»¶
            self._push_sse_bgm_detected(job, level, ratios)

            self.logger.info(
                f"BGMæ£€æµ‹ç»“æœ: {level.value}, "
                f"æ¯”ä¾‹={ratios}, æœ€å¤§={max(ratios) if ratios else 0:.2f}"
            )

            return level, ratios

        except Exception as e:
            self.logger.warning(f"BGMæ£€æµ‹å¤±è´¥ï¼Œå°†è·³è¿‡Demucs: {e}")
            # å¤±è´¥æ—¶è¿”å› NONE çº§åˆ«ï¼Œä¸å½±å“ä¸»æµç¨‹
            from app.services.demucs_service import BGMLevel
            return BGMLevel.NONE, []

    def _separate_vocals_global(self, audio_path: str, job: JobState) -> str:
        """
        æ‰§è¡Œå…¨å±€äººå£°åˆ†ç¦»ï¼Œæ›´æ–°è¿›åº¦

        Args:
            audio_path: åŸå§‹éŸ³é¢‘è·¯å¾„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            str: åˆ†ç¦»åçš„äººå£°æ–‡ä»¶è·¯å¾„
        """
        from app.services.demucs_service import get_demucs_service

        self._update_progress(job, 'demucs_global', 0, 'äººå£°åˆ†ç¦»ä¸­...')

        try:
            demucs = get_demucs_service()

            def progress_callback(progress: float, message: str):
                """è¿›åº¦å›è°ƒ"""
                self._update_progress(job, 'demucs_global', progress, message)

            # æ‰§è¡Œäººå£°åˆ†ç¦»
            vocals_path = demucs.separate_vocals(
                audio_path,
                progress_callback=progress_callback
            )

            self._update_progress(job, 'demucs_global', 1, 'äººå£°åˆ†ç¦»å®Œæˆ')
            self.logger.info(f"å…¨å±€äººå£°åˆ†ç¦»å®Œæˆ: {vocals_path}")

            return vocals_path

        except Exception as e:
            self.logger.error(f"äººå£°åˆ†ç¦»å¤±è´¥: {e}")
            # åˆ†ç¦»å¤±è´¥æ—¶è¿”å›åŸå§‹éŸ³é¢‘è·¯å¾„ï¼ˆé™çº§å¤„ç†ï¼‰
            self.logger.warning("äººå£°åˆ†ç¦»å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå§‹éŸ³é¢‘ç»§ç»­å¤„ç†")
            return audio_path

    def _push_sse_bgm_detected(self, job: JobState, level, ratios):
        """
        æ¨é€BGMæ£€æµ‹ç»“æœäº‹ä»¶

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            level: BGMå¼ºåº¦çº§åˆ«
            ratios: å„é‡‡æ ·ç‚¹çš„BGMæ¯”ä¾‹åˆ—è¡¨
        """
        try:
            from app.services.sse_service import get_sse_manager

            sse_manager = get_sse_manager()
            channel_id = f"job:{job.job_id}"

            # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œé¿å…JSONåºåˆ—åŒ–é”™è¯¯
            native_ratios = [float(r) for r in ratios] if ratios else []
            max_ratio = float(max(ratios)) if ratios else 0.0

            # æ„é€ äº‹ä»¶æ•°æ®
            event_data = {
                "level": level.value,
                "ratios": native_ratios,
                "max_ratio": max_ratio,
                "recommendation": self._get_demucs_recommendation(level)
            }

            # å¹¿æ’­äº‹ä»¶
            sse_manager.broadcast_sync(channel_id, "signal.bgm_detected", event_data)

        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            self.logger.debug(f"SSEæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _push_sse_separation_strategy(self, job: JobState, strategy):
        """
        æ¨é€åˆ†ç¦»ç­–ç•¥å†³ç­–äº‹ä»¶

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            strategy: SeparationStrategy å¯¹è±¡
        """
        try:
            from app.services.sse_service import get_sse_manager

            sse_manager = get_sse_manager()
            channel_id = f"job:{job.job_id}"

            # ä½¿ç”¨ strategy.to_dict() è·å–äº‹ä»¶æ•°æ®
            event_data = strategy.to_dict()

            # å¹¿æ’­äº‹ä»¶
            sse_manager.broadcast_sync(channel_id, "signal.separation_strategy", event_data)

            self.logger.debug(f"åˆ†ç¦»ç­–ç•¥äº‹ä»¶å·²æ¨é€: {strategy.reason}")

        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            self.logger.debug(f"SSEæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _push_sse_model_escalated(
        self,
        job: JobState,
        from_model: str,
        to_model: str,
        reason: str,
        breaker_state: CircuitBreakerState
    ):
        """
        æ¨é€æ¨¡å‹å‡çº§äº‹ä»¶

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            from_model: åŸæ¨¡å‹åç§°
            to_model: æ–°æ¨¡å‹åç§°
            reason: å‡çº§åŸå› 
            breaker_state: ç†”æ–­å™¨çŠ¶æ€
        """
        try:
            from app.services.sse_service import get_sse_manager

            sse_manager = get_sse_manager()
            channel_id = f"job:{job.job_id}"

            # æ„é€ äº‹ä»¶æ•°æ® (ä½¿ç”¨ ConfigAdapter å…¼å®¹æ–°æ—§é…ç½®)
            event_data = {
                "from_model": from_model,
                "to_model": to_model,
                "reason": reason,
                "escalation_count": breaker_state.escalation_count,
                "max_escalations": ConfigAdapter.get_max_escalations(job.settings),
                "stats": breaker_state.get_stats()
            }

            # å¹¿æ’­äº‹ä»¶
            sse_manager.broadcast_sync(channel_id, "signal.model_upgrade", event_data)

            self.logger.info(f"æ¨¡å‹å‡çº§äº‹ä»¶å·²æ¨é€: {from_model} -> {to_model}")

        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            self.logger.debug(f"SSEæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _push_sse_circuit_breaker_triggered(
        self,
        job: JobState,
        circuit_breaker: Optional[CircuitBreakerState]
    ):
        """
        æ¨é€ç†”æ–­è§¦å‘äº‹ä»¶ï¼ˆPhase 4: æ‰©å±•åŒ…å«å‡çº§ä¿¡æ¯ï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            circuit_breaker: ç†”æ–­å™¨çŠ¶æ€å¯¹è±¡
        """
        try:
            from app.services.sse_service import get_sse_manager

            sse_manager = get_sse_manager()
            channel_id = f"job:{job.job_id}"

            # æ„é€ äº‹ä»¶æ•°æ®ï¼ˆæ‰©å±•åŒ…å«å‡çº§å†å²ï¼‰
            stats = circuit_breaker.get_stats() if circuit_breaker else {}
            event_data = {
                "triggered": True,
                "reason": self._get_circuit_break_reason(circuit_breaker),
                "stats": stats,
                "action": "å‡çº§ä¸ºå…¨å±€äººå£°åˆ†ç¦»æ¨¡å¼"
            }

            # å¹¿æ’­äº‹ä»¶
            sse_manager.broadcast_sync(channel_id, "signal.circuit_breaker", event_data)

            self.logger.info("ç†”æ–­äº‹ä»¶å·²æ¨é€åˆ°å‰ç«¯")

        except Exception as e:
            # SSEæ¨é€å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            self.logger.debug(f"SSEæ¨é€å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")

    def _get_circuit_break_reason(self, circuit_breaker: Optional[CircuitBreakerState]) -> str:
        """
        ç”Ÿæˆç†”æ–­åŸå› æè¿°

        Args:
            circuit_breaker: ç†”æ–­å™¨çŠ¶æ€

        Returns:
            ç†”æ–­åŸå› æè¿°å­—ç¬¦ä¸²
        """
        if not circuit_breaker:
            return "è½¬å½•è´¨é‡ä½ï¼Œè§¦å‘ç†”æ–­å‡çº§"

        stats = circuit_breaker.get_stats()

        # å¦‚æœæœ‰å‡çº§å†å²ï¼Œè¯´æ˜å·²ç»å°è¯•è¿‡å‡çº§
        if circuit_breaker.escalation_count > 0:
            return (
                f"å·²å‡çº§ {circuit_breaker.escalation_count} æ¬¡æ¨¡å‹ä»æœªæ”¹å–„ï¼Œè§¦å‘ç†”æ–­ã€‚"
                f"å‡çº§å†å²: {', '.join(circuit_breaker.escalation_history)}"
            )
        else:
            return (
                f"è¿ç»­ {stats['consecutive_retries']} ä¸ªæ®µè½é‡è¯•å¤±è´¥ï¼Œ"
                f"æ€»é‡è¯•ç‡ {stats['retry_ratio']:.1%}ï¼Œè§¦å‘ç†”æ–­"
            )

    def _get_demucs_recommendation(self, level) -> str:
        """
        æ ¹æ®BGMçº§åˆ«è¿”å›å»ºè®®çš„å¤„ç†æ¨¡å¼

        Args:
            level: BGMå¼ºåº¦çº§åˆ«

        Returns:
            str: å»ºè®®çš„å¤„ç†æ¨¡å¼æè¿°
        """
        from app.services.demucs_service import BGMLevel

        if level == BGMLevel.HEAVY:
            return "å…¨å±€åˆ†ç¦»"
        elif level == BGMLevel.LIGHT:
            return "æŒ‰éœ€åˆ†ç¦»"
        else:
            return "æ— éœ€åˆ†ç¦»"

    # ==========================================
    # æŒ‰éœ€åˆ†ç¦»ä¸ç†”æ–­æœºåˆ¶ç›¸å…³æ–¹æ³•
    # ==========================================

    def _check_transcription_confidence(
        self,
        result: Dict,
        logprob_threshold: float,
        no_speech_threshold: float
    ) -> bool:
        """
        æ£€æŸ¥è½¬å½•ç»“æœçš„ç½®ä¿¡åº¦

        Args:
            result: è½¬å½•ç»“æœå­—å…¸
            logprob_threshold: logprobé˜ˆå€¼ï¼ˆä½äºæ­¤å€¼éœ€è¦é‡è¯•ï¼‰
            no_speech_threshold: no_speech_probé˜ˆå€¼ï¼ˆé«˜äºæ­¤å€¼éœ€è¦é‡è¯•ï¼‰

        Returns:
            bool: Trueè¡¨ç¤ºç½®ä¿¡åº¦ä½ï¼Œéœ€è¦é‡è¯•
        """
        segments = result.get('segments', [])

        if not segments:
            return True  # æ²¡æœ‰è¯†åˆ«å‡ºå†…å®¹ï¼Œéœ€è¦é‡è¯•

        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        total_logprob = 0
        total_no_speech = 0
        count = 0

        for seg in segments:
            if 'avg_logprob' in seg:
                total_logprob += seg['avg_logprob']
                count += 1
            if 'no_speech_prob' in seg:
                total_no_speech += seg['no_speech_prob']

        if count == 0:
            return False  # æ²¡æœ‰ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œä¸é‡è¯•

        avg_logprob = total_logprob / count
        avg_no_speech = total_no_speech / count if count > 0 else 0

        # åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è¯•
        if avg_logprob < logprob_threshold:
            self.logger.debug(f"avg_logprob={avg_logprob:.2f} < {logprob_threshold}, éœ€è¦é‡è¯•")
            return True

        if avg_no_speech > no_speech_threshold:
            self.logger.debug(f"no_speech_prob={avg_no_speech:.2f} > {no_speech_threshold}, éœ€è¦é‡è¯•")
            return True

        return False

    def _is_better_result(self, new_result: Dict, old_result: Dict) -> bool:
        """
        æ¯”è¾ƒä¸¤ä¸ªè½¬å½•ç»“æœï¼Œåˆ¤æ–­æ–°ç»“æœæ˜¯å¦æ›´å¥½

        Args:
            new_result: æ–°çš„è½¬å½•ç»“æœ
            old_result: æ—§çš„è½¬å½•ç»“æœ

        Returns:
            bool: Trueè¡¨ç¤ºæ–°ç»“æœæ›´å¥½
        """
        new_segments = new_result.get('segments', [])
        old_segments = old_result.get('segments', [])

        # å¦‚æœæ–°ç»“æœæ²¡æœ‰å†…å®¹ï¼Œæ—§çš„æ›´å¥½
        if not new_segments:
            return False

        # å¦‚æœæ—§ç»“æœæ²¡æœ‰å†…å®¹ï¼Œæ–°çš„æ›´å¥½
        if not old_segments:
            return True

        # æ¯”è¾ƒå¹³å‡logprob
        def get_avg_logprob(segments):
            logprobs = [s.get('avg_logprob', -1) for s in segments if 'avg_logprob' in s]
            return np.mean(logprobs) if logprobs else -1

        new_logprob = get_avg_logprob(new_segments)
        old_logprob = get_avg_logprob(old_segments)

        # æ–°ç»“æœçš„logprobæ›´é«˜ï¼ˆæ›´æ¥è¿‘0ï¼‰åˆ™æ›´å¥½
        return new_logprob > old_logprob

    def _transcribe_segment_with_retry(
        self,
        seg_meta: Dict,
        model,
        job: JobState,
        audio_array: Optional[np.ndarray] = None,
        circuit_breaker: Optional[CircuitBreakerState] = None
    ) -> Optional[Dict]:
        """
        å¸¦é‡è¯•çš„è½¬å½•æ–¹æ³•ï¼ˆæ”¯æŒDemucsäººå£°åˆ†ç¦»é‡è¯• + åŠ¨æ€ç†”æ–­ï¼‰

        æµç¨‹ï¼š
        1. é¦–æ¬¡è½¬å½•ï¼ˆä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼‰
        2. æ£€æŸ¥ç½®ä¿¡åº¦
        3. å¦‚æœç½®ä¿¡åº¦ä½ï¼Œä½¿ç”¨Demucsåˆ†ç¦»äººå£°åé‡è¯•
        4. æ›´æ–°ç†”æ–­å™¨çŠ¶æ€
        5. æ£€æŸ¥æ˜¯å¦è§¦å‘ç†”æ–­
        6. è¿”å›ç½®ä¿¡åº¦æ›´é«˜çš„ç»“æœ

        Args:
            seg_meta: æ®µè½å…ƒæ•°æ®
            model: Whisperæ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
            circuit_breaker: ç†”æ–­å™¨çŠ¶æ€å¯¹è±¡

        Returns:
            Optional[Dict]: è½¬å½•ç»“æœ

        Raises:
            BreakToGlobalSeparation: å½“è§¦å‘ç†”æ–­æ¡ä»¶æ—¶æŠ›å‡º
        """
        demucs_settings = job.settings.demucs

        # é¦–æ¬¡è½¬å½•
        result = self._transcribe_segment(seg_meta, model, job, audio_array)

        if not result or not demucs_settings.enabled:
            if circuit_breaker:
                circuit_breaker.record_success()
            return result

        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
        needs_retry = self._check_transcription_confidence(
            result,
            demucs_settings.retry_threshold_logprob,
            demucs_settings.retry_threshold_no_speech
        )

        if not needs_retry:
            # ä¸éœ€è¦é‡è¯•ï¼Œè®°å½•æˆåŠŸ
            if circuit_breaker:
                circuit_breaker.record_success()
            return result

        # ========== éœ€è¦é‡è¯•çš„é€»è¾‘ ==========
        self.logger.info(f"æ®µè½ {seg_meta['index']} ç½®ä¿¡åº¦ä½ï¼Œå°è¯•äººå£°åˆ†ç¦»é‡è¯•")

        # æ›´æ–°ç†”æ–­å™¨çŠ¶æ€
        if circuit_breaker:
            circuit_breaker.record_retry()

            # æ£€æŸ¥æ˜¯å¦è§¦å‘ç†”æ–­
            if circuit_breaker.should_break(demucs_settings):
                stats = circuit_breaker.get_stats()
                self.logger.warning(
                    f"è§¦å‘ç†”æ–­ï¼è¿ç»­é‡è¯•={stats['consecutive_retries']}, "
                    f"æ€»é‡è¯•æ¯”ä¾‹={stats['retry_ratio']:.1%}"
                )
                raise BreakToGlobalSeparation(
                    f"è¿ç»­{stats['consecutive_retries']}æ®µéœ€è¦Demucsé‡è¯•ï¼Œ"
                    f"å»ºè®®å‡çº§ä¸ºå…¨å±€äººå£°åˆ†ç¦»æ¨¡å¼"
                )

        # å°è¯•æŒ‰éœ€åˆ†ç¦»
        try:
            from app.services.demucs_service import get_demucs_service
            demucs = get_demucs_service()

            start_sec = seg_meta['start']
            end_sec = seg_meta['end']

            if audio_array is not None:
                # å†…å­˜æ¨¡å¼ï¼šåˆ†ç¦»äººå£°
                vocals = demucs.separate_vocals_segment(
                    audio_array, sr=16000,
                    start_sec=start_sec, end_sec=end_sec
                )

                # æ„é€ ä¸´æ—¶seg_meta
                retry_seg = seg_meta.copy()
                retry_seg['start'] = 0  # å› ä¸ºvocalså·²ç»æ˜¯åˆ‡ç‰‡
                retry_seg['end'] = len(vocals) / 16000

                # é‡æ–°è½¬å½•
                retry_result = self._transcribe_segment_in_memory(
                    vocals,
                    retry_seg,
                    model,
                    job,
                    is_vocals=True  # æ ‡è®°æ˜¯äººå£°
                )
            else:
                # ç¡¬ç›˜æ¨¡å¼ï¼šæš‚ä¸æ”¯æŒ
                self.logger.warning("ç¡¬ç›˜æ¨¡å¼æš‚ä¸æ”¯æŒDemucsé‡è¯•")
                return result

            if retry_result:
                # æ ¡æ­£æ—¶é—´åç§»ï¼ˆæ¢å¤åˆ°åŸå§‹æ—¶é—´è½´ï¼‰
                original_start = seg_meta['start']
                for seg in retry_result.get('segments', []):
                    seg['start'] += original_start
                    seg['end'] += original_start

                # æ¯”è¾ƒä¸¤æ¬¡ç»“æœï¼Œè¿”å›æ›´å¥½çš„
                if self._is_better_result(retry_result, result):
                    self.logger.info(f"æ®µè½ {seg_meta['index']} é‡è¯•æˆåŠŸï¼Œä½¿ç”¨åˆ†ç¦»åçš„ç»“æœ")
                    retry_result['used_demucs'] = True
                    return retry_result

        except Exception as e:
            self.logger.warning(f"Demucsé‡è¯•å¤±è´¥: {e}")

        return result

    def _get_model(self, settings: JobSettings, job: Optional[JobState] = None):
        """
        è·å– Faster-Whisper æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼‰

        ä¼˜å…ˆä½¿ç”¨æ¨¡å‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹ï¼Œå¦åˆ™ä½¿ç”¨ç®€å•ç¼“å­˜

        Args:
            settings: ä»»åŠ¡è®¾ç½®
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡(å¯é€‰,ç”¨äºæ›´æ–°ä¸‹è½½è¿›åº¦)

        Returns:
            æ¨¡å‹å¯¹è±¡
        """
        # å°è¯•ä½¿ç”¨æ¨¡å‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹
        try:
            from app.services.model_manager_service import get_model_manager
            model_mgr = get_model_manager()
            whisper_model_info = model_mgr.whisper_models.get(settings.model)

            if whisper_model_info:
                # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
                if whisper_model_info.status == "not_downloaded" or whisper_model_info.status == "incomplete":
                    self.logger.warning(f"Whisperæ¨¡å‹æœªä¸‹è½½æˆ–ä¸å®Œæ•´: {settings.model}")

                    # è·å–æ¨¡å‹å¤§å°ä¿¡æ¯
                    model_size_mb = whisper_model_info.size_mb

                    # å¦‚æœæ¨¡å‹å¤§å°>=1GB,ç»™å‡ºç‰¹æ®Šæç¤º
                    download_msg = ""
                    if model_size_mb >= 1024:
                        size_gb = model_size_mb / 1024
                        download_msg = f"å½“å‰ä¸‹è½½æ¨¡å‹å¤§äº1GB ({size_gb:.1f}GB),è¯·è€å¿ƒç­‰å¾…"
                        self.logger.info(f"{download_msg}")
                    else:
                        download_msg = f"å¼€å§‹ä¸‹è½½æ¨¡å‹ {settings.model} ({model_size_mb}MB)"

                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    if job:
                        job.message = download_msg

                    self.logger.info(f"è‡ªåŠ¨è§¦å‘ä¸‹è½½Whisperæ¨¡å‹: {settings.model} ({model_size_mb}MB)")

                    # è§¦å‘ä¸‹è½½
                    success = model_mgr.download_whisper_model(settings.model)
                    if not success:
                        self.logger.warning(f"æ¨¡å‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥æˆ–å·²åœ¨ä¸‹è½½ä¸­,ä½¿ç”¨å¤‡ç”¨æ–¹å¼")
                        raise RuntimeError("æ¨¡å‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥")

                    # ç­‰å¾…ä¸‹è½½å®Œæˆï¼ˆæœ€å¤šç­‰å¾…10åˆ†é’Ÿï¼‰
                    import time
                    max_wait_time = 600  # 10åˆ†é’Ÿ
                    wait_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                    elapsed = 0

                    while elapsed < max_wait_time:
                        time.sleep(wait_interval)
                        elapsed += wait_interval

                        current_status = model_mgr.whisper_models[settings.model].status
                        progress = model_mgr.whisper_models[settings.model].download_progress

                        if current_status == "ready":
                            self.logger.info(f"Whisperæ¨¡å‹ä¸‹è½½å®Œæˆ: {settings.model}")
                            if job:
                                job.message = f"æ¨¡å‹ä¸‹è½½å®Œæˆ,å‡†å¤‡åŠ è½½"
                            break
                        elif current_status == "error":
                            self.logger.error(f"æ¨¡å‹ç®¡ç†å™¨ä¸‹è½½å¤±è´¥,ä½¿ç”¨å¤‡ç”¨æ–¹å¼")
                            raise RuntimeError(f"Whisperæ¨¡å‹ä¸‹è½½å¤±è´¥: {settings.model}")
                        else:
                            # å¦‚æœæ¨¡å‹å¤§å°>=1GB,å®šæœŸæé†’ç”¨æˆ·è€å¿ƒç­‰å¾…
                            if model_size_mb >= 1024 and elapsed % 30 == 0:  # æ¯30ç§’æé†’ä¸€æ¬¡
                                wait_msg = f"å½“å‰ä¸‹è½½æ¨¡å‹å¤§äº1GB,è¯·è€å¿ƒç­‰å¾…... {progress:.1f}% ({elapsed}s/{max_wait_time}s)"
                                self.logger.info(f"{wait_msg}")
                                if job:
                                    job.message = wait_msg
                            else:
                                wait_msg = f"ç­‰å¾…æ¨¡å‹ä¸‹è½½... {progress:.1f}%"
                                self.logger.info(f"{wait_msg} ({elapsed}s/{max_wait_time}s)")
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€(æ¯æ¬¡éƒ½æ›´æ–°,è¿™æ ·ç”¨æˆ·å¯ä»¥çœ‹åˆ°è¿›åº¦å˜åŒ–)
                                if job:
                                    job.message = wait_msg

                    if elapsed >= max_wait_time:
                        self.logger.error(f"æ¨¡å‹ä¸‹è½½è¶…æ—¶,ä½¿ç”¨å¤‡ç”¨æ–¹å¼")
                        raise TimeoutError(f"Whisperæ¨¡å‹ä¸‹è½½è¶…æ—¶: {settings.model}")

        except Exception as e:
            self.logger.warning(f"æ¨¡å‹ç®¡ç†æœåŠ¡æ£€æŸ¥å¤±è´¥,ä½¿ç”¨å¤‡ç”¨æ–¹å¼: {e}")

        # å°è¯•ä½¿ç”¨æ¨¡å‹é¢„åŠ è½½ç®¡ç†å™¨
        try:
            from app.services.model_preload_manager import get_model_manager as get_preload_manager
            model_manager = get_preload_manager()
            if model_manager:
                self.logger.debug("ä½¿ç”¨æ¨¡å‹é¢„åŠ è½½ç®¡ç†å™¨è·å–æ¨¡å‹")
                if job:
                    job.message = "åŠ è½½æ¨¡å‹ä¸­"
                return model_manager.get_model(settings)
        except Exception as e:
            self.logger.debug(f"æ— æ³•ä½¿ç”¨æ¨¡å‹é¢„åŠ è½½ç®¡ç†å™¨ï¼Œå›é€€åˆ°æœ¬åœ°ç¼“å­˜: {e}")
            pass

        # å›é€€åˆ°ç®€å•ç¼“å­˜æœºåˆ¶
        key = (settings.model, settings.compute_type, settings.device)
        with _model_lock:
            if key in _model_cache:
                self.logger.debug(f"å‘½ä¸­æ¨¡å‹ç¼“å­˜: {key}")
                if job:
                    job.message = "ä½¿ç”¨ç¼“å­˜çš„æ¨¡å‹"
                return _model_cache[key]

            self.logger.info(f"åŠ è½½æ¨¡å‹: {key}")
            if job:
                job.message = f"åŠ è½½æ¨¡å‹ {settings.model}"

            # é¦–å…ˆå°è¯•ä»…ä½¿ç”¨æœ¬åœ°æ–‡ä»¶ (ä½¿ç”¨ Faster-Whisper)
            try:
                from app.core.config import config
                from faster_whisper import WhisperModel
                m = WhisperModel(
                    settings.model,
                    device=settings.device,
                    compute_type=settings.compute_type,
                    download_root=str(config.HF_CACHE_DIR),
                    local_files_only=True  # ç¦æ­¢è‡ªåŠ¨ä¸‹è½½ï¼Œåªä½¿ç”¨æœ¬åœ°æ–‡ä»¶
                )
                _model_cache[key] = m
                if job:
                    job.message = "æ¨¡å‹åŠ è½½å®Œæˆ"
                return m
            except Exception as e:
                self.logger.warning(f"æœ¬åœ°åŠ è½½å¤±è´¥,å…è®¸ä¸‹è½½: {e}")
                if job:
                    job.message = "æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨,æ­£åœ¨ä¸‹è½½"
                # å¦‚æœæœ¬åœ°åŠ è½½å¤±è´¥,å…è®¸ä¸‹è½½
                m = WhisperModel(
                    settings.model,
                    device=settings.device,
                    compute_type=settings.compute_type,
                    download_root=str(config.HF_CACHE_DIR),
                    local_files_only=False  # å…è®¸ä¸‹è½½
                )
                _model_cache[key] = m
                if job:
                    job.message = "æ¨¡å‹ä¸‹è½½å¹¶åŠ è½½å®Œæˆ"
                return m

  
    def _transcribe_segment_unaligned(
        self,
        seg: Dict,
        model,
        job: JobState
    ) -> Optional[Dict]:
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ®µï¼ˆä»…è½¬å½•ï¼Œä¸å¯¹é½ï¼‰

        Args:
            seg: æ®µä¿¡æ¯ {file, start_ms, duration_ms, index}
            model: Faster-Whisper æ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
            {
                "segment_index": 0,
                "language": "zh",
                "segments": [{"id": 0, "start": 10.5, "end": 15.2, "text": "..."}]
            }
        """
        # ä½¿ç”¨ whisper_service æä¾›çš„ load_audio å‡½æ•°
        audio = whisper_load_audio(seg['file'])

        try:
            # ä½¿ç”¨ Faster-Whisper è½¬å½•
            segments_gen, info = model.transcribe(
                audio,
                language=job.language,
                beam_size=5,
                vad_filter=True
            )

            # è½¬æ¢ç”Ÿæˆå™¨ä¸ºåˆ—è¡¨
            segments_list = list(segments_gen)

            if not segments_list:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and info.language:
                job.language = info.language
                self.logger.info(f"æ£€æµ‹åˆ°è¯­è¨€: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆé’ˆå¯¹ç²—ç•¥æ—¶é—´æˆ³ï¼‰
            start_offset = seg['start_ms'] / 1000.0
            adjusted_segments = []

            for idx, s in enumerate(segments_list):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.start + start_offset,
                    'end': s.end + start_offset,
                    'text': s.text.strip()
                })

            return {
                'segment_index': seg.get('index', 0),
                'language': info.language or job.language,
                'segments': adjusted_segments
            }

        finally:
            del audio
            gc.collect()

    def _transcribe_segment_in_memory(
        self,
        audio_array: np.ndarray,
        seg_meta: Dict,
        model,
        job: JobState,
        is_vocals: bool = False
    ) -> Optional[Dict]:
        """
        ä»å†…å­˜åˆ‡ç‰‡è½¬å½•ï¼ˆZero-copyï¼Œé«˜æ€§èƒ½ï¼‰

        å†…å­˜æ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œç›´æ¥ä»å®Œæ•´éŸ³é¢‘æ•°ç»„ä¸­åˆ‡ç‰‡ï¼Œæ— éœ€ç£ç›˜IOã€‚

        Args:
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            seg_meta: åˆ†æ®µå…ƒæ•°æ® {"index": 0, "start": 0.0, "end": 30.5, "mode": "memory"}
            model: Faster-Whisper æ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€
            is_vocals: æ˜¯å¦æ˜¯Demucsåˆ†ç¦»åçš„äººå£°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
        """
        sr = 16000
        start_sample = int(seg_meta['start'] * sr)
        end_sample = int(seg_meta['end'] * sr)

        # Zero-copyåˆ‡ç‰‡ï¼ˆnumpy viewï¼Œä¸å¤åˆ¶æ•°æ®ï¼‰
        audio_slice = audio_array[start_sample:end_sample]

        try:
            # ä½¿ç”¨ Faster-Whisper è½¬å½•
            segments_gen, info = model.transcribe(
                audio_slice,
                language=job.language,
                beam_size=5,
                vad_filter=False  # å·²ç»æ˜¯åˆ‡ç‰‡ï¼Œä¸éœ€è¦å†åš VAD
            )

            # è½¬æ¢ç”Ÿæˆå™¨ä¸ºåˆ—è¡¨
            segments_list = list(segments_gen)

            if not segments_list:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and info.language:
                job.language = info.language
                self.logger.info(f"detected language: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£
            start_offset = seg_meta['start']
            adjusted_segments = []

            for idx, s in enumerate(segments_list):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.start + start_offset,
                    'end': s.end + start_offset,
                    'text': s.text.strip()
                })

            return {
                'segment_index': seg_meta['index'],
                'language': info.language or job.language,
                'segments': adjusted_segments
            }

        finally:
            # æ³¨æ„ï¼šaudio_sliceæ˜¯viewï¼Œä¸éœ€è¦å•ç‹¬é‡Šæ”¾
            gc.collect()

    def _transcribe_segment_from_disk(
        self,
        seg: Dict,
        model,
        job: JobState
    ) -> Optional[Dict]:
        """
        ä»æ–‡ä»¶åŠ è½½è½¬å½•ï¼ˆç¡¬ç›˜æ¨¡å¼ï¼‰

        ç¡¬ç›˜æ¨¡å¼ä¸‹ä½¿ç”¨ï¼Œä»segmentæ–‡ä»¶åŠ è½½éŸ³é¢‘è¿›è¡Œè½¬å½•ã€‚

        Args:
            seg: åˆ†æ®µä¿¡æ¯ {"index": 0, "file": "segment_0.wav", "start": 0.0, "end": 30.0, "mode": "disk"}
            model: Faster-Whisper æ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
        """
        # ä½¿ç”¨ whisper_service æä¾›çš„ load_audio å‡½æ•°
        audio = whisper_load_audio(seg['file'])

        try:
            # ä½¿ç”¨ Faster-Whisper è½¬å½•
            segments_gen, info = model.transcribe(
                audio,
                language=job.language,
                beam_size=5,
                vad_filter=True
            )

            # è½¬æ¢ç”Ÿæˆå™¨ä¸ºåˆ—è¡¨
            segments_list = list(segments_gen)

            if not segments_list:
                return None

            # æ£€æµ‹è¯­è¨€ï¼ˆé¦–æ¬¡ï¼‰
            if not job.language and info.language:
                job.language = info.language
                self.logger.info(f"detected language: {job.language}")

            # æ—¶é—´åç§»æ ¡æ­£ï¼ˆä½¿ç”¨startå­—æ®µï¼Œç§’ä¸ºå•ä½ï¼‰
            start_offset = seg.get('start', seg.get('start_ms', 0) / 1000.0)
            adjusted_segments = []

            for idx, s in enumerate(segments_list):
                adjusted_segments.append({
                    'id': idx,
                    'start': s.start + start_offset,
                    'end': s.end + start_offset,
                    'text': s.text.strip()
                })

            return {
                'segment_index': seg['index'],
                'language': info.language or job.language,
                'segments': adjusted_segments
            }

        finally:
            del audio
            gc.collect()

    def _transcribe_segment(
        self,
        seg_meta: Dict,
        model,
        job: JobState,
        audio_array: Optional[np.ndarray] = None
    ) -> Optional[Dict]:
        """
        ç»Ÿä¸€è½¬å½•å…¥å£ï¼ˆæ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©ï¼‰

        Args:
            seg_meta: åˆ†æ®µå…ƒæ•°æ®
            model: Whisperæ¨¡å‹
            job: ä»»åŠ¡çŠ¶æ€
            audio_array: éŸ³é¢‘æ•°ç»„ï¼ˆå†…å­˜æ¨¡å¼æ—¶å¿…é¡»æä¾›ï¼‰

        Returns:
            Dict: æœªå¯¹é½çš„è½¬å½•ç»“æœ
        """
        mode = seg_meta.get('mode', 'disk')

        if mode == 'memory':
            if audio_array is None:
                raise ValueError("memory mode requires audio_array parameter")
            return self._transcribe_segment_in_memory(audio_array, seg_meta, model, job)
        else:
            return self._transcribe_segment_from_disk(seg_meta, model, job)

    def _check_memory_during_transcription(self, job: JobState) -> bool:
        """
        è½¬å½•è¿‡ç¨‹ä¸­æ£€æŸ¥å†…å­˜çŠ¶æ€

        å¦‚æœå†…å­˜ä¸¥é‡ä¸è¶³ï¼Œæš‚åœä»»åŠ¡å¹¶è­¦å‘Šç”¨æˆ·ã€‚

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡

        Returns:
            bool: True=ç»§ç»­å¤„ç†ï¼ŒFalse=éœ€è¦æš‚åœ
        """
        mem_info = psutil.virtual_memory()
        available_mb = mem_info.available / (1024 * 1024)
        percent_used = mem_info.percent

        # å±é™©é˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<500MB æˆ– ä½¿ç”¨ç‡>95%
        if available_mb < 500 or percent_used > 95:
            self.logger.error(f"memory critically low! available: {available_mb:.0f}MB, usage: {percent_used}%")
            job.status = 'paused'
            job.message = f"memory insufficient (available {available_mb:.0f}MB), please close other programs"
            job.paused = True

            # æ¨é€è­¦å‘ŠSSE
            self._push_sse_signal(job, "memory_warning",
                f"memory critically low (available {available_mb:.0f}MB), task paused")

            return False

        # è­¦å‘Šé˜ˆå€¼ï¼šå¯ç”¨å†…å­˜<1GB æˆ– ä½¿ç”¨ç‡>90%
        if available_mb < 1024 or percent_used > 90:
            self.logger.warning(f"memory tight: available {available_mb:.0f}MB, usage {percent_used}%")
            # ä¸æš‚åœï¼Œä½†è®°å½•è­¦å‘Š

        return True

    def _align_all_results(
        self,
        unaligned_results: List[Dict],
        job: JobState,
        audio_path: str
    ) -> List[Dict]:
        """
        åˆå¹¶è½¬å½•ç»“æœçš„åˆ†æ®µ

        æ­¤æ–¹æ³•åˆå¹¶æ‰€æœ‰ segments å¹¶è¿”å›ï¼Œä¸æ‰§è¡Œå¯¹é½æ“ä½œã€‚
        """
        self.logger.info(f"åˆå¹¶ {len(unaligned_results)} ä¸ªåˆ†æ®µçš„è½¬å½•ç»“æœï¼ˆè·³è¿‡å¼ºåˆ¶å¯¹é½ï¼‰")

        # åˆå¹¶æ‰€æœ‰segments
        all_segments = []
        for result in unaligned_results:
            all_segments.extend(result['segments'])

        if not all_segments:
            self.logger.warning("æ²¡æœ‰å¯å¤„ç†çš„å†…å®¹")
            return []

        # ç›´æ¥è¿”å›åˆå¹¶åçš„ç»“æœï¼ˆFaster-Whisper å·²æä¾›æ—¶é—´æˆ³ï¼‰
        return [{
            'segments': all_segments,
            'word_segments': []  # æ–°æ¶æ„ä½¿ç”¨ä¼ªå¯¹é½ç”Ÿæˆå­—çº§æ—¶é—´æˆ³
        }]

    def _push_sse_align_progress(
        self,
        job: JobState,
        current_batch: int,
        total_batches: int,
        aligned_count: int,
        total_count: int
    ):
        """
        æ¨é€å¯¹é½è¿›åº¦SSEäº‹ä»¶ï¼ˆå‰ç«¯è¿›åº¦æ¡å®æ—¶æ›´æ–°ï¼‰

        äº‹ä»¶ç±»å‹: "align_progress"

        Args:
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            current_batch: å½“å‰æ‰¹æ¬¡å·ï¼ˆ1-basedï¼‰
            total_batches: æ€»æ‰¹æ¬¡æ•°
            aligned_count: å·²å¯¹é½çš„segmentæ•°é‡
            total_count: æ€»segmentæ•°é‡
        """
        try:
            from app.services.sse_service import get_sse_manager
            sse_manager = get_sse_manager()

            channel_id = f"job:{job.job_id}"

            # è®¡ç®—ç™¾åˆ†æ¯”
            batch_progress = (current_batch / total_batches) * 100 if total_batches > 0 else 0
            segment_progress = (aligned_count / total_count) * 100 if total_count > 0 else 0

            sse_manager.broadcast_sync(
                channel_id,
                "progress.align",
                {
                    "job_id": job.job_id,
                    "phase": "align",
                    "batch": {
                        "current": current_batch,
                        "total": total_batches,
                        "progress": round(batch_progress, 2)
                    },
                    "segments": {
                        "aligned": aligned_count,
                        "total": total_count,
                        "progress": round(segment_progress, 2)
                    },
                    "message": f"aligning batch {current_batch}/{total_batches} ({aligned_count}/{total_count} segments)"
                }
            )

        except Exception as e:
            self.logger.debug(f"SSE align progress push failed (non-fatal): {e}")

    def _align_all_results_batched(
        self,
        unaligned_results: List[Dict],
        job: JobState,
        audio_source,  # Union[np.ndarray, str]
        processing_mode: ProcessingMode
    ) -> List[Dict]:
        """
        æ‰¹é‡å¤„ç†è½¬å½•ç»“æœçš„åˆ†æ®µ

        æ­¤æ–¹æ³•åˆå¹¶æ‰€æœ‰ segmentsï¼Œåº”ç”¨æ—¶é—´æ ¡éªŒå’Œå¾®è°ƒï¼Œç„¶åè¿”å›ã€‚
        """
        self.logger.info(f"å¤„ç† {len(unaligned_results)} ä¸ªåˆ†æ®µçš„è½¬å½•ç»“æœï¼ˆè·³è¿‡å¼ºåˆ¶å¯¹é½ï¼‰")

        # 1. åˆå¹¶æ‰€æœ‰segments
        all_segments = []
        for result in unaligned_results:
            all_segments.extend(result['segments'])

        if not all_segments:
            self.logger.warning("æ²¡æœ‰å¯å¤„ç†çš„å†…å®¹")
            return []

        # 2. å¯¹ç»“æœè¿›è¡Œè¾¹ç•Œæ ¡éªŒï¼Œè¿‡æ»¤å¼‚å¸¸ç»“æœ
        valid_segments = []
        for seg in all_segments:
            start = seg.get('start', 0)
            end = seg.get('end', 0)
            text = seg.get('text', '').strip()

            # æ ¡éªŒ1ï¼šæ—¶é—´æˆ³å¿…é¡»æœ‰æ•ˆ
            if start is None or end is None or start < 0 or end <= start:
                self.logger.warning(f"è¿‡æ»¤æ— æ•ˆæ—¶é—´æˆ³: start={start}, end={end}, text={text[:20] if text else ''}...")
                continue

            # æ ¡éªŒ2ï¼šå­—å¹•æ—¶é•¿ä¸èƒ½è¿‡é•¿ï¼ˆè¶…è¿‡30ç§’å¯èƒ½æ˜¯å¼‚å¸¸ï¼‰
            duration = end - start
            if duration > 30:
                self.logger.warning(f"è¿‡æ»¤è¿‡é•¿å­—å¹•({duration:.1f}s): {text[:30] if text else ''}...")
                continue

            # æ ¡éªŒ3ï¼šå­—å¹•æ—¶é•¿ä¸èƒ½è¿‡çŸ­ï¼ˆå°äº0.1ç§’å¯èƒ½æ˜¯å™ªéŸ³ï¼‰
            if duration < 0.1 and len(text) > 0:
                self.logger.warning(f"è¿‡æ»¤è¿‡çŸ­å­—å¹•({duration:.2f}s): {text}")
                continue

            valid_segments.append(seg)

        # 3. å­—å¹•æ—¶é—´å¾®è°ƒ - ä¿®æ­£"æŠ¢å…ˆå‡ºç°"é—®é¢˜
        valid_segments = self._adjust_subtitle_timing(valid_segments)

        self.logger.info(f"å¤„ç†å®Œæˆ: {len(valid_segments)}/{len(all_segments)} ä¸ªæœ‰æ•ˆå­—å¹•æ®µ")

        return [{
            'segments': valid_segments,
            'word_segments': []  # æ–°æ¶æ„ä½¿ç”¨ä¼ªå¯¹é½ç”Ÿæˆå­—çº§æ—¶é—´æˆ³
        }]

    def _adjust_subtitle_timing(
        self,
        segments: List[Dict],
        start_delay_ms: int = 25,
        end_padding_ms: int = 25
    ) -> List[Dict]:
        """
        å­—å¹•æ—¶é—´å¾®è°ƒ - ä¿®æ­£å¯¹é½åå·®

        é—®é¢˜èƒŒæ™¯ï¼š
        è½¬å½•åçš„å­—å¹•å¯èƒ½å‡ºç°æ—¶é—´åå·®ï¼Œéœ€è¦é€‚å½“è°ƒæ•´ã€‚

        è§£å†³æ–¹æ¡ˆï¼š
        1. å°†å­—å¹•å¼€å§‹æ—¶é—´å»¶å start_delay_msï¼ˆé»˜è®¤25msï¼‰
        2. å°†å­—å¹•ç»“æŸæ—¶é—´å»¶å end_padding_msï¼ˆé»˜è®¤25msï¼Œç»™ä¸€ç‚¹ä½™é‡ï¼‰
        3. ç¡®ä¿ç›¸é‚»å­—å¹•ä¸é‡å 

        Args:
            segments: å¯¹é½åçš„å­—å¹•åˆ—è¡¨
            start_delay_ms: å¼€å§‹æ—¶é—´å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œæ¨è20-50ms
            end_padding_ms: ç»“æŸæ—¶é—´å»¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œæ¨è20-50ms

        Returns:
            è°ƒæ•´åçš„å­—å¹•åˆ—è¡¨
        """
        if not segments:
            return segments

        start_delay = start_delay_ms / 1000.0
        end_padding = end_padding_ms / 1000.0

        adjusted = []
        for i, seg in enumerate(segments):
            new_seg = seg.copy()
            old_start = seg.get('start', 0)
            old_end = seg.get('end', 0)

            # å»¶è¿Ÿå¼€å§‹æ—¶é—´
            new_start = old_start + start_delay

            # å»¶é•¿ç»“æŸæ—¶é—´
            new_end = old_end + end_padding

            # ç¡®ä¿å¼€å§‹æ—¶é—´ä¸è¶…è¿‡ç»“æŸæ—¶é—´
            if new_start >= new_end:
                new_start = old_start  # å›é€€åˆ°åŸå§‹å¼€å§‹æ—¶é—´

            # ç¡®ä¿ä¸ä¸ä¸‹ä¸€æ¡å­—å¹•é‡å 
            if i < len(segments) - 1:
                next_start = segments[i + 1].get('start', float('inf'))
                # ä¸‹ä¸€æ¡ä¹Ÿä¼šè¢«å»¶è¿Ÿï¼Œæ‰€ä»¥æ¯”è¾ƒæ—¶è¦è€ƒè™‘
                next_adjusted_start = next_start + start_delay
                if new_end > next_adjusted_start:
                    new_end = next_adjusted_start - 0.05  # ç•™50msé—´éš”

            # ç¡®ä¿ç»“æŸæ—¶é—´ä»ç„¶æœ‰æ•ˆ
            if new_end <= new_start:
                new_end = old_end  # å›é€€åˆ°åŸå§‹ç»“æŸæ—¶é—´

            new_seg['start'] = round(new_start, 3)
            new_seg['end'] = round(new_end, 3)
            adjusted.append(new_seg)

        self.logger.info(f"å­—å¹•æ—¶é—´å¾®è°ƒ: å»¶è¿Ÿå¼€å§‹25ms, å»¶é•¿ç»“æŸ25ms")
        return adjusted

    def _format_ts(self, sec: float) -> str:
        """
        æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºSRTæ ¼å¼

        Args:
            sec: ç§’æ•°

        Returns:
            str: SRTæ—¶é—´æˆ³ (HH:MM:SS,mmm)
        """
        if sec < 0:
            sec = 0

        ms = int(round(sec * 1000))
        h = ms // 3600000
        ms %= 3600000
        m = ms // 60000
        ms %= 60000
        s = ms // 1000
        ms %= 1000

        return f"{h:02}:{m:02}:{s:02},{ms:03}"

    def _generate_srt(self, results: List[Dict], path: str, word_level: bool):
        """
        ç”ŸæˆSRTå­—å¹•æ–‡ä»¶

        Args:
            results: è½¬å½•ç»“æœåˆ—è¡¨
            path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            word_level: æ˜¯å¦ä½¿ç”¨è¯çº§æ—¶é—´æˆ³
        """
        lines = []
        n = 1  # å­—å¹•åºå·

        for r in results:
            if not r:
                continue

            entries = []

            # è¯çº§æ—¶é—´æˆ³æ¨¡å¼
            if word_level and r.get('word_segments'):
                for w in r['word_segments']:
                    if w.get('start') is not None and w.get('end') is not None:
                        txt = (w.get('word') or '').strip()
                        if txt:
                            entries.append({
                                'start': w['start'],
                                'end': w['end'],
                                'text': txt
                            })

            # å¥å­çº§æ—¶é—´æˆ³æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            elif r.get('segments'):
                for s in r['segments']:
                    if s.get('start') is not None and s.get('end') is not None:
                        txt = (s.get('text') or '').strip()
                        if txt:
                            entries.append({
                                'start': s['start'],
                                'end': s['end'],
                                'text': txt
                            })

            # å†™å…¥SRTæ ¼å¼
            for e in entries:
                if e['end'] <= e['start']:
                    continue  # è·³è¿‡æ— æ•ˆæ—¶é—´æˆ³

                lines.append(str(n))  # åºå·
                lines.append(
                    f"{self._format_ts(e['start'])} --> {self._format_ts(e['end'])}"
                )  # æ—¶é—´æˆ³
                lines.append(e['text'])  # å­—å¹•æ–‡æœ¬
                lines.append("")  # ç©ºè¡Œ
                n += 1

        # å†™å…¥æ–‡ä»¶
        with open(path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        self.logger.info(f"SRTæ–‡ä»¶å·²ç”Ÿæˆ: {path}, å…±{n-1}æ¡å­—å¹•")

    def clear_model_cache(self):
        """
        æ¸…ç©ºæ¨¡å‹ç¼“å­˜ï¼ˆä¾›é˜Ÿåˆ—æœåŠ¡è°ƒç”¨ï¼‰

        æ³¨æ„: æ–°æ¶æ„å·²ç§»é™¤å¯¹é½æ¨¡å‹ï¼Œä»…æ¸…ç† Whisper æ¨¡å‹
        """
        global _model_cache

        with _model_lock:
            for key in list(_model_cache.keys()):
                try:
                    del _model_cache[key]
                except:
                    pass
            _model_cache.clear()
            self.logger.info("Whisperæ¨¡å‹ç¼“å­˜å·²æ¸…ç©º")

    # ==========================================
    # SenseVoice é›†æˆæ–¹æ³•ï¼ˆPhase 3ï¼‰
    # ==========================================

    def _sensevoice_transcribe(
        self,
        audio_array: np.ndarray,
        job: 'JobState',
        sample_rate: int = 16000
    ) -> 'SenseVoiceResult':
        """
        è°ƒç”¨ SenseVoice æœåŠ¡è¿›è¡Œè½¬å½•ï¼ˆè¿”å›å¸¦çœŸå®å­—çº§æ—¶é—´æˆ³çš„ç»“æœï¼‰

        Args:
            audio_array: éŸ³é¢‘æ•°ç»„
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            sample_rate: é‡‡æ ·ç‡

        Returns:
            SenseVoiceResult: è½¬å½•ç»“æœï¼ŒåŒ…å«:
                - text: åŸå§‹æ–‡æœ¬ï¼ˆå¸¦æ ‡ç­¾ï¼‰
                - text_clean: æ¸…æ´—åæ–‡æœ¬
                - words: å­—çº§æ—¶é—´æˆ³åˆ—è¡¨ï¼ˆçœŸå®æ—¶é—´æˆ³ï¼Œéä¼ªå¯¹é½ï¼‰
                - confidence: å¹³å‡ç½®ä¿¡åº¦
                - language: æ£€æµ‹åˆ°çš„è¯­è¨€
                - emotion: æƒ…æ„Ÿæ ‡ç­¾
                - event: äº‹ä»¶æ ‡ç­¾
        """
        from app.services.sensevoice_onnx_service import get_sensevoice_service
        from app.models.sensevoice_models import SenseVoiceResult, WordTimestamp

        self.logger.debug("è°ƒç”¨ SenseVoice è½¬å½•æœåŠ¡")

        try:
            service = get_sensevoice_service()

            # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            if not service.is_loaded:
                self.logger.info("åŠ è½½ SenseVoice æ¨¡å‹...")
                service.load_model()

            # è°ƒç”¨è½¬å½•ï¼ˆè¿”å›å­—å…¸ï¼‰
            # æ³¨: SenseVoice çš„ language å‚æ•°å®é™…ä¸Šæ˜¯è‡ªåŠ¨æ£€æµ‹ï¼Œè¿™é‡Œä¼ å…¥ "auto" å³å¯
            result_dict = service.transcribe_audio_array(
                audio_array=audio_array,
                sample_rate=sample_rate,
                language="auto"
            )

            # è½¬æ¢ä¸º SenseVoiceResult å¯¹è±¡
            words = [
                WordTimestamp(**w) if isinstance(w, dict) else w
                for w in result_dict.get('words', [])
            ]

            result = SenseVoiceResult(
                text=result_dict.get('text', ''),
                text_clean=result_dict.get('text_clean', ''),
                confidence=result_dict.get('confidence', 1.0),
                words=words,
                start=0.0,  # Chunk çº§åˆ«çš„èµ·å§‹æ—¶é—´ï¼Œç”±è°ƒç”¨è€…è®¾ç½®
                end=len(audio_array) / sample_rate,
                language=result_dict.get('language'),
                emotion=result_dict.get('emotion'),
                event=result_dict.get('event'),
                raw_result=result_dict
            )

            self.logger.debug(f"SenseVoice è½¬å½•å®Œæˆ: {len(result.text_clean)} å­—ç¬¦, {len(words)} ä¸ªå­—")
            return result

        except Exception as e:
            self.logger.error(f"SenseVoice è½¬å½•å¤±è´¥: {e}")
            raise

    def _split_sentences(
        self,
        sv_result: 'SenseVoiceResult',
        chunk_start_time: float = 0.0,
        split_config: Optional['SplitConfig'] = None,  # Layer 1: å…è®¸ä¼ å…¥é…ç½®
        enable_grouping: bool = True                    # Layer 2: æ˜¯å¦å¯ç”¨è¯­ä¹‰åˆ†ç»„ (é¢„ç•™)
    ) -> List['SentenceSegment']:
        """
        å°† SenseVoice ç»“æœåˆ‡åˆ†ä¸ºå¥å­ï¼ˆåŸºäºçœŸå®å­—çº§æ—¶é—´æˆ³ï¼‰

        Args:
            sv_result: SenseVoice è½¬å½•ç»“æœï¼ˆåŒ…å«çœŸå®å­—çº§æ—¶é—´æˆ³ï¼‰
            chunk_start_time: Chunk åœ¨å®Œæ•´éŸ³é¢‘ä¸­çš„èµ·å§‹æ—¶é—´ï¼ˆç”¨äºæ—¶é—´åç§»ï¼‰
            split_config: åˆ†å¥é…ç½®ï¼ˆLayer 1 æ–°å¢ï¼Œå¯é€‰ï¼‰
            enable_grouping: æ˜¯å¦å¯ç”¨è¯­ä¹‰åˆ†ç»„ï¼ˆLayer 2 é¢„ç•™ï¼Œå¯é€‰ï¼‰

        Returns:
            List[SentenceSegment]: å¥å­åˆ—è¡¨
        """
        from app.models.sensevoice_models import SentenceSegment, TextSource
        from app.services.sentence_splitter import SentenceSplitter, SplitConfig

        self.logger.debug(f"å¼€å§‹å¥å­åˆ‡åˆ†: {len(sv_result.words)} ä¸ªå­—")

        if not sv_result.words:
            return []

        # Layer 1: ä½¿ç”¨ä¼ å…¥çš„é…ç½®æˆ–é»˜è®¤é…ç½®
        config = split_config or SplitConfig()
        splitter = SentenceSplitter(config)
        sentences = splitter.split(sv_result.words, sv_result.text_clean)

        # Layer 2: è¯­ä¹‰åˆ†ç»„ (å¯é€‰ï¼Œå·²å®ç°)
        if enable_grouping:
            from app.services.semantic_grouper import SemanticGrouper, GroupConfig
            grouper = SemanticGrouper(GroupConfig(language=config.language))
            sentences = grouper.group(sentences)

        # ã€é˜¶æ®µä¸‰ã€‘VAD è¾¹ç¼˜å¸é™„ (Head Snap)
        # é€»è¾‘ï¼šå¦‚æœæ˜¯ Chunk çš„ç¬¬ä¸€å¥è¯ï¼Œä¸” CTC å»¶è¿Ÿåœ¨åˆç†èŒƒå›´å†…ï¼ˆ<0.6sï¼‰ï¼Œ
        # å¼ºåˆ¶å°†å…¶ start å¯¹é½åˆ° Chunk çš„ç‰©ç†èµ·å§‹ç‚¹ (0.0 ç›¸å¯¹æ—¶é—´)
        HEAD_SNAP_THRESHOLD = 0.6  # æœ€å¤§å…è®¸å¸é™„çš„å»¶è¿Ÿï¼ˆç§’ï¼‰

        if sentences:
            first_sent = sentences[0]
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªè¯çš„ç›¸å¯¹å¼€å§‹æ—¶é—´ï¼ˆç›¸å¯¹äº chunkï¼‰
            # å¦‚æœ > 0 ä¸” < é˜ˆå€¼ï¼Œè¯´æ˜ CTC æœ‰å»¶è¿Ÿï¼Œéœ€è¦å¸é™„åˆ° VAD è¾¹ç¼˜
            if 0 < first_sent.start < HEAD_SNAP_THRESHOLD:
                self.logger.debug(
                    f"Head Snap: '{first_sent.text[:15]}...' å»¶è¿Ÿä¿®æ­£ "
                    f"{first_sent.start:.3f}s -> 0.0s (ç›¸å¯¹VAD)"
                )
                # ä¿®æ­£å¥å­å¼€å§‹æ—¶é—´
                first_sent.start = 0.0
                # åŒæ—¶ä¿®æ­£ç¬¬ä¸€ä¸ªå•è¯çš„å¼€å§‹æ—¶é—´ï¼ˆä¿æŒä¸€è‡´æ€§ï¼‰
                if first_sent.words:
                    first_sent.words[0].start = 0.0

        # è°ƒæ•´æ—¶é—´åç§»ï¼ˆå°† Chunk å†…çš„ç›¸å¯¹æ—¶é—´è½¬æ¢ä¸ºç»å¯¹æ—¶é—´ï¼‰
        for sentence in sentences:
            sentence.start += chunk_start_time
            sentence.end += chunk_start_time
            sentence.source = TextSource.SENSEVOICE
            sentence.confidence = sv_result.confidence

            # è°ƒæ•´å­—çº§æ—¶é—´æˆ³çš„åç§»
            for word in sentence.words:
                word.start += chunk_start_time
                word.end += chunk_start_time

        self.logger.debug(f"å¥å­åˆ‡åˆ†å®Œæˆ: {len(sentences)} å¥")
        return sentences

    def _split_text_by_punctuation(self, text: str) -> List[str]:
        """
        åŸºäºæ ‡ç‚¹ç¬¦å·åˆ‡åˆ†æ–‡æœ¬

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            List[str]: å¥å­åˆ—è¡¨
        """
        import re

        # å¥æœ«æ ‡ç‚¹
        sentence_end_pattern = r'([ã€‚ï¼Ÿï¼.?!])'

        # ä½¿ç”¨æ­£åˆ™åˆ‡åˆ†ï¼Œä¿ç•™æ ‡ç‚¹
        parts = re.split(sentence_end_pattern, text)

        # åˆå¹¶æ ‡ç‚¹åˆ°å‰ä¸€ä¸ªå¥å­
        sentences = []
        i = 0
        while i < len(parts):
            if i + 1 < len(parts) and re.match(sentence_end_pattern, parts[i + 1]):
                sentences.append(parts[i] + parts[i + 1])
                i += 2
            else:
                if parts[i].strip():
                    sentences.append(parts[i])
                i += 1

        return [s.strip() for s in sentences if s.strip()]

    def _generate_pseudo_word_timestamps(
        self,
        text: str,
        start: float,
        end: float,
        confidence: float = 1.0
    ) -> List['WordTimestamp']:
        """
        ç”Ÿæˆä¼ªå­—çº§æ—¶é—´æˆ³ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰

        Args:
            text: å¥å­æ–‡æœ¬
            start: å¥å­å¼€å§‹æ—¶é—´
            end: å¥å­ç»“æŸæ—¶é—´
            confidence: ç½®ä¿¡åº¦

        Returns:
            List[WordTimestamp]: å­—çº§æ—¶é—´æˆ³åˆ—è¡¨
        """
        from app.models.sensevoice_models import WordTimestamp

        if not text:
            return []

        duration = end - start
        char_duration = duration / len(text)

        words = []
        for i, char in enumerate(text):
            word_start = start + i * char_duration
            word_end = start + (i + 1) * char_duration

            words.append(WordTimestamp(
                word=char,
                start=word_start,
                end=word_end,
                confidence=confidence,
                is_pseudo=True  # æ ‡è®°ä¸ºä¼ªå¯¹é½
            ))

        return words

    def _generate_subtitle_from_sentences(
        self,
        sentences: List['SentenceSegment'],
        output_path: str,
        include_translation: bool = False
    ) -> str:
        """
        ä»å¥å­åˆ—è¡¨ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶

        Args:
            sentences: å¥å­åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            include_translation: æ˜¯å¦åŒ…å«ç¿»è¯‘ï¼ˆåŒè¯­å­—å¹•ï¼‰

        Returns:
            str: ç”Ÿæˆçš„SRTæ–‡ä»¶è·¯å¾„
        """
        self.logger.info(f"ç”ŸæˆSRTå­—å¹•: {len(sentences)} å¥ -> {output_path}")

        lines = []
        for idx, sentence in enumerate(sentences, 1):
            # åºå·
            lines.append(str(idx))

            # æ—¶é—´æˆ³
            start_ts = self._format_ts(sentence.start)
            end_ts = self._format_ts(sentence.end)
            lines.append(f"{start_ts} --> {end_ts}")

            # å­—å¹•æ–‡æœ¬ï¼ˆä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬ï¼‰
            if include_translation and sentence.translation:
                # åŒè¯­å­—å¹•ï¼šåŸæ–‡ + ç¿»è¯‘
                lines.append(sentence.text_clean or sentence.text)
                lines.append(sentence.translation)
            else:
                lines.append(sentence.text_clean or sentence.text)

            # ç©ºè¡Œåˆ†éš”
            lines.append("")

        # å†™å…¥æ–‡ä»¶
        # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
        from pathlib import Path
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        self.logger.info(f"SRTå­—å¹•ç”Ÿæˆå®Œæˆ: {output_path}")
        return output_path

    def _save_raw_transcription(
        self,
        job: 'JobState',
        sentences: List['SentenceSegment']
    ):
        """
        ä¿å­˜åŸå§‹è½¬å½•æ•°æ®ï¼ˆæœªç» LLM å¤„ç†çš„ SenseVoice åŸå§‹è¾“å‡ºï¼‰

        Args:
            job: ä»»åŠ¡çŠ¶æ€
            sentences: å¥å­åˆ—è¡¨
        """
        import json
        from pathlib import Path

        try:
            # å‡†å¤‡ä¿å­˜æ•°æ®
            raw_data = {
                "job_id": job.job_id,
                "filename": job.filename,
                "timestamp": self._get_current_timestamp(),
                "total_sentences": len(sentences),
                "sentences": []
            }

            # æ”¶é›†æ‰€æœ‰å¥å­çš„åŸå§‹æ•°æ®
            for idx, sentence in enumerate(sentences):
                sentence_data = {
                    "index": idx,
                    "start": sentence.start,
                    "end": sentence.end,
                    "text": sentence.text,  # åŒ…å«åŸå§‹æ ‡ç­¾çš„æ–‡æœ¬
                    "confidence": sentence.confidence,
                    "source": sentence.source.value if hasattr(sentence.source, 'value') else str(sentence.source),
                    "words": []
                }

                # æ·»åŠ å­—çº§æ—¶é—´æˆ³
                if hasattr(sentence, 'words') and sentence.words:
                    for word in sentence.words:
                        word_data = {
                            "word": word.word,
                            "start": word.start,
                            "end": word.end,
                            "confidence": word.confidence,
                            "is_pseudo": word.is_pseudo
                        }
                        sentence_data["words"].append(word_data)

                raw_data["sentences"].append(sentence_data)

            # ä¿å­˜åˆ°æ–‡ä»¶
            output_path = Path(job.dir) / f"{job.job_id}_raw_transcription.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(raw_data, f, ensure_ascii=False, indent=2)

            self.logger.info(f"åŸå§‹è½¬å½•æ•°æ®å·²ä¿å­˜: {output_path}")

        except Exception as e:
            self.logger.error(f"ä¿å­˜åŸå§‹è½¬å½•æ•°æ®å¤±è´¥: {e}", exc_info=True)

    def _get_current_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().isoformat()

    def _init_chunk_states(
        self,
        vad_segments: List[dict],
        audio_array: np.ndarray,
        sr: int = 16000
    ) -> List['ChunkProcessState']:
        """
        åˆå§‹åŒ–æ‰€æœ‰ Chunk çš„å¤„ç†çŠ¶æ€

        å…³é”®ï¼šä¿å­˜åŸå§‹éŸ³é¢‘å¼•ç”¨ï¼Œç”¨äºç†”æ–­å›æº¯

        Args:
            vad_segments: VAD åˆ‡åˆ†ç»“æœ
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            sr: é‡‡æ ·ç‡

        Returns:
            List[ChunkProcessState]: Chunk çŠ¶æ€åˆ—è¡¨
        """
        from app.models.circuit_breaker_models import ChunkProcessState, SeparationLevel

        self.logger.info(f"åˆå§‹åŒ– {len(vad_segments)} ä¸ª Chunk çŠ¶æ€...")

        states = []
        for seg in vad_segments:
            start_sample = int(seg['start'] * sr)
            end_sample = int(seg['end'] * sr)
            chunk_audio = audio_array[start_sample:end_sample]

            state = ChunkProcessState(
                chunk_index=seg['index'],
                start_time=seg['start'],
                end_time=seg['end'],
                original_audio=chunk_audio.copy(),  # å…³é”®ï¼šä¿å­˜åŸå§‹éŸ³é¢‘å‰¯æœ¬
                current_audio=chunk_audio,           # å½“å‰ä½¿ç”¨çš„éŸ³é¢‘ï¼ˆå¯èƒ½è¢«åˆ†ç¦»åæ›¿æ¢ï¼‰
                sample_rate=sr,
                separation_level=SeparationLevel.NONE
            )
            states.append(state)

        self.logger.info(f"Chunk çŠ¶æ€åˆå§‹åŒ–å®Œæˆ")
        return states

    async def _transcribe_chunk_with_fusing(
        self,
        chunk_state: 'ChunkProcessState',
        job: 'JobState',
        subtitle_manager: 'StreamingSubtitleManager',
        demucs_service
    ) -> List['SentenceSegment']:
        """
        å•ä¸ª Chunk çš„è½¬å½•æµç¨‹ï¼ˆå«ç†”æ–­å›æº¯ï¼‰

        æµç¨‹ï¼š
        1. ä½¿ç”¨ current_audio è¿›è¡Œ SenseVoice è½¬å½•
        2. è¯„ä¼°ç½®ä¿¡åº¦å’Œäº‹ä»¶æ ‡ç­¾
        3. ç†”æ–­å†³ç­–
        4. å¦‚éœ€ç†”æ–­ï¼šå›æº¯åˆ° original_audioï¼Œå‡çº§åˆ†ç¦»ï¼Œé‡æ–°è½¬å½•
        5. æ­¢æŸç‚¹ï¼šmax_retry=1

        Args:
            chunk_state: Chunk å¤„ç†çŠ¶æ€
            job: ä»»åŠ¡çŠ¶æ€å¯¹è±¡
            subtitle_manager: æµå¼å­—å¹•ç®¡ç†å™¨
            demucs_service: Demucs æœåŠ¡å®ä¾‹

        Returns:
            List[SentenceSegment]: å¥å­åˆ—è¡¨
        """
        from app.services.fuse_breaker import get_fuse_breaker, execute_fuse_upgrade, FuseAction

        fuse_breaker = get_fuse_breaker()

        while True:
            # 1. SenseVoice è½¬å½•
            sv_result = self._sensevoice_transcribe(chunk_state.current_audio, job, chunk_state.sample_rate)

            # 2. åˆ†å¥
            sentences = self._split_sentences(sv_result, chunk_state.start_time)

            # 3. è®¡ç®—ç½®ä¿¡åº¦å’Œäº‹ä»¶æ ‡ç­¾
            avg_confidence = sum(s.confidence for s in sentences) / len(sentences) if sentences else 0.0
            event_tag = sv_result.event  # SenseVoice æ£€æµ‹åˆ°çš„äº‹ä»¶ï¼ˆBGM/Noiseç­‰ï¼‰

            # 4. ç†”æ–­å†³ç­–
            decision = fuse_breaker.should_fuse(
                chunk_state=chunk_state,
                confidence=avg_confidence,
                event_tag=event_tag
            )

            self.logger.debug(
                f"Chunk {chunk_state.chunk_index} ç†”æ–­å†³ç­–: {decision.action.value}, "
                f"ç½®ä¿¡åº¦={avg_confidence:.2f}, äº‹ä»¶={event_tag}"
            )

            # 5. å¤„ç†å†³ç­–
            if decision.action == FuseAction.ACCEPT:
                # æ¥å—ç»“æœï¼Œæ¨é€è‰ç¨¿äº‹ä»¶ï¼ˆPhase 5: åŒæ¨¡æ€æ¶æ„ï¼‰
                # ä½¿ç”¨ add_draft_sentences æ‰¹é‡æ¨é€ï¼Œè§¦å‘ subtitle.draft äº‹ä»¶
                subtitle_manager.add_draft_sentences(chunk_state.chunk_index, sentences)
                return sentences

            elif decision.action == FuseAction.UPGRADE_SEPARATION:
                # ç†”æ–­å›æº¯ï¼šä½¿ç”¨åŸå§‹éŸ³é¢‘é‡æ–°åˆ†ç¦»
                self.logger.info(
                    f"Chunk {chunk_state.chunk_index} è§¦å‘ç†”æ–­ï¼Œ"
                    f"å‡çº§åˆ†ç¦»: {chunk_state.separation_level.value} â†’ {decision.next_separation_level.value}"
                )

                chunk_state = execute_fuse_upgrade(
                    chunk_state=chunk_state,
                    next_level=decision.next_separation_level,
                    demucs_service=demucs_service
                )

                # ç»§ç»­å¾ªç¯ï¼Œä½¿ç”¨å‡çº§åçš„éŸ³é¢‘é‡æ–°è½¬å½•
                continue

            else:
                # æœªçŸ¥åŠ¨ä½œï¼Œæ¥å—å½“å‰ç»“æœ
                subtitle_manager.add_draft_sentences(chunk_state.chunk_index, sentences)
                return sentences

    async def _whisper_text_patch_with_arbitration(
        self,
        sentence: 'SentenceSegment',
        sentence_index: int,
        audio_array: np.ndarray,
        job: 'JobState',
        subtitle_manager: 'StreamingSubtitleManager',
        is_trash_suspect: bool = False
    ) -> 'SentenceSegment':
        """
        Whisper è¡¥åˆ€ + ä»²è£åˆ¤å†³ï¼ˆäºŒæ¬¡å®‰æ£€æœºåˆ¶ï¼‰

        æ ¸å¿ƒé€»è¾‘ï¼š
        - å¦‚æœæ˜¯åƒåœ¾å«Œç–‘æ ·æœ¬ï¼Œæ ¹æ® Whisper åé¦ˆåˆ¤å†³å»ç•™
        - å¦‚æœæ˜¯å¸¸è§„è¡¥åˆ€ï¼Œç›´æ¥é‡‡çº³ Whisper ç»“æœ

        Args:
            sentence: åŸå§‹å¥å­
            sentence_index: å¥å­ç´¢å¼•
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            job: ä»»åŠ¡çŠ¶æ€
            subtitle_manager: æµå¼å­—å¹•ç®¡ç†å™¨
            is_trash_suspect: æ˜¯å¦æ˜¯åƒåœ¾å«Œç–‘æ ·æœ¬

        Returns:
            SentenceSegment: æ›´æ–°åçš„å¥å­ï¼ˆæˆ–æ ‡è®°åˆ é™¤ï¼‰
        """
        from app.services.whisper_service import get_whisper_service
        from app.models.sensevoice_models import TextSource

        whisper_service = get_whisper_service()

        # ç¡®ä¿ Whisper æ¨¡å‹å·²åŠ è½½ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        if not whisper_service.is_loaded:
            self.logger.info("åŠ è½½ Whisper æ¨¡å‹...")
            whisper_service.load_model()  # è‡ªåŠ¨ä¸‹è½½ CTranslate2 æ ¼å¼æ¨¡å‹

        # æå–å¯¹åº”æ—¶é—´æ®µçš„éŸ³é¢‘ï¼ˆå¢åŠ å‰å‘é‡å ï¼Œä¸º Whisper æä¾›ä¸Šä¸‹æ–‡é¢„çƒ­ï¼‰
        sr = 16000
        WHISPER_OVERLAP_SEC = 0.5  # Whisper ä¸Šä¸‹æ–‡é‡å æ—¶é•¿ï¼ˆç§’ï¼‰

        # è®¡ç®—é‡å åçš„èµ·å§‹ä½ç½®ï¼ˆä¸å°äº0ï¼‰
        overlap_start = max(0.0, sentence.start - WHISPER_OVERLAP_SEC)
        start_sample = int(overlap_start * sr)
        end_sample = int(sentence.end * sr)
        audio_segment = audio_array[start_sample:end_sample]

        # è®°å½•æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if overlap_start < sentence.start:
            self.logger.debug(
                f"Whisper è¡¥åˆ€æ·»åŠ  {sentence.start - overlap_start:.2f}s å‰å‘é‡å : "
                f"[{overlap_start:.2f}s, {sentence.end:.2f}s]"
            )

        # è·å–ä¸Šä¸‹æ–‡æç¤ºï¼ˆç°åœ¨ä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬ï¼Œé¿å…ä¸‹åˆ’çº¿ç­‰åŸå§‹ tokenï¼‰
        context = subtitle_manager.get_context_window(sentence_index)

        # Whisper è½¬å½•
        result = whisper_service.transcribe(
            audio=audio_segment,
            initial_prompt=context,
            language=getattr(job.settings, 'language', 'auto'),
            word_timestamps=False,
            condition_on_previous_text=False  # ç¦ç”¨å‰æ–‡æ¡ä»¶åŒ–ï¼Œé¿å…ä¸ initial_prompt å½¢æˆåŒé‡æç¤ºè¯å¢ç›Š
        )

        whisper_text = result.get('text', '').strip()
        whisper_conf = self._estimate_whisper_confidence(result)
        segments = result.get('segments', [])

        # ========== ç¬¬ä¸‰é“é˜²çº¿: åŒæµæ ¡éªŒä¸ç½®ä¿¡åº¦é—¨æ§ ==========
        from app.services.text_normalizer import TextNormalizer

        # A. avg_logprob æ£€æŸ¥ï¼ˆæ¨¡å‹åœ¨ççŒœï¼‰
        avg_logprob = -0.5  # é»˜è®¤å€¼
        avg_no_speech = 0.0  # é»˜è®¤å€¼
        if segments:
            avg_logprob = sum(s.get('avg_logprob', -0.5) for s in segments) / len(segments)
            avg_no_speech = sum(s.get('no_speech_prob', 0.0) for s in segments) / len(segments)

            # ç†”æ–­æ¡ä»¶1: avg_logprob è¿‡ä½ï¼ˆæ¨¡å‹ä¸ç¡®ä¿¡ï¼‰
            if avg_logprob < -1.0:
                self.logger.warning(
                    f"Whisper ç†”æ–­(avg_logprob={avg_logprob:.2f} < -1.0) {sentence_index}: "
                    f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                )
                return sentence

            # ç†”æ–­æ¡ä»¶2: no_speech_prob é«˜ä½†ä»è¾“å‡ºæ–‡æœ¬ï¼ˆé™éŸ³æ®µè¢«å¼ºè¡Œç¿»è¯‘ï¼‰
            if avg_no_speech > 0.6 and whisper_text:
                self.logger.warning(
                    f"Whisper ç†”æ–­(no_speech={avg_no_speech:.2f} > 0.6) {sentence_index}: "
                    f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                )
                return sentence

        # B. å¹»è§‰æ­£åˆ™æ£€æµ‹ï¼ˆä½¿ç”¨å‡çº§åçš„ TextNormalizerï¼‰
        if TextNormalizer.is_whisper_hallucination(whisper_text):
            self.logger.warning(
                f"Whisper ç†”æ–­(å¹»è§‰æ£€æµ‹) {sentence_index}: '{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
            )
            return sentence

        # C. åŒæµé•¿åº¦/å†…å®¹å¯¹æ¯”ï¼ˆå…³é”®åˆ›æ–°ï¼‰
        sensevoice_text = sentence.text_clean or sentence.text or ""

        # ç‰¹æ®Šæƒ…å†µ: SenseVoice ä¸ºç©ºï¼Œä½† Whisper æœ‰è¾“å‡º
        if not sensevoice_text and whisper_text:
            # å¦‚æœ Whisper ç½®ä¿¡åº¦æé«˜ï¼Œç»™äºˆç‰¹æƒæ”¾è¡Œ
            if avg_logprob > -0.5:
                self.logger.info(
                    f"SenseVoice ä¸ºç©ºï¼ŒWhisper é«˜ç½®ä¿¡åº¦(logprob={avg_logprob:.2f})ç‰¹æƒæ”¾è¡Œ {sentence_index}: "
                    f"'{whisper_text[:50]}...'"
                )
                # ç»§ç»­æ­£å¸¸æµç¨‹
            else:
                # Whisper ç½®ä¿¡åº¦ä¸å¤Ÿé«˜ï¼Œä¿å®ˆèµ·è§ä¸é‡‡çº³
                self.logger.warning(
                    f"SenseVoice ä¸ºç©ºï¼ŒWhisper ç½®ä¿¡åº¦ä¸è¶³(logprob={avg_logprob:.2f}) {sentence_index}: "
                    f"'{whisper_text[:50]}...', ä¿æŒ SenseVoice ç©ºç»“æœ"
                )
                return sentence

        # é•¿åº¦æš´æ¶¨æ£€æµ‹: Whisper è¾“å‡ºè¿œè¶… SenseVoice
        if sensevoice_text:
            len_sv = len(sensevoice_text)
            len_w = len(whisper_text)

            # å…¬å¼: len(whisper) > 3 * len(sensevoice) + 10
            if len_w > 3 * len_sv + 10:
                # ç‰¹æƒæ”¾è¡Œ: å¦‚æœ Whisper ç½®ä¿¡åº¦æé«˜ï¼Œå¯èƒ½æ˜¯ SenseVoice æ¼è¯†åˆ«
                if avg_logprob > -0.5:
                    self.logger.info(
                        f"Whisper é•¿åº¦æš´æ¶¨ä½†ç½®ä¿¡åº¦é«˜(logprob={avg_logprob:.2f}) {sentence_index}, ç‰¹æƒæ”¾è¡Œ"
                    )
                else:
                    self.logger.warning(
                        f"Whisper ç†”æ–­(é•¿åº¦æš´æ¶¨ {len_w} > 3*{len_sv}+10) {sentence_index}: "
                        f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                    )
                    return sentence

        # D. åŸæœ‰æ£€æµ‹é€»è¾‘ï¼ˆä¿ç•™å…¼å®¹ï¼‰
        if context and whisper_text:
            # æ£€æµ‹æ˜¯å¦åŒ…å«å¤§é‡ä¸‹åˆ’çº¿ï¼ˆå¹»è§‰æ ‡å¿—ï¼‰
            underscore_ratio = whisper_text.count('_') / max(len(whisper_text), 1)
            if underscore_ratio > 0.3:  # è¶…è¿‡ 30% æ˜¯ä¸‹åˆ’çº¿
                self.logger.warning(
                    f"Whisper è¡¥åˆ€æ£€æµ‹åˆ°ä¸‹åˆ’çº¿å¹»è§‰ {sentence_index}: "
                    f"'{whisper_text[:50]}...' (ä¸‹åˆ’çº¿å æ¯” {underscore_ratio:.1%}), å›é€€åˆ° SenseVoice"
                )
                return sentence

            # æ£€æµ‹æ˜¯å¦é‡å¤äº†æç¤ºè¯å†…å®¹ï¼ˆç›¸ä¼¼åº¦è¿‡é«˜ï¼‰
            context_words = set(context.split())
            whisper_words = set(whisper_text.split())
            if len(context_words) > 0:
                overlap_ratio = len(context_words & whisper_words) / len(context_words)
                # å¦‚æœ Whisper è¾“å‡ºä¸ context é‡å åº¦è¶…è¿‡ 80%ï¼Œä¸”é•¿åº¦ç›¸è¿‘ï¼Œå¯èƒ½æ˜¯ç…§æŠ„
                if overlap_ratio > 0.8 and abs(len(whisper_text) - len(context)) < len(context) * 0.3:
                    self.logger.warning(
                        f"Whisper è¡¥åˆ€æ£€æµ‹åˆ°æç¤ºè¯é‡å¤ {sentence_index}: "
                        f"ä¸ context é‡å åº¦ {overlap_ratio:.1%}, å›é€€åˆ° SenseVoice"
                    )
                    return sentence

        # === åˆ¤å†³æ—¶åˆ» ===
        if is_trash_suspect:
            # ä»²è£é˜ˆå€¼
            WHISPER_ARBITRATION_CONF = 0.5  # Whisper ä¹Ÿå¿…é¡»æœ‰ä¸€å®šç¡®ä¿¡åº¦
            MIN_TEXT_LENGTH = 1  # æœ€å°‘æ–‡æœ¬é•¿åº¦

            # åˆ¤æ­»åˆ‘æ¡ä»¶ï¼šWhisper ä¹Ÿå¬ä¸æ¸… OR è¾“å‡ºä¸ºç©º
            if whisper_conf < WHISPER_ARBITRATION_CONF or len(whisper_text) < MIN_TEXT_LENGTH:
                self.logger.info(
                    f"ä»²è£ç»“æœ: åˆ é™¤åƒåœ¾ç‰‡æ®µ {sentence_index} - "
                    f"SenseVoice({sentence.confidence:.2f}) + Whisper({whisper_conf:.2f}, '{whisper_text}')"
                )
                subtitle_manager.mark_for_deletion(
                    index=sentence_index,
                    reason=f"whisper_arbitration_failed_conf_{whisper_conf:.2f}"
                )
                return sentence
            else:
                # æŒ½æ•‘æˆåŠŸï¼
                self.logger.info(
                    f"ä»²è£ç»“æœ: æŒ½æ•‘ç‰‡æ®µ {sentence_index} - "
                    f"'{whisper_text}' (Whisper Conf {whisper_conf:.2f})"
                )

        # å¸¸è§„è¡¥åˆ€ OR åƒåœ¾æ ·æœ¬é€šè¿‡ä»²è£ => é‡‡çº³ Whisper ç»“æœ
        if not whisper_text:
            self.logger.warning(f"Whisper è¡¥åˆ€è¿”å›ç©ºæ–‡æœ¬ï¼Œä¿ç•™åŸç»“æœ")
            return sentence

        # ä¿å­˜ Whisper å¤‡é€‰æ–‡æœ¬
        sentence.whisper_alternative = whisper_text

        # ä½¿ç”¨ä¼ªå¯¹é½æ›´æ–°å¥å­
        subtitle_manager.update_sentence(
            index=sentence_index,
            new_text=whisper_text,
            source=TextSource.WHISPER_PATCH,
            confidence=whisper_conf
        )

        return subtitle_manager.sentences[sentence_index]

    async def _whisper_text_patch(
        self,
        sentence: 'SentenceSegment',
        sentence_index: int,
        audio_array: np.ndarray,
        job: 'JobState',
        subtitle_manager: 'StreamingSubtitleManager'
    ) -> 'SentenceSegment':
        """
        Whisper è¡¥åˆ€ï¼ˆæ—¶ç©ºè§£è€¦ç‰ˆï¼šä»…å–æ–‡æœ¬ï¼‰

        æ ¸å¿ƒåŸåˆ™ï¼š
        - SenseVoice ç¡®å®šçš„æ—¶é—´è½´ï¼ˆstart/endï¼‰ä¸å¯å˜
        - ä»…ä½¿ç”¨ Whisper çš„æ–‡æœ¬ç»“æœ
        - æ–°æ–‡æœ¬ä½¿ç”¨ä¼ªå¯¹é½ç”Ÿæˆå­—çº§æ—¶é—´æˆ³

        Args:
            sentence: åŸå§‹å¥å­ï¼ˆç”± SenseVoice ç”Ÿæˆï¼‰
            sentence_index: å¥å­ç´¢å¼•
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            job: ä»»åŠ¡çŠ¶æ€
            subtitle_manager: æµå¼å­—å¹•ç®¡ç†å™¨

        Returns:
            SentenceSegment: æ›´æ–°åçš„å¥å­
        """
        from app.services.whisper_service import get_whisper_service
        from app.models.sensevoice_models import TextSource

        whisper_service = get_whisper_service()

        # ç¡®ä¿ Whisper æ¨¡å‹å·²åŠ è½½ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
        if not whisper_service.is_loaded:
            self.logger.info("åŠ è½½ Whisper æ¨¡å‹...")
            whisper_service.load_model()  # è‡ªåŠ¨ä¸‹è½½ CTranslate2 æ ¼å¼æ¨¡å‹

        # æå–å¯¹åº”æ—¶é—´æ®µçš„éŸ³é¢‘ï¼ˆå¢åŠ å‰å‘é‡å ï¼Œä¸º Whisper æä¾›ä¸Šä¸‹æ–‡é¢„çƒ­ï¼‰
        sr = 16000
        WHISPER_OVERLAP_SEC = 0.5  # Whisper ä¸Šä¸‹æ–‡é‡å æ—¶é•¿ï¼ˆç§’ï¼‰

        # è®¡ç®—é‡å åçš„èµ·å§‹ä½ç½®ï¼ˆä¸å°äº0ï¼‰
        overlap_start = max(0.0, sentence.start - WHISPER_OVERLAP_SEC)
        start_sample = int(overlap_start * sr)
        end_sample = int(sentence.end * sr)
        audio_segment = audio_array[start_sample:end_sample]

        # è®°å½•æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if overlap_start < sentence.start:
            self.logger.debug(
                f"Whisper è¡¥åˆ€æ·»åŠ  {sentence.start - overlap_start:.2f}s å‰å‘é‡å : "
                f"[{overlap_start:.2f}s, {sentence.end:.2f}s]"
            )

        # è·å–ä¸Šä¸‹æ–‡æç¤ºï¼ˆç°åœ¨ä½¿ç”¨æ¸…æ´—åçš„æ–‡æœ¬ï¼Œé¿å…ä¸‹åˆ’çº¿ç­‰åŸå§‹ tokenï¼‰
        context = subtitle_manager.get_context_window(sentence_index)

        # Whisper è½¬å½•ï¼ˆä»…å–æ–‡æœ¬ï¼Œå¼ƒç”¨æ—¶é—´æˆ³ï¼‰
        result = whisper_service.transcribe(
            audio=audio_segment,
            initial_prompt=context,
            language=getattr(job.settings, 'language', 'auto'),
            word_timestamps=False,  # ä¸éœ€è¦å­—çº§æ—¶é—´æˆ³ï¼Œä½¿ç”¨ä¼ªå¯¹é½
            condition_on_previous_text=False  # ç¦ç”¨å‰æ–‡æ¡ä»¶åŒ–ï¼Œé¿å…ä¸ initial_prompt å½¢æˆåŒé‡æç¤ºè¯å¢ç›Š
        )

        whisper_text = result.get('text', '').strip()
        segments = result.get('segments', [])

        # ========== ç¬¬ä¸‰é“é˜²çº¿: åŒæµæ ¡éªŒä¸ç½®ä¿¡åº¦é—¨æ§ ==========
        from app.services.text_normalizer import TextNormalizer

        # A. avg_logprob æ£€æŸ¥ï¼ˆæ¨¡å‹åœ¨ççŒœï¼‰
        avg_logprob = -0.5  # é»˜è®¤å€¼
        avg_no_speech = 0.0  # é»˜è®¤å€¼
        if segments:
            avg_logprob = sum(s.get('avg_logprob', -0.5) for s in segments) / len(segments)
            avg_no_speech = sum(s.get('no_speech_prob', 0.0) for s in segments) / len(segments)

            # ç†”æ–­æ¡ä»¶1: avg_logprob è¿‡ä½ï¼ˆæ¨¡å‹ä¸ç¡®ä¿¡ï¼‰
            if avg_logprob < -1.0:
                self.logger.warning(
                    f"Whisper ç†”æ–­(avg_logprob={avg_logprob:.2f} < -1.0) {sentence_index}: "
                    f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                )
                return sentence

            # ç†”æ–­æ¡ä»¶2: no_speech_prob é«˜ä½†ä»è¾“å‡ºæ–‡æœ¬ï¼ˆé™éŸ³æ®µè¢«å¼ºè¡Œç¿»è¯‘ï¼‰
            if avg_no_speech > 0.6 and whisper_text:
                self.logger.warning(
                    f"Whisper ç†”æ–­(no_speech={avg_no_speech:.2f} > 0.6) {sentence_index}: "
                    f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                )
                return sentence

        # B. å¹»è§‰æ­£åˆ™æ£€æµ‹ï¼ˆä½¿ç”¨å‡çº§åçš„ TextNormalizerï¼‰
        if TextNormalizer.is_whisper_hallucination(whisper_text):
            self.logger.warning(
                f"Whisper ç†”æ–­(å¹»è§‰æ£€æµ‹) {sentence_index}: '{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
            )
            return sentence

        # C. åŒæµé•¿åº¦å¯¹æ¯”
        sensevoice_text = sentence.text_clean or sentence.text or ""
        if sensevoice_text:
            len_sv = len(sensevoice_text)
            len_w = len(whisper_text)

            # é•¿åº¦æš´æ¶¨æ£€æµ‹
            if len_w > 3 * len_sv + 10:
                if avg_logprob > -0.5:
                    self.logger.info(
                        f"Whisper é•¿åº¦æš´æ¶¨ä½†ç½®ä¿¡åº¦é«˜(logprob={avg_logprob:.2f}) {sentence_index}, ç‰¹æƒæ”¾è¡Œ"
                    )
                else:
                    self.logger.warning(
                        f"Whisper ç†”æ–­(é•¿åº¦æš´æ¶¨ {len_w} > 3*{len_sv}+10) {sentence_index}: "
                        f"'{whisper_text[:50]}...', å›é€€åˆ° SenseVoice"
                    )
                    return sentence

        # D. åŸæœ‰æ£€æµ‹é€»è¾‘ï¼ˆä¿ç•™å…¼å®¹ï¼‰
        if context and whisper_text:
            # æ£€æµ‹æ˜¯å¦åŒ…å«å¤§é‡ä¸‹åˆ’çº¿ï¼ˆå¹»è§‰æ ‡å¿—ï¼‰
            underscore_ratio = whisper_text.count('_') / max(len(whisper_text), 1)
            if underscore_ratio > 0.3:  # è¶…è¿‡ 30% æ˜¯ä¸‹åˆ’çº¿
                self.logger.warning(
                    f"Whisper è¡¥åˆ€æ£€æµ‹åˆ°ä¸‹åˆ’çº¿å¹»è§‰ {sentence_index}: "
                    f"'{whisper_text[:50]}...' (ä¸‹åˆ’çº¿å æ¯” {underscore_ratio:.1%}), å›é€€åˆ° SenseVoice"
                )
                return sentence

            # æ£€æµ‹æ˜¯å¦é‡å¤äº†æç¤ºè¯å†…å®¹ï¼ˆç›¸ä¼¼åº¦è¿‡é«˜ï¼‰
            context_words = set(context.split())
            whisper_words = set(whisper_text.split())
            if len(context_words) > 0:
                overlap_ratio = len(context_words & whisper_words) / len(context_words)
                # å¦‚æœ Whisper è¾“å‡ºä¸ context é‡å åº¦è¶…è¿‡ 80%ï¼Œä¸”é•¿åº¦ç›¸è¿‘ï¼Œå¯èƒ½æ˜¯ç…§æŠ„
                if overlap_ratio > 0.8 and abs(len(whisper_text) - len(context)) < len(context) * 0.3:
                    self.logger.warning(
                        f"Whisper è¡¥åˆ€æ£€æµ‹åˆ°æç¤ºè¯é‡å¤ {sentence_index}: "
                        f"ä¸ context é‡å åº¦ {overlap_ratio:.1%}, å›é€€åˆ° SenseVoice"
                    )
                    return sentence

        if not whisper_text:
            self.logger.warning(f"Whisper è¡¥åˆ€è¿”å›ç©ºæ–‡æœ¬ï¼Œä¿ç•™åŸç»“æœ")
            return sentence

        # ä¿å­˜ Whisper å¤‡é€‰æ–‡æœ¬
        sentence.whisper_alternative = whisper_text

        # ä½¿ç”¨ä¼ªå¯¹é½æ›´æ–°å¥å­
        subtitle_manager.update_sentence(
            index=sentence_index,
            new_text=whisper_text,
            source=TextSource.WHISPER_PATCH,
            confidence=self._estimate_whisper_confidence(result)
        )

        return subtitle_manager.sentences[sentence_index]

    def _estimate_whisper_confidence(self, result: dict) -> float:
        """ä¼°ç®— Whisper ç»“æœç½®ä¿¡åº¦"""
        segments = result.get('segments', [])
        if not segments:
            return 0.7

        # åŸºäº avg_logprob å’Œ no_speech_prob è®¡ç®—
        total_logprob = sum(s.get('avg_logprob', -0.5) for s in segments)
        avg_logprob = total_logprob / len(segments)

        avg_no_speech = sum(s.get('no_speech_prob', 0.1) for s in segments) / len(segments)

        # è½¬æ¢ä¸º 0-1 ç½®ä¿¡åº¦
        confidence = min(1.0, max(0.0, 1.0 + avg_logprob))  # logprob è¶Šæ¥è¿‘ 0 è¶Šå¥½
        confidence *= (1.0 - avg_no_speech)  # no_speech è¶Šä½è¶Šå¥½

        return round(confidence, 3)

    async def _whisper_buffer_pool_process(
        self,
        patch_queue: List[Dict],
        audio_array: np.ndarray,
        job: 'JobState',
        subtitle_manager: 'StreamingSubtitleManager',
        progress_tracker
    ):
        """
        ä½¿ç”¨ Whisper ç¼“å†²æ± æ‰¹é‡å¤„ç†å¥å­ï¼ˆDEEP_LISTEN æ¨¡å¼ï¼‰

        ä¼˜åŠ¿:
        - ç´¯ç§¯å¤šä¸ªçŸ­ Chunkï¼Œæ‹¼æ¥åä¸€æ¬¡æ€§æ¨ç†
        - åˆ©ç”¨ Whisper é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œä»æ ¹æºæ¶ˆé™¤çŸ­éŸ³é¢‘å¹»è§‰
        - é•¿æ–‡æœ¬å›å¡«å¯¹é½åˆ°åŸå§‹æ—¶é—´æˆ³

        Args:
            patch_queue: éœ€è¦è¡¥åˆ€çš„å¥å­é˜Ÿåˆ—
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            job: ä»»åŠ¡çŠ¶æ€
            subtitle_manager: æµå¼å­—å¹•ç®¡ç†å™¨
            progress_tracker: è¿›åº¦è¿½è¸ªå™¨
        """
        from app.services.whisper_service import get_whisper_service
        from app.services.whisper_buffer_pool import WhisperBufferService, WhisperBufferConfig
        from app.services.text_normalizer import TextNormalizer
        from app.models.sensevoice_models import TextSource
        from app.services.progress_tracker import ProcessPhase

        whisper_service = get_whisper_service()

        # ç¡®ä¿ Whisper æ¨¡å‹å·²åŠ è½½
        if not whisper_service.is_loaded:
            self.logger.info("åŠ è½½ Whisper æ¨¡å‹...")
            whisper_service.load_model()

        # åˆå§‹åŒ–ç¼“å†²æ± æœåŠ¡
        buffer_config = WhisperBufferConfig(
            min_duration_sec=5.0,       # ç´¯ç§¯ 5 ç§’åè§¦å‘
            max_chunk_count=3,          # æˆ–ç´¯ç§¯ 3 ä¸ª Chunk åè§¦å‘
            silence_trigger_sec=1.0,    # é•¿é™éŸ³ä¹Ÿè§¦å‘
            max_duration_sec=30.0,      # æœ€å¤§ 30 ç§’
        )
        buffer_service = WhisperBufferService(buffer_config)

        sr = 16000
        processed_count = 0
        total_count = len(patch_queue)

        self.logger.info(f"Whisper ç¼“å†²æ± æ¨¡å¼: å¤„ç† {total_count} ä¸ªå¥å­")

        # æŒ‰é¡ºåºå¤„ç†å¥å­ï¼Œç´¯ç§¯åˆ°ç¼“å†²æ± 
        for idx, item in enumerate(patch_queue):
            sent_idx = item["index"]
            sentence = item["sentence"]

            # æå–éŸ³é¢‘ç‰‡æ®µ
            start_sample = int(sentence.start * sr)
            end_sample = int(sentence.end * sr)
            audio_segment = audio_array[start_sample:end_sample]

            # è·å– SenseVoice æ–‡æœ¬
            sv_text = getattr(sentence, 'text_clean', None) or sentence.text or ""
            sv_conf = sentence.confidence

            # æ·»åŠ åˆ°ç¼“å†²æ± 
            buffer_service.add_chunk(
                index=sent_idx,
                start=sentence.start,
                end=sentence.end,
                audio=audio_segment,
                sensevoice_text=sv_text,
                sensevoice_confidence=sv_conf
            )

            # æ£€æµ‹æ˜¯å¦ä¸ä¸‹ä¸€ä¸ªå¥å­æœ‰é•¿é™éŸ³é—´éš”
            has_long_silence = False
            if idx < len(patch_queue) - 1:
                next_sentence = patch_queue[idx + 1]["sentence"]
                gap = next_sentence.start - sentence.end
                if gap > buffer_config.silence_trigger_sec:
                    has_long_silence = True

            is_last = (idx == len(patch_queue) - 1)

            # æ£€æŸ¥æ˜¯å¦è§¦å‘ç¼“å†²æ± å¤„ç†
            if buffer_service.should_trigger(has_long_silence=has_long_silence, is_eof=is_last):
                # è·å–ä¸Šä¸‹æ–‡æç¤º
                context = subtitle_manager.get_context_window(sent_idx)

                # å¤„ç†ç¼“å†²æ± 
                aligned_results = buffer_service.process_buffer(
                    whisper_service=whisper_service,
                    language=getattr(job.settings, 'language', 'auto'),
                    initial_prompt=context
                )

                # åº”ç”¨å¯¹é½ç»“æœ
                for result in aligned_results:
                    chunk_idx = result["chunk_index"]
                    whisper_text = result.get("whisper_text", "").strip()
                    whisper_conf = result.get("whisper_confidence", 0.5)
                    sv_text_orig = result.get("sensevoice_text", "")

                    # è·³è¿‡ç©ºç»“æœ
                    if not whisper_text:
                        self.logger.debug(f"ç¼“å†²æ± å¯¹é½: Chunk {chunk_idx} Whisper è¾“å‡ºä¸ºç©ºï¼Œä¿ç•™ SenseVoice")
                        processed_count += 1
                        continue

                    # å¹»è§‰æ£€æµ‹
                    if TextNormalizer.is_whisper_hallucination(whisper_text):
                        self.logger.warning(
                            f"ç¼“å†²æ± å¯¹é½: Chunk {chunk_idx} Whisper å¹»è§‰ '{whisper_text[:30]}...', ä¿ç•™ SenseVoice"
                        )
                        processed_count += 1
                        continue

                    # åŒæµé•¿åº¦å¯¹æ¯”
                    if sv_text_orig:
                        len_sv = len(sv_text_orig)
                        len_w = len(whisper_text)
                        if len_w > 3 * len_sv + 10 and whisper_conf < 0.7:
                            self.logger.warning(
                                f"ç¼“å†²æ± å¯¹é½: Chunk {chunk_idx} é•¿åº¦æš´æ¶¨ ({len_w} > 3*{len_sv}+10), ä¿ç•™ SenseVoice"
                            )
                            processed_count += 1
                            continue

                    # æ›´æ–°å¥å­
                    if chunk_idx in subtitle_manager.sentences:
                        subtitle_manager.update_sentence(
                            index=chunk_idx,
                            new_text=whisper_text,
                            source=TextSource.WHISPER_PATCH,
                            confidence=whisper_conf
                        )
                        self.logger.debug(
                            f"ç¼“å†²æ± å¯¹é½: Chunk {chunk_idx} æ›´æ–°ä¸º '{whisper_text[:50]}...'"
                        )

                    processed_count += 1

                # æ›´æ–°è¿›åº¦
                progress_tracker.update_phase(ProcessPhase.WHISPER_PATCH, increment=len(aligned_results))

        # å¤„ç†ç¼“å†²æ± ä¸­çš„å‰©ä½™å†…å®¹
        if not buffer_service.is_empty:
            context = subtitle_manager.get_context_window(patch_queue[-1]["index"]) if patch_queue else ""
            remaining_results = buffer_service.flush_remaining(
                whisper_service=whisper_service,
                language=getattr(job.settings, 'language', 'auto'),
                initial_prompt=context
            )

            for result in remaining_results:
                chunk_idx = result["chunk_index"]
                whisper_text = result.get("whisper_text", "").strip()
                whisper_conf = result.get("whisper_confidence", 0.5)

                if whisper_text and not TextNormalizer.is_whisper_hallucination(whisper_text):
                    if chunk_idx in subtitle_manager.sentences:
                        subtitle_manager.update_sentence(
                            index=chunk_idx,
                            new_text=whisper_text,
                            source=TextSource.WHISPER_PATCH,
                            confidence=whisper_conf
                        )
                processed_count += 1

            progress_tracker.update_phase(ProcessPhase.WHISPER_PATCH, increment=len(remaining_results))

        self.logger.info(f"Whisper ç¼“å†²æ± å¤„ç†å®Œæˆ: {processed_count}/{total_count} ä¸ªå¥å­")

    async def _post_process_enhancement(
        self,
        sentences: List['SentenceSegment'],
        audio_array: np.ndarray,
        job: 'JobState',
        subtitle_manager: 'StreamingSubtitleManager',
        solution_config: 'SolutionConfig'
    ) -> List['SentenceSegment']:
        """
        åå¤„ç†å¢å¼ºå±‚ï¼ˆæ‰€æœ‰ Chunk è½¬å½•å®Œæˆåæ‰§è¡Œï¼‰

        æ ¹æ®ç”¨æˆ·é…ç½®æ‰§è¡Œï¼š
        1. ä½ç½®ä¿¡åº¦å¥å­ â†’ Whisper è¡¥åˆ€ï¼ˆä»…æ–‡æœ¬ + ä¼ªå¯¹é½ï¼‰
        2. [å¯é€‰] LLM æ ¡å¯¹
        3. [å¯é€‰] LLM ç¿»è¯‘

        æ³¨æ„ï¼šè¿™ä¸æ˜¯ç†”æ–­ï¼Œç†”æ–­åœ¨è½¬å½•é˜¶æ®µå·²ç»å¤„ç†å®Œæˆ

        Args:
            sentences: æ‰€æœ‰å¥å­åˆ—è¡¨
            audio_array: å®Œæ•´éŸ³é¢‘æ•°ç»„
            job: ä»»åŠ¡çŠ¶æ€
            subtitle_manager: æµå¼å­—å¹•ç®¡ç†å™¨
            solution_config: æ–¹æ¡ˆé…ç½®

        Returns:
            List[SentenceSegment]: å¢å¼ºåçš„å¥å­åˆ—è¡¨
        """
        from app.services.progress_tracker import get_progress_tracker, ProcessPhase
        from app.services.solution_matrix import EnhancementMode, ProofreadMode, TranslateMode
        from app.core.thresholds import needs_whisper_patch, is_critical_patch_needed

        progress_tracker = get_progress_tracker(job.job_id, solution_config.preset_id)

        # è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤æ–¹æ³•è¢«è°ƒç”¨
        self.logger.debug(f"å¼€å§‹åå¤„ç†å¢å¼º: {len(sentences)} å¥, enhancement={solution_config.enhancement.value}")

        # 1. æ”¶é›†éœ€è¦ Whisper è¡¥åˆ€çš„å¥å­ï¼ˆå«å¼ºåˆ¶è¡¥åˆ€ã€å¸¸è§„è¡¥åˆ€ã€åƒåœ¾æ ¸æŸ¥ï¼‰
        patch_queue = []
        # é˜ˆå€¼é…ç½®
        GARBAGE_CONFIDENCE_THRESHOLD = 0.4  # ä½äºæ­¤å€¼è§¦å‘ Whisper ä»²è£

        for i, sentence in enumerate(sentences):
            should_patch = False
            is_critical = False
            is_trash_suspect = False  # æ˜¯å¦æ˜¯"åƒåœ¾å«Œç–‘"éœ€è¦ Whisper ä»²è£

            # === DEEP_LISTEN å¿«é€Ÿè·¯å¾„ ===
            # DEEP_LISTEN æ¨¡å¼ä¸‹æ‰€æœ‰å¥å­éƒ½è¦è¡¥åˆ€ï¼Œç›´æ¥å…¥é˜Ÿï¼Œè·³è¿‡åç»­å†—ä½™åˆ¤æ–­
            if solution_config.enhancement == EnhancementMode.DEEP_LISTEN:
                patch_queue.append({
                    "index": i,
                    "sentence": sentence,
                    "is_critical": False,
                    "is_trash_suspect": False
                })
                self.logger.debug(f"[DEEP_LISTEN] å¥å­{i} ç›´æ¥åŠ å…¥åŒæµé˜Ÿåˆ—")
                continue

            # è®¡ç®—ç‰‡æ®µæ—¶é•¿å’Œæ¸…æ´—åæ–‡æœ¬é•¿åº¦
            duration = sentence.end - sentence.start
            text_clean = getattr(sentence, 'text_clean', None) or sentence.text
            clean_text = text_clean.strip() if text_clean else ""
            text_length = len(clean_text)

            # ã€é˜¶æ®µå››ã€‘å¼ºåˆ¶å…³é”®è¡¥åˆ€æ¡ä»¶ï¼ˆæ— è®ºç”¨æˆ·è®¾ç½®å¦‚ä½•ï¼Œå¿…é¡»ä¿®ï¼‰
            if is_critical_patch_needed(clean_text, duration, sentence.confidence):
                should_patch = True
                is_critical = True
                self.logger.warning(
                    f"è§¦å‘å¼ºåˆ¶è¡¥åˆ€: '{clean_text}' "
                    f"(conf={sentence.confidence:.2f}, dur={duration:.2f}s)"
                )

            # ã€æ–°å¢ã€‘ä½ç½®ä¿¡åº¦"äºŒæ¬¡å®‰æ£€"é€»è¾‘
            # å¦‚æœæ•´å¥ç½®ä¿¡åº¦æä½ï¼ˆå¯èƒ½æ˜¯å¹»è§‰/å™ªéŸ³ï¼‰ï¼Œç”¨ Whisper ä»²è£
            elif sentence.confidence < GARBAGE_CONFIDENCE_THRESHOLD:
                should_patch = True
                is_trash_suspect = True
                self.logger.info(
                    f"è§¦å‘ä½ç½®ä¿¡åº¦æ ¸æŸ¥: '{clean_text[:30]}...' "
                    f"(conf={sentence.confidence:.2f})"
                )

            # ã€æ–°å¢ã€‘å­—çº§å¼ºåˆ¶è¡¥åˆ€ï¼ˆç‹¬ç«‹æ£€æŸ¥ï¼Œä¸å— enhancement é…ç½®å½±å“ï¼‰
            # æ¡ä»¶1: å•å­—ç¬¦å®è¯ä¸”ç½®ä¿¡åº¦ < 0.9
            # æ¡ä»¶2: ä»»æ„å®è¯ç½®ä¿¡åº¦æä½ (< 0.35)ï¼Œå‡ ä¹è‚¯å®šæ˜¯è¯†åˆ«é”™è¯¯
            if not should_patch and sentence.words:
                SINGLE_CHAR_CONF_THRESHOLD = 0.9  # å•å­—ç¬¦è¯çš„é«˜ç½®ä¿¡åº¦è¦æ±‚
                CRITICAL_WORD_CONF_THRESHOLD = 0.35  # æä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼å‡ ä¹è‚¯å®šæ˜¯é”™è¯¯ï¼‰
                LOW_CONF_WORD_COUNT_THRESHOLD = 3  # å¤šä¸ªä½ç½®ä¿¡åº¦è¯çš„æ•°é‡é˜ˆå€¼
                LOW_WORD_CONF_THRESHOLD = 0.5  # ä½ç½®ä¿¡åº¦è¯çš„é˜ˆå€¼

                low_conf_word_count = 0  # ç»Ÿè®¡ä½ç½®ä¿¡åº¦è¯æ•°é‡

                for w in sentence.words:
                    # å»é™¤ç©ºç™½å’Œ SentencePiece è¾¹ç•Œæ ‡è®° (U+2581)
                    word_text = w.word.strip().lstrip('\u2581').lower()
                    word_conf = w.confidence

                    # è·³è¿‡ç©ºå­—ç¬¦ã€æ ‡ç‚¹
                    if not word_text or (len(word_text) == 1 and not word_text.isalnum()):
                        continue

                    # æ¡ä»¶1: å•å­—ç¬¦å®è¯ + ç½®ä¿¡åº¦ < 0.9
                    if len(word_text) == 1 and word_text.isalnum() and word_conf < SINGLE_CHAR_CONF_THRESHOLD:
                        should_patch = True
                        is_critical = True
                        self.logger.warning(
                            f"è§¦å‘å­—çº§å•å­—ç¬¦å¼ºåˆ¶è¡¥åˆ€: Sentence {i} å«å•å­—ç¬¦è¯ '{word_text}' "
                            f"(conf={word_conf:.2f})"
                        )
                        break

                    # æ¡ä»¶2: ä»»æ„å®è¯ç½®ä¿¡åº¦æä½ (< 0.35)ï¼Œå‡ ä¹è‚¯å®šæ˜¯è¯†åˆ«é”™è¯¯
                    if len(word_text) >= 2 and word_conf < CRITICAL_WORD_CONF_THRESHOLD:
                        should_patch = True
                        is_critical = True
                        self.logger.warning(
                            f"è§¦å‘å­—çº§æä½ç½®ä¿¡åº¦å¼ºåˆ¶è¡¥åˆ€: Sentence {i} å«æä½ç½®ä¿¡åº¦è¯ '{word_text}' "
                            f"(conf={word_conf:.2f})"
                        )
                        break

                    # ç»Ÿè®¡ä½ç½®ä¿¡åº¦è¯æ•°é‡
                    if len(word_text) >= 2 and word_conf < LOW_WORD_CONF_THRESHOLD:
                        low_conf_word_count += 1

                # æ¡ä»¶3: å¤šä¸ªä½ç½®ä¿¡åº¦è¯ï¼ˆ>= 3ä¸ªï¼‰ï¼Œæ•´å¥å¯èƒ½æœ‰é—®é¢˜
                if not should_patch and low_conf_word_count >= LOW_CONF_WORD_COUNT_THRESHOLD:
                    should_patch = True
                    is_critical = True
                    self.logger.warning(
                        f"è§¦å‘å­—çº§å¤šä½ç½®ä¿¡åº¦è¯å¼ºåˆ¶è¡¥åˆ€: Sentence {i} å« {low_conf_word_count} ä¸ªä½ç½®ä¿¡åº¦è¯"
                    )

            # å¸¸è§„è¡¥åˆ€æ¡ä»¶ï¼ˆéµå¾ªç”¨æˆ·è®¾ç½®ï¼Œä»… SMART_PATCH æ¨¡å¼ï¼‰
            # æ³¨: DEEP_LISTEN æ¨¡å¼å·²åœ¨å¾ªç¯å¼€å¤´é€šè¿‡å¿«é€Ÿè·¯å¾„å¤„ç†
            if not should_patch and solution_config.enhancement == EnhancementMode.SMART_PATCH:
                # SMART_PATCH æ¨¡å¼: ä»…ä½ç½®ä¿¡åº¦å¥å­è§¦å‘è¡¥åˆ€
                # ã€é˜¶æ®µäº”ã€‘æ„å»ºå­—çº§æ—¶é—´æˆ³åˆ—è¡¨
                words_data = [{"word": w.word, "confidence": w.confidence} for w in sentence.words]

                # å¢å¼ºç‰ˆè¡¥åˆ€åˆ¤æ–­ï¼šç½®ä¿¡åº¦ã€çŸ­ç‰‡æ®µã€å•å­—ç¬¦ã€å­—çº§è§¦å‘
                if needs_whisper_patch(
                    sentence.confidence,
                    duration=duration,
                    text_length=text_length,
                    words=words_data  # ã€é˜¶æ®µäº”ã€‘ä¼ å…¥å­—çº§æ•°æ®
                ):
                    should_patch = True

            if should_patch:
                patch_queue.append({
                    "index": i,
                    "sentence": sentence,
                    "is_critical": is_critical,
                    "is_trash_suspect": is_trash_suspect
                })

        # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºè¡¥åˆ€é˜Ÿåˆ—ç»Ÿè®¡
        self.logger.debug(f"è¡¥åˆ€é˜Ÿåˆ—æ„å»ºå®Œæˆ: {len(patch_queue)} ä¸ªå¥å­éœ€è¦è¡¥åˆ€")

        # 2. Whisper è¡¥åˆ€é˜¶æ®µï¼ˆå«ä»²è£åˆ¤å†³ï¼‰
        if patch_queue:
            progress_tracker.start_phase(ProcessPhase.WHISPER_PATCH, len(patch_queue), "Whisper è¡¥åˆ€ä¸­...")

            # === DEEP_LISTEN æ¨¡å¼: ä½¿ç”¨ Whisper ç¼“å†²æ± æ‰¹é‡å¤„ç† ===
            if solution_config.enhancement == EnhancementMode.DEEP_LISTEN:
                await self._whisper_buffer_pool_process(
                    patch_queue=patch_queue,
                    audio_array=audio_array,
                    job=job,
                    subtitle_manager=subtitle_manager,
                    progress_tracker=progress_tracker
                )
            else:
                # === SMART_PATCH æ¨¡å¼: é€å¥å¤„ç† ===
                for idx, item in enumerate(patch_queue):
                    sent_idx = item["index"]
                    sentence = item["sentence"]
                    is_trash_suspect = item["is_trash_suspect"]

                    # æ‰§è¡Œ Whisper è¡¥åˆ€å¹¶è·å–ä»²è£ç»“æœ
                    await self._whisper_text_patch_with_arbitration(
                        sentence=sentence,
                        sentence_index=sent_idx,
                        audio_array=audio_array,
                        job=job,
                        subtitle_manager=subtitle_manager,
                        is_trash_suspect=is_trash_suspect
                    )
                    progress_tracker.update_phase(ProcessPhase.WHISPER_PATCH, increment=1)

            progress_tracker.complete_phase(ProcessPhase.WHISPER_PATCH)

        # 3. æ¸…ç†è¢«æ ‡è®°ä¸ºåƒåœ¾çš„å¥å­
        deleted_count = subtitle_manager.remove_marked_sentences()
        if deleted_count > 0:
            self.logger.info(f"Whisper ä»²è£ï¼šåˆ é™¤äº† {deleted_count} ä¸ªç¡®è®¤ä¸ºåƒåœ¾çš„ç‰‡æ®µ")

        # 4. [å¯é€‰] LLM æ ¡å¯¹
        if solution_config.proofread != ProofreadMode.OFF:
            # TODO: å®ç° LLM æ ¡å¯¹
            self.logger.info("LLM æ ¡å¯¹åŠŸèƒ½å¾…å®ç°")

        # 4. [å¯é€‰] LLM ç¿»è¯‘
        if solution_config.translate != TranslateMode.OFF:
            # TODO: å®ç° LLM ç¿»è¯‘
            self.logger.info("LLM ç¿»è¯‘åŠŸèƒ½å¾…å®ç°")

        return subtitle_manager.get_all_sentences()

    async def _process_video_sensevoice(self, job: 'JobState'):
        """
        SenseVoice ä¸»å¤„ç†æµç¨‹ï¼ˆv2.1 æ¦‚å¿µæ¾„æ¸…ç‰ˆï¼‰

        æµç¨‹è¯´æ˜ï¼š
        1-4: å‡†å¤‡é˜¶æ®µï¼ˆéŸ³é¢‘æå–ã€VADã€é¢‘è°±åˆ†è¯Šã€æŒ‰éœ€åˆ†ç¦»ï¼‰
        5: è½¬å½•é˜¶æ®µï¼ˆé€Chunkè½¬å½• + ç†”æ–­å›æº¯ï¼‰
        6-8: åå¤„ç†å¢å¼ºé˜¶æ®µï¼ˆWhisperè¡¥åˆ€ã€LLMæ ¡å¯¹/ç¿»è¯‘ï¼‰
        9: è¾“å‡ºé˜¶æ®µï¼ˆç”Ÿæˆå­—å¹•ï¼‰
        """
        from app.services.streaming_subtitle import get_streaming_subtitle_manager, remove_streaming_subtitle_manager
        from app.services.progress_tracker import get_progress_tracker, remove_progress_tracker, ProcessPhase
        from app.services.solution_matrix import SolutionConfig, TranslateMode
        from app.services.audio_spectrum_classifier import get_spectrum_classifier
        from app.services.demucs_service import get_demucs_service
        from app.services.sse_service import get_sse_manager
        from app.models.circuit_breaker_models import SeparationLevel
        from pathlib import Path

        def push_signal_event(sse_manager, job_id: str, signal_code: str, message: str = ""):
            """æ¨é€ä¿¡å·äº‹ä»¶ï¼ˆä½¿ç”¨ç»Ÿä¸€å‘½åç©ºé—´æ ¼å¼ï¼‰"""
            sse_manager.broadcast_sync(
                f"job:{job_id}",
                f"signal.{signal_code}",
                {"signal": signal_code, "message": message}
            )

        # è·å–æ–¹æ¡ˆé…ç½® - v3.5: ä¼˜å…ˆä½¿ç”¨æ–°ç‰ˆé…ç½®ï¼Œå…¼å®¹æ—§ç‰ˆ
        # æ£€æŸ¥æ˜¯å¦æœ‰ v3.5 æ–°ç‰ˆé…ç½®
        if hasattr(job.settings, 'transcription') and hasattr(job.settings.transcription, 'transcription_profile'):
            # v3.5 æ–°ç‰ˆé…ç½®: ä» job.settings åˆ›å»º SolutionConfig
            solution_config = SolutionConfig.from_job_settings(job.settings)
            self.logger.info(f"ä½¿ç”¨ v3.5 é…ç½®: profile={job.settings.transcription.transcription_profile}, "
                           f"enhancement={solution_config.enhancement.value}, "
                           f"proofread={solution_config.proofread.value}")
        else:
            # æ—§ç‰ˆé…ç½®: ä» sensevoice.preset_id åˆ›å»º
            preset_id = getattr(job.settings.sensevoice, 'preset_id', 'default')
            solution_config = SolutionConfig.from_preset(preset_id)
            self.logger.info(f"ä½¿ç”¨æ—§ç‰ˆé¢„è®¾: {preset_id}")

        # åˆå§‹åŒ–ç®¡ç†å™¨
        subtitle_manager = get_streaming_subtitle_manager(job.job_id)
        progress_tracker = get_progress_tracker(job.job_id, solution_config.preset_id)

        try:
            # 1. éŸ³é¢‘æå–
            progress_tracker.start_phase(ProcessPhase.EXTRACT, 1, "æå–éŸ³é¢‘...")
            audio_array, sr = self._extract_audio_with_array(job.input_path, job, target_sr=16000)

            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶ä¾›æ³¢å½¢å›¾ä½¿ç”¨
            import soundfile as sf
            audio_path = Path(job.dir) / "audio.wav"
            sf.write(str(audio_path), audio_array, sr)
            self.logger.info(f"éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜: {audio_path}")

            progress_tracker.complete_phase(ProcessPhase.EXTRACT)

            # 2. VAD ç‰©ç†åˆ‡åˆ†
            progress_tracker.start_phase(ProcessPhase.VAD, 1, "VAD åˆ‡åˆ†...")
            raw_vad_segments = self._memory_vad_split(audio_array, sr, job)

            # ã€é˜¶æ®µäºŒã€‘Post-VAD æ™ºèƒ½åˆå¹¶å±‚
            # max_gap=1.0s æ¶µç›–æ…¢è¯­é€Ÿåœºæ™¯ï¼Œç¢ç‰‡ä¿æŠ¤é¿å…çŸ­ç‰‡æ®µå­¤ç«‹
            vad_segments = self._merge_vad_segments(
                raw_vad_segments,
                max_gap=1.0,
                max_duration=25.0,
                min_fragment_duration=1.0
            )
            progress_tracker.complete_phase(ProcessPhase.VAD)

            # 3. é¢‘è°±åˆ†è¯Šï¼ˆChunkçº§åˆ«ï¼‰
            progress_tracker.start_phase(ProcessPhase.BGM_DETECT, 1, "é¢‘è°±åˆ†è¯Š...")
            spectrum_classifier = get_spectrum_classifier()
            diagnoses = spectrum_classifier.diagnose_chunks(
                [(audio_array[int(s['start']*sr):int(s['end']*sr)], s['start'], s['end'])
                 for s in vad_segments],
                sr=sr
            )
            progress_tracker.complete_phase(ProcessPhase.BGM_DETECT)

            # 4. åˆå§‹åŒ– Chunk çŠ¶æ€ + æŒ‰éœ€äººå£°åˆ†ç¦»
            chunk_states = self._init_chunk_states(vad_segments, audio_array, sr)
            demucs_service = get_demucs_service()

            chunks_to_separate = [(i, chunk_states[i], diagnoses[i])
                                  for i in range(len(diagnoses))
                                  if diagnoses[i].need_separation]

            if chunks_to_separate:
                progress_tracker.start_phase(ProcessPhase.DEMUCS, len(chunks_to_separate), "äººå£°åˆ†ç¦»...")
                for sep_idx, (chunk_idx, chunk_state, diag) in enumerate(chunks_to_separate):
                    # æ‰§è¡Œåˆ†ç¦»ï¼Œæ›´æ–° current_audio
                    separated_audio = demucs_service.separate_chunk(
                        audio=chunk_state.original_audio,
                        model=diag.recommended_model,
                        sr=sr
                    )
                    chunk_state.current_audio = separated_audio
                    chunk_state.separation_level = (
                        SeparationLevel.HTDEMUCS if diag.recommended_model == "htdemucs"
                        else SeparationLevel.MDX_EXTRA
                    )
                    chunk_state.separation_model_used = diag.recommended_model
                    progress_tracker.update_phase(ProcessPhase.DEMUCS, increment=1)
                progress_tracker.complete_phase(ProcessPhase.DEMUCS)
            else:
                # æ²¡æœ‰ Chunk éœ€è¦åˆ†ç¦»ï¼Œå¸è½½ Demucs æ¨¡å‹é‡Šæ”¾æ˜¾å­˜
                if demucs_service.is_model_loaded():
                    self.logger.info("æ‰€æœ‰ Chunk å‡ä¸ºçº¯å‡€äººå£°ï¼Œå¸è½½ Demucs æ¨¡å‹é‡Šæ”¾æ˜¾å­˜")
                    demucs_service.unload_model()

            # 5. é€Chunkè½¬å½• + ç†”æ–­å›æº¯ï¼ˆè½¬å½•å±‚æ ¸å¿ƒï¼‰
            progress_tracker.start_phase(ProcessPhase.SENSEVOICE, len(chunk_states), "SenseVoice è½¬å½•...")
            all_sentences = []

            for chunk_state in chunk_states:
                # å•ä¸ª Chunk è½¬å½•ï¼ˆå«ç†”æ–­å›æº¯å¾ªç¯ï¼‰
                sentences = await self._transcribe_chunk_with_fusing(
                    chunk_state=chunk_state,
                    job=job,
                    subtitle_manager=subtitle_manager,
                    demucs_service=demucs_service
                )
                all_sentences.extend(sentences)
                progress_tracker.update_phase(ProcessPhase.SENSEVOICE, increment=1)

            progress_tracker.complete_phase(ProcessPhase.SENSEVOICE)

            # ä¿å­˜åŸå§‹è½¬å½•æ•°æ®ï¼ˆæœªåˆ†å¥çš„å®Œæ•´æ•°æ®ï¼‰
            self._save_raw_transcription(job, all_sentences)

            # 6. åå¤„ç†å¢å¼ºï¼ˆWhisperè¡¥åˆ€ã€LLMæ ¡å¯¹/ç¿»è¯‘ï¼‰
            final_results = await self._post_process_enhancement(
                all_sentences, audio_array, job, subtitle_manager, solution_config
            )

            # 7. ç”Ÿæˆå­—å¹•
            progress_tracker.start_phase(ProcessPhase.SRT, 1, "ç”Ÿæˆå­—å¹•...")
            output_path = str(Path(job.dir) / f"{job.job_id}.srt")
            self._generate_subtitle_from_sentences(
                final_results,
                output_path,
                include_translation=(solution_config.translate != TranslateMode.OFF)
            )
            progress_tracker.complete_phase(ProcessPhase.SRT)

            # 8. å®Œæˆ
            job.status = 'completed'
            push_signal_event(get_sse_manager(), job.job_id, "job_complete", "å¤„ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"SenseVoice å¤„ç†å¤±è´¥: {e}", exc_info=True)
            job.status = 'failed'
            job.error = str(e)
            push_signal_event(get_sse_manager(), job.job_id, "job_failed", str(e))
            raise

        finally:
            # æ¸…ç†èµ„æº
            remove_streaming_subtitle_manager(job.job_id)
            remove_progress_tracker(job.job_id)


# å•ä¾‹å¤„ç†å™¨
_service_instance: Optional[TranscriptionService] = None


def get_transcription_service(root: str) -> TranscriptionService:
    """è·å–è½¬å½•æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _service_instance
    if _service_instance is None:
        _service_instance = TranscriptionService(root)
    return _service_instance