"""
任务相关的数据模型定义 - v3.5 重构版

与 preset_models.py 中的 1+3 预设模式保持一致
"""
from dataclasses import dataclass, field, asdict
from typing import List, Dict, Optional, TYPE_CHECKING, Any
import torch

# 使用TYPE_CHECKING避免循环导入
if TYPE_CHECKING:
    from app.services.cpu_affinity_service import CPUAffinityConfig


# ========== 分组一: 预处理与音频设置 ==========

@dataclass
class PreprocessingConfig:
    """
    预处理与音频配置 (Demucs 人声分离 + 频谱分诊 + 熔断回溯)
    对应文档分组一
    """
    # ========== 人声分离配置 ==========
    # 人声分离策略: off/auto/force_on
    demucs_strategy: str = "auto"

    # 分离模型: htdemucs/htdemucs_ft/mdx_q/mdx_extra
    demucs_model: str = "htdemucs"

    # 分离预测次数: 1-5
    demucs_shifts: int = 1

    # 分离模式: global/on_demand (新增)
    separation_mode: str = "on_demand"

    # ========== 频谱分诊配置 ==========
    # 是否启用频谱分诊 (新增)
    enable_spectral_triage: bool = True

    # 分诊灵敏度: 0.0-1.0 (默认从 spectrum_thresholds.py: 0.35)
    spectrum_threshold: float = 0.35

    # ========== 熔断回溯配置 (新增) ==========
    # 是否启用熔断回溯
    enable_fuse_breaker: bool = True

    # 最大重试次数（默认1，只升级到 HTDEMUCS）
    fuse_max_retry: int = 1

    # 置信度阈值
    fuse_confidence_threshold: float = 0.5

    # 是否启用第二次自动升级到 MDX_EXTRA（默认False，可选配置）
    fuse_auto_upgrade: bool = False

    # ========== VAD配置 ==========
    # VAD 静音过滤开关
    vad_filter: bool = True


# ========== 分组二: 转录核心设置 ==========

@dataclass
class TranscriptionConfig:
    """
    转录核心配置 (ASR 引擎)
    对应文档分组二
    """
    # 转录流水线模式: sensevoice_only/sv_whisper_patch/sv_whisper_dual
    transcription_profile: str = "sensevoice_only"

    # 主引擎运行设备: auto/cpu
    sensevoice_device: str = "auto"

    # 辅助/补刀模型: tiny/small/medium/large-v3
    whisper_model: str = "medium"

    # 补刀触发阈值: 0.0-1.0
    patching_threshold: float = 0.60


# ========== 分组三: 增强与润色设置 ==========

@dataclass
class RefinementConfig:
    """
    增强与润色配置 (LLM)
    对应文档分组三
    """
    # LLM 任务目标: off/proofread/translate
    llm_task: str = "off"

    # 介入范围: sparse/global
    llm_scope: str = "sparse"

    # 稀疏校对阈值: 0.0-1.0
    sparse_threshold: float = 0.70

    # 目标语言
    target_language: str = "zh"

    # 模型提供商: openai_compatible/local_ollama
    llm_provider: str = "openai_compatible"

    # 模型名称
    llm_model_name: str = "gpt-4o-mini"

    # API Key (运行时注入，不持久化)
    api_key: Optional[str] = None

    # 自定义 API 地址
    base_url: Optional[str] = None


# ========== 分组四: 计算与系统设置 ==========

@dataclass
class ComputeConfig:
    """
    计算与系统配置
    对应文档分组四
    """
    # 并发调度策略: auto/parallel/serial
    concurrency_strategy: str = "auto"

    # GPU 选择
    gpu_id: int = 0

    # 输出格式列表
    output_formats: List[str] = field(default_factory=lambda: ["srt"])

    # 临时文件策略: delete_on_complete/keep
    temp_file_policy: str = "delete_on_complete"


# ========== 兼容性: 保留旧的设置类 (带别名) ==========
# 这些类保留用于向后兼容，新代码应使用上面的新结构

@dataclass
class DemucsSettings:
    """
    Demucs人声分离配置 (兼容旧版)
    新代码请使用 PreprocessingConfig
    """
    # 基础配置 - 映射到新字段
    enabled: bool = True                        # 对应 demucs_strategy != "off"
    mode: str = "auto"                          # 对应 demucs_strategy

    # 分级模型配置 - 简化为单一 model 字段
    weak_model: str = "htdemucs"
    strong_model: str = "htdemucs"
    fallback_model: str = "htdemucs"
    auto_escalation: bool = True
    max_escalations: int = 1

    # BGM检测阈值 - 映射到 spectrum_threshold
    bgm_light_threshold: float = 0.02
    bgm_heavy_threshold: float = 0.15

    # 质量评估阈值
    retry_threshold_logprob: float = -0.8
    retry_threshold_no_speech: float = 0.6

    # 熔断配置
    circuit_breaker_enabled: bool = True
    consecutive_threshold: int = 3
    ratio_threshold: float = 0.2

    # 熔断处理策略
    on_break: str = "continue"
    mark_problem_segments: bool = True
    problem_segment_suffix: str = "[?]"

    # 质量预设
    quality_preset: str = "balanced"


@dataclass
class SenseVoiceSettings:
    """
    SenseVoice 转录引擎配置 (兼容旧版)
    新代码请使用 TranscriptionConfig + RefinementConfig
    """
    # 预设方案
    preset_id: str = "default"

    # 增强模式 - 映射到 transcription_profile
    enhancement: str = "off"                    # off/smart_patch/deep_listen

    # 校对模式 - 映射到 llm_task + llm_scope
    proofread: str = "off"                      # off/sparse/full

    # 翻译模式 - 映射到 llm_task
    translate: str = "off"                      # off/full/partial
    target_language: str = "en"

    # 阈值配置 - 映射到 patching_threshold
    confidence_threshold: float = 0.6
    whisper_patch_threshold: float = 0.5


# ========== 任务设置 ==========

@dataclass
class JobSettings:
    """
    转录任务设置 - v3.5 重构版

    支持两种配置方式:
    1. 新版 (推荐): 使用 task_config 字段
    2. 旧版 (兼容): 使用 demucs/sensevoice 字段
    """
    # === 转录引擎选择 (兼容旧版) ===
    engine: str = "sensevoice"                  # whisper/sensevoice

    # === 旧版设置 (兼容) ===
    model: str = "medium"
    compute_type: str = "float16"
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    batch_size: int = 16
    word_timestamps: bool = False
    cpu_affinity: Optional["CPUAffinityConfig"] = None
    demucs: DemucsSettings = field(default_factory=DemucsSettings)
    sensevoice: SenseVoiceSettings = field(default_factory=SenseVoiceSettings)

    # === 新版 1+3 预设配置 ===
    # 选择的宏预设 ID (fast/balanced/quality/custom)
    preset_id: str = "balanced"

    # 四个设置分组
    preprocessing: PreprocessingConfig = field(default_factory=PreprocessingConfig)
    transcription: TranscriptionConfig = field(default_factory=TranscriptionConfig)
    refinement: RefinementConfig = field(default_factory=RefinementConfig)
    compute: ComputeConfig = field(default_factory=ComputeConfig)

    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            # 新版配置
            "preset_id": self.preset_id,
            "preprocessing": {
                "demucs_strategy": self.preprocessing.demucs_strategy,
                "demucs_model": self.preprocessing.demucs_model,
                "demucs_shifts": self.preprocessing.demucs_shifts,
                "spectrum_threshold": self.preprocessing.spectrum_threshold,
                "vad_filter": self.preprocessing.vad_filter,
            },
            "transcription": {
                "transcription_profile": self.transcription.transcription_profile,
                "sensevoice_device": self.transcription.sensevoice_device,
                "whisper_model": self.transcription.whisper_model,
                "patching_threshold": self.transcription.patching_threshold,
            },
            "refinement": {
                "llm_task": self.refinement.llm_task,
                "llm_scope": self.refinement.llm_scope,
                "sparse_threshold": self.refinement.sparse_threshold,
                "target_language": self.refinement.target_language,
                "llm_provider": self.refinement.llm_provider,
                "llm_model_name": self.refinement.llm_model_name,
            },
            "compute": {
                "concurrency_strategy": self.compute.concurrency_strategy,
                "gpu_id": self.compute.gpu_id,
                "output_formats": self.compute.output_formats,
                "temp_file_policy": self.compute.temp_file_policy,
            },
            # 旧版配置 (兼容)
            "engine": self.engine,
            "model": self.model,
            "compute_type": self.compute_type,
            "device": self.device,
            "batch_size": self.batch_size,
            "word_timestamps": self.word_timestamps,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "JobSettings":
        """从字典创建设置"""
        # 解析新版配置
        preprocessing_data = data.get("preprocessing", {})
        transcription_data = data.get("transcription", {})
        refinement_data = data.get("refinement", {})
        compute_data = data.get("compute", {})

        # 解析旧版配置
        demucs_data = data.get("demucs", {})
        sensevoice_data = data.get("sensevoice", {})

        return cls(
            # 新版配置
            preset_id=data.get("preset_id", "balanced"),
            preprocessing=PreprocessingConfig(
                demucs_strategy=preprocessing_data.get("demucs_strategy", "auto"),
                demucs_model=preprocessing_data.get("demucs_model", "htdemucs"),
                demucs_shifts=preprocessing_data.get("demucs_shifts", 1),
                separation_mode=preprocessing_data.get("separation_mode", "on_demand"),
                enable_spectral_triage=preprocessing_data.get("enable_spectral_triage", True),
                spectrum_threshold=preprocessing_data.get("spectrum_threshold", 0.35),
                enable_fuse_breaker=preprocessing_data.get("enable_fuse_breaker", True),
                fuse_max_retry=preprocessing_data.get("fuse_max_retry", 2),
                fuse_confidence_threshold=preprocessing_data.get("fuse_confidence_threshold", 0.5),
                fuse_auto_upgrade=preprocessing_data.get("fuse_auto_upgrade", True),
                vad_filter=preprocessing_data.get("vad_filter", True),
            ),
            transcription=TranscriptionConfig(
                transcription_profile=transcription_data.get("transcription_profile", "sensevoice_only"),
                sensevoice_device=transcription_data.get("sensevoice_device", "auto"),
                whisper_model=transcription_data.get("whisper_model", "medium"),
                patching_threshold=transcription_data.get("patching_threshold", 0.60),
            ),
            refinement=RefinementConfig(
                llm_task=refinement_data.get("llm_task", "off"),
                llm_scope=refinement_data.get("llm_scope", "sparse"),
                sparse_threshold=refinement_data.get("sparse_threshold", 0.70),
                target_language=refinement_data.get("target_language", "zh"),
                llm_provider=refinement_data.get("llm_provider", "openai_compatible"),
                llm_model_name=refinement_data.get("llm_model_name", "gpt-4o-mini"),
            ),
            compute=ComputeConfig(
                concurrency_strategy=compute_data.get("concurrency_strategy", "auto"),
                gpu_id=compute_data.get("gpu_id", 0),
                output_formats=compute_data.get("output_formats", ["srt"]),
                temp_file_policy=compute_data.get("temp_file_policy", "delete_on_complete"),
            ),
            # 旧版配置
            engine=data.get("engine", "sensevoice"),
            model=data.get("model", "medium"),
            compute_type=data.get("compute_type", "float16"),
            device=data.get("device", "cuda"),
            batch_size=data.get("batch_size", 16),
            word_timestamps=data.get("word_timestamps", False),
            demucs=DemucsSettings(
                enabled=demucs_data.get("enabled", True),
                mode=demucs_data.get("mode", "auto"),
                weak_model=demucs_data.get("weak_model", "htdemucs"),
                strong_model=demucs_data.get("strong_model", "htdemucs"),
                fallback_model=demucs_data.get("fallback_model", "htdemucs"),
                auto_escalation=demucs_data.get("auto_escalation", True),
                max_escalations=demucs_data.get("max_escalations", 1),
                bgm_light_threshold=demucs_data.get("bgm_light_threshold", 0.02),
                bgm_heavy_threshold=demucs_data.get("bgm_heavy_threshold", 0.15),
                retry_threshold_logprob=demucs_data.get("retry_threshold_logprob", -0.8),
                retry_threshold_no_speech=demucs_data.get("retry_threshold_no_speech", 0.6),
                circuit_breaker_enabled=demucs_data.get("circuit_breaker_enabled", True),
                consecutive_threshold=demucs_data.get("consecutive_threshold", 3),
                ratio_threshold=demucs_data.get("ratio_threshold", 0.2),
                on_break=demucs_data.get("on_break", "continue"),
                mark_problem_segments=demucs_data.get("mark_problem_segments", True),
                problem_segment_suffix=demucs_data.get("problem_segment_suffix", "[?]"),
                quality_preset=demucs_data.get("quality_preset", "balanced"),
            ),
            sensevoice=SenseVoiceSettings(
                preset_id=sensevoice_data.get("preset_id", "default"),
                enhancement=sensevoice_data.get("enhancement", "off"),
                proofread=sensevoice_data.get("proofread", "off"),
                translate=sensevoice_data.get("translate", "off"),
                target_language=sensevoice_data.get("target_language", "en"),
                confidence_threshold=sensevoice_data.get("confidence_threshold", 0.6),
                whisper_patch_threshold=sensevoice_data.get("whisper_patch_threshold", 0.5),
            ),
        )

    @classmethod
    def from_preset(cls, preset_id: str) -> "JobSettings":
        """从预设创建设置"""
        from app.models.preset_models import MACRO_PRESETS, PRESET_BALANCED

        preset = MACRO_PRESETS.get(preset_id)
        if not preset:
            preset = PRESET_BALANCED
            preset_id = "balanced"

        return cls(
            preset_id=preset_id,
            preprocessing=PreprocessingConfig(
                demucs_strategy=preset.preprocessing.demucs_strategy,
                demucs_model=preset.preprocessing.demucs_model,
                demucs_shifts=preset.preprocessing.demucs_shifts,
                spectrum_threshold=preset.preprocessing.spectrum_threshold,
                vad_filter=preset.preprocessing.vad_filter,
            ),
            transcription=TranscriptionConfig(
                transcription_profile=preset.transcription.transcription_profile,
                sensevoice_device=preset.transcription.sensevoice_device,
                whisper_model=preset.transcription.whisper_model,
                patching_threshold=preset.transcription.patching_threshold,
            ),
            refinement=RefinementConfig(
                llm_task=preset.refinement.llm_task,
                llm_scope=preset.refinement.llm_scope,
                sparse_threshold=preset.refinement.sparse_threshold,
                target_language=preset.refinement.target_language,
                llm_provider=preset.refinement.llm_provider,
                llm_model_name=preset.refinement.llm_model_name,
            ),
            compute=ComputeConfig(
                concurrency_strategy=preset.compute.concurrency_strategy,
                gpu_id=preset.compute.gpu_id,
                output_formats=preset.compute.output_formats,
                temp_file_policy=preset.compute.temp_file_policy,
            ),
            # 根据预设设置旧版字段的默认值
            engine="sensevoice",
            model=preset.transcription.whisper_model,
        )


@dataclass
class MediaStatus:
    """媒体资源状态（用于编辑器）"""
    video_exists: bool = False          # 视频文件是否存在
    video_format: Optional[str] = None  # 视频格式（.mp4, .mkv等）
    needs_proxy: bool = False           # 是否需要Proxy转码
    proxy_exists: bool = False          # Proxy视频是否已生成
    audio_exists: bool = False          # 音频文件是否存在
    peaks_ready: bool = False           # 波形峰值数据是否就绪
    thumbnails_ready: bool = False      # 缩略图是否就绪
    srt_exists: bool = False            # SRT文件是否存在


@dataclass
class JobState:
    """转录任务状态"""
    job_id: str
    filename: str
    dir: str
    input_path: str = ""  # 添加原始输入路径记录
    settings: JobSettings = field(default_factory=JobSettings)
    status: str = "queued"  # queued, processing, finished, failed, canceled, paused
    phase: str = "pending"  # extract, split, transcribe, srt
    progress: float = 0.0
    phase_percent: float = 0.0  # 当前阶段内进度 (0-100)
    message: str = "等待开始"
    error: Optional[str] = None
    segments: List[Dict] = field(default_factory=list)
    processed: int = 0
    total: int = 0
    language: Optional[str] = None
    srt_path: Optional[str] = None
    canceled: bool = False
    paused: bool = False  # 暂停标志
    title: str = ""  # 用户自定义的任务名称，为空时使用 filename
    createdAt: Optional[int] = None  # 创建时间戳

    # 媒体状态（用于编辑器，转录完成后更新）
    media_status: Optional[MediaStatus] = None

    def to_dict(self):
        """转换为字典格式，用于API响应"""
        d = asdict(self)
        d.pop('segments', None)  # 不透出内部详情
        return d

    def to_meta_dict(self) -> dict:
        """
        转换为元信息字典格式，用于持久化到 job_meta.json
        只保存恢复任务所需的核心信息，不包含 segments 等大数据
        """
        import time
        return {
            "job_id": self.job_id,
            "filename": self.filename,
            "title": self.title,
            "dir": self.dir,
            "input_path": self.input_path,
            "status": self.status,
            "phase": self.phase,
            "progress": self.progress,
            "phase_percent": self.phase_percent,
            "message": self.message,
            "error": self.error,
            "processed": self.processed,
            "total": self.total,
            "language": self.language,
            "srt_path": self.srt_path,
            "canceled": self.canceled,
            "paused": self.paused,
            "settings": self.settings.to_dict(),
            "updated_at": time.time()
        }

    @classmethod
    def from_meta_dict(cls, data: dict) -> "JobState":
        """
        从元信息字典恢复 JobState 对象

        Args:
            data: job_meta.json 中的数据

        Returns:
            JobState: 恢复的任务状态对象
        """
        settings_data = data.get("settings", {})
        settings = JobSettings.from_dict(settings_data)

        return cls(
            job_id=data["job_id"],
            filename=data.get("filename", "unknown"),
            title=data.get("title", ""),
            dir=data.get("dir", ""),
            input_path=data.get("input_path", ""),
            settings=settings,
            status=data.get("status", "queued"),
            phase=data.get("phase", "pending"),
            progress=data.get("progress", 0.0),
            phase_percent=data.get("phase_percent", 0.0),
            message=data.get("message", ""),
            error=data.get("error"),
            processed=data.get("processed", 0),
            total=data.get("total", 0),
            language=data.get("language"),
            srt_path=data.get("srt_path"),
            canceled=data.get("canceled", False),
            paused=data.get("paused", False),
        )

    def update_media_status(self, job_dir: str):
        """
        更新媒体状态（检查各类资源文件是否就绪）

        Args:
            job_dir: 任务目录路径
        """
        from pathlib import Path

        job_path = Path(job_dir)
        if not job_path.exists():
            return

        # 需要转码的格式
        need_transcode_formats = {'.mkv', '.avi', '.mov', '.wmv', '.flv', '.m4v'}

        # 查找视频文件
        video_file = None
        video_exts = ['.mp4', '.avi', '.mkv', '.mov', '.wmv', '.webm', '.flv', '.m4v']
        for file in job_path.iterdir():
            if file.is_file() and file.suffix.lower() in video_exts:
                video_file = file
                break

        # 检查各项资源
        audio_file = job_path / "audio.wav"
        proxy_file = job_path / "proxy.mp4"
        peaks_file = job_path / "peaks_2000.json"
        thumbnails_file = job_path / "thumbnails_10.json"

        # 查找SRT文件
        srt_exists = False
        for file in job_path.iterdir():
            if file.suffix.lower() == '.srt':
                srt_exists = True
                break

        # 更新媒体状态
        self.media_status = MediaStatus(
            video_exists=video_file is not None,
            video_format=video_file.suffix if video_file else None,
            needs_proxy=video_file is not None and video_file.suffix.lower() in need_transcode_formats,
            proxy_exists=proxy_file.exists(),
            audio_exists=audio_file.exists(),
            peaks_ready=peaks_file.exists(),
            thumbnails_ready=thumbnails_file.exists(),
            srt_exists=srt_exists
        )
