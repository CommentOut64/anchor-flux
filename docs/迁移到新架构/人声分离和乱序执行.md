# AnchorFlux v3.0 核心架构重构设计文档

## 1. 架构核心理念：乱序执行，顺序提交 (Out-of-Order Execution, In-Order Commit)

为了解决“复杂音频（需人声分离）阻塞简单音频”的效率问题，我们将系统从简单的串行流水线升级为**异步并发流水线**。

* **FastWorker (CPU)**：不再等待，全速并发处理。简单 Chunk 秒级完成，复杂 Chunk（触发熔断）后台慢跑。
* **SequencedQueue (中间层)**：充当“整流器”。无论上游处理完成的顺序如何，保证下游（GPU）接收到的永远是严格按时间戳排序的数据。
* **SlowWorker (GPU)**：维持顺序处理，确保 Whisper 的上下文连贯性和 BufferPool 的拼接正确性。

---

## 2. 修正后的智能熔断机制 (Intelligent Fuse Breaker V2)

摒弃复杂的频谱预推荐逻辑，采用基于**SenseVoice 事件感知**的后置判断策略。

频谱分诊的结果不再用于选择人声分离模型，而是作为熔断的前置过滤

```python
# 在FuseBreakerV2.should_fuse() 中添加
if chunk.spectrum_diagnosis and chunk.spectrum_diagnosis.diagnosis == "clean":
    # 频谱分诊确认纯净人声，跳过熔断检查
    return FuseDecision(
        action=FuseAction.ACCEPT,
        reason="频谱分诊确认纯净人声，无需熔断"
    )
```

### 2.1 核心逻辑公式

不再单纯依赖置信度，而是结合 SenseVoice 的事件标签（Event Tags）进行加权判断。

**标签权重表：**

| 标签 (Tag) | 权重 (Weight) | 说明 |
| :--- | :--- | :--- |
| **BGM** | 1.0 | 背景音乐，干扰极大，必须分离 |
| **Music** | 0.9 | 音乐，干扰大 |
| **Noise** | 0.8 | 噪音，干扰中等 |
| **Applause** | 0.6 | 掌声，干扰较小 |
| **None** | 0.0 | 纯净人声，无需分离 |

### 2.2 决策流程

1. **预判**：SenseVoice 首次推理。
2. **计算**：根据公式计算加权置信度。
3. **判断**：
* **Pass**：加权置信度 > 阈值（默认0.5）。直接输出。
* **Fuse (熔断)**：加权置信度 < 阈值，且存在 BGM/Noise 标签。触发 `htdemucs` 分离。
* **Skip (跳过)**：原始置信度低，但**无**干扰标签（如口音重）。不分离，直接交给 Whisper（SlowWorker）利用大模型语义纠错。



### 2.3 模型策略与配置

* **默认策略**：死磕 `htdemucs` (shifts=1)。速度快、显存低、人声保留好。
* **配置开关**：增加 `allow_mdx_extra` 配置项。
* `False` (默认)：路径为 `None -> htdemucs -> (Stop)`。
* `True` (高级用户)：路径为 `None -> htdemucs -> mdx_extra`。



---

## 3. FastWorker 乱序并发池 (Out-of-Order Concurrency)

FastWorker 不再逐个处理 Chunk，而是维护一个并发任务池，最大化利用 CPU 多核性能。

### 3.1 核心组件

* **Semaphore (信号量)**：控制最大并发数（如 8 或 CPU核心数），防止内存溢出。
* **Async Task Pool**：同时运行多个 `_bounded_process` 任务。

### 3.2 工作流程

1. **分发**：主循环遍历所有 Chunk，创建 Task 并立即启动。
2. **执行**：
* Chunk A (简单)：SenseVoice 推理 -> 结束 -> 耗时 0.2s。
* Chunk B (复杂)：SenseVoice -> 熔断 -> Demucs -> SenseVoice -> 结束 -> 耗时 5.0s。


3. **提交**：使用 `asyncio.as_completed` 或直接 `await`，任务一旦完成，**立即**放入下游队列（无论顺序）。

---

## 4. 智能序列化队列 (SequencedQueue)

这是新架构的灵魂组件。它封装了复杂的排序逻辑和背压控制，使 Worker 的代码保持极简。

### 4.1 类定义 (`backend/app/utils/sequenced_queue.py`)

```python
class SequencedAsyncQueue(Generic[T]):
    def __init__(self, maxsize: int = 0):
        self._inner_queue = asyncio.Queue(maxsize=maxsize) # 实际给消费者的队列
        self._buffer: Dict[int, T] = {}                    # 乱序暂存区
        self._next_expected_index = 0                      # 指针：当前急需的序号

    async def put(self, item: T):
        # 1. 索引检查
        index = getattr(item, 'chunk_index', None)
        
        # 2. 存入缓冲区
        self._buffer[index] = item

        # 3. 连续发射逻辑 (核心)
        # 只要 buffer 里有下一个期望的 index，就一直往 inner_queue 里放
        while self._next_expected_index in self._buffer:
            item_to_send = self._buffer.pop(self._next_expected_index)
            
            # 【背压关键点】
            # 如果下游 SlowWorker 处理慢，inner_queue 满，这里会阻塞。
            # 进而阻塞 FastWorker 的 put，最终阻塞 Semaphore，停止 CPU 新任务。
            await self._inner_queue.put(item_to_send)
            
            self._next_expected_index += 1

    async def get(self) -> T:
        return await self._inner_queue.get()

```

### 4.2 作用

1. **消除乱序**：Chunk 1 先做完会停在 `_buffer` 里，直到 Chunk 0 做完并被 `put`，SequencedQueue 会自动按 `0 -> 1` 的顺序释放给下游。
2. **自动背压**：将 SlowWorker (GPU) 的压力反向传导给 FastWorker (CPU)，实现系统级的流控。

---

## 5. GPU 动态优先级与数据流整合

通过上述组件的配合，系统自然形成了对 GPU 友好的调度流。

### 5.1 完整数据流视图

```mermaid
graph TD
    Input[VAD切分 Chunk 0..N] --> FW_Distributor
    
    subgraph "FastWorker (CPU并发层)"
        FW_Distributor --并发分发--> T0[Task 0 (触发熔断/慢)]
        FW_Distributor --并发分发--> T1[Task 1 (简单/快)]
        FW_Distributor --并发分发--> T2[Task 2 (简单/快)]
        
        T0 --耗时5s--> SQ_Input
        T1 --耗时0.1s--> SQ_Input
        T2 --耗时0.1s--> SQ_Input
    end

    subgraph "Queue Inter (智能序列化层)"
        SQ_Input[SequencedQueue.put] --> Buffer{检查 Index}
        Buffer --是 next_index--> InnerQ[内部有序队列]
        Buffer --非 next_index--> Hold[暂存区 _buffer]
        Hold --等待前序--> Buffer
    end

    InnerQ --有序输出 Chunk 0,1,2...--> SW

    subgraph "SlowWorker (GPU顺序层)"
        SW[SlowWorker] --> BufferPool[WhisperBufferPool]
        BufferPool --拼接长音频--> Whisper[Whisper推理]
    end
    
    Whisper --> Alignment[对齐与输出]

```

### 5.2 GPU 调度策略

* **Demucs (GPU/CPU)**：在 FastWorker 阶段运行。如果配置为 GPU 运行，建议使用全局锁或信号量限制同时运行的 Demucs 实例数为 1，避免与 Whisper 抢显存。
* **Whisper (GPU)**：在 SlowWorker 阶段运行。由于 `SequencedQueue` 的存在，Whisper 接收到的数据流是**严格有序**的。
* 这使得 `WhisperBufferPool` 可以安全地将短 Chunk 拼接成 5-30s 的长音频进行批量推理，极大提升 GPU 利用率并减少幻觉。



---

## 6. 实施 Checklist

1. **[ ] 新建 `backend/app/utils/sequenced_queue.py**`：实现上述的智能队列类。
2. **[ ] 修改 `async_dual_pipeline.py**`：
* 将 `self.queue_inter` 替换为 `SequencedAsyncQueue`。
* 重写 `_fast_loop`，移除原来的手动排序逻辑，改为使用 `asyncio.Semaphore` 和 `asyncio.as_completed` (或简单的 list of tasks) 进行并发处理和直接 `put`。


3. **[ ] 修正 `fuse_breaker.py**`：
* 引入 `EVENT_TAG_WEIGHTS`。
* 修改 `should_fuse` 逻辑，增加 `allow_mdx_extra` 参数。


4. **[ ] 配置更新**：在 `config` 相关文件中添加 `allow_mdx_extra` (默认 False)。
5. **[ ] 测试**：
* 测试乱序场景：构造 Chunk 0 需要分离，Chunk 1 不需要的情况，验证最终输出顺序是否为 0 -> 1。
* 测试背压：人为阻塞 SlowWorker，观察 FastWorker 是否会停止接受新任务。
