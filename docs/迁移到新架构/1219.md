# AnchorFlux v3.0 乱序执行架构 - 开发文档

> **更新日期**: 2025-12-19
> **文档版本**: v2.0

## 1. 架构概述

### 1.1 核心架构理念

**乱序执行，顺序提交 (Out-of-Order Execution, In-Order Commit)**

```text
VAD切分 → [FastWorker (CPU并发)] → SequencedQueue → [SlowWorker (GPU)] → Queue2 → [AlignmentWorker] → 完成
```

- **FastWorker (CPU)**: 全速并发处理，简单 Chunk 秒级完成，复杂 Chunk（触发熔断）后台慢跑
- **SequencedQueue (中间层)**: 充当"整流器"，保证下游接收到严格按时间戳排序的数据
- **SlowWorker (GPU)**: 维持顺序处理，确保 Whisper 上下文连贯性

### 1.2 实现状态总览

| 组件 | 状态 | 文件位置 | 说明 |
|------|------|----------|------|
| AudioChunk 数据模型 | **已完成** | `chunk_engine.py:24-77` | 含熔断回溯字段（9个新字段） |
| FuseBreakerV2 熔断器 | **已完成** | `fuse_breaker_v2.py` | 事件权重、升级路径（基础版） |
| FastWorker | **已完成** | `fast_worker.py` | 熔断回溯逻辑 |
| AsyncDualPipeline | **部分完成** | `async_dual_pipeline.py` | 三级流水线框架，**但_fast_loop仍是串行处理** |
| PreprocessingPipeline | **已完成** | `preprocessing_pipeline.py` | Stage模式 |
| SpectralTriageStage | **已完成** | `spectral_triage_stage.py` | 频谱分诊 |
| SeparationStage | **已完成** | `separation_stage.py` | 按需分离（chunk级分离暂返回原始音频） |
| DemucsService | **已完成** | `demucs_service.py` | 完整分离服务 |
| 背压控制 | **已完成** | `async_dual_pipeline.py:70-71` | `asyncio.Queue(maxsize=5)` |
| **SequencedAsyncQueue** | **未实现** | - | 智能序列化队列 |
| **Semaphore 并发控制** | **未实现** | - | FastWorker并发改造 |
| **GPU资源协调器** | **未实现** | - | Demucs/Whisper GPU协同 |
| **allow_mdx_extra 配置** | **未实现** | - | 限制MDX_EXTRA升级 |
| **weight_strategy 多标签** | **未实现** | - | max/sum策略选择 |
| **FuseMetrics 监控** | **未实现** | - | 运行时指标收集 |

---

## 2. 已实现模块参考

> 以下模块已完成实现，详细架构文档请参阅 `/llmdoc/architecture/`

### 2.1 FuseBreakerV2 熔断决策器

**参考文档**: `/llmdoc/architecture/fuse-breaker-v2.md`
**源码**: `backend/app/services/fuse_breaker_v2.py:24-227`

**当前实现特性**:
- 事件标签权重: BGM=1.0, Music=0.9, Noise=0.8, Applause=0.6
- 升级路径: NONE → HTDEMUCS → MDX_EXTRA
- max_retry=2, 第二次重试自动升级（auto_upgrade=True）
- 加权置信度: `weighted_confidence = confidence * (1 + weight)`

**已知局限**:
- 仅支持单标签，不支持多标签列表
- auto_upgrade控制MDX_EXTRA升级，无条件限制机制
- 无运行时监控指标

### 2.2 FastWorker 快流推理

**参考文档**: `/llmdoc/architecture/fast-worker.md`
**源码**: `backend/app/pipelines/workers/fast_worker.py:32-335`

**当前实现特性**:
- SenseVoice ONNX推理（CPU）
- 熔断回溯循环（enable_fuse_breaker=True时启用）
- 两层分句策略（VAD停顿 + 物理约束）
- SSE草稿推送

### 2.3 AsyncDualPipeline 流水线

**源码**: `backend/app/pipelines/async_dual_pipeline.py`

**当前实现特性**:
- 三级流水线框架（FastWorker → SlowWorker → AlignmentWorker）
- 背压控制: `asyncio.Queue(maxsize=5)`
- 错误传播和结束信号

**核心问题 - 串行处理**:

```python
# 当前实现 (第158-219行)
async def _fast_loop(self, chunks, ...):
    for i, chunk in enumerate(chunks):  # 串行!
        ctx = ProcessingContext(...)
        await self.fast_worker.process(ctx)
        await self.queue_inter.put(ctx)
```

---

## 3. 待实现模块

### 3.1 SequencedAsyncQueue（核心 - P0优先级）

**目标文件**: `backend/app/utils/sequenced_queue.py` (新建)

**核心功能**:
1. **乱序放入，顺序取出** - 通过`_buffer`字典和`_next_expected_index`指针实现
2. **失败跳号** - `mark_failed(index)`标记失败，自动跳过
3. **超时处理** - 超时后自动标记失败
4. **缓冲区背压** - `max_buffer_size`限制，满时阻塞put

**设计规范**:

```python
class SequencedAsyncQueue(Generic[T]):
    def __init__(
        self,
        maxsize: int = 0,
        max_buffer_size: int = 100,
        timeout_seconds: float = 60.0
    ):
        self._inner_queue = asyncio.Queue(maxsize=maxsize)
        self._buffer: Dict[int, T] = {}
        self._next_expected_index = 0
        self._failed_indices: Set[int] = set()
        self._max_buffer_size = max_buffer_size
        self._timeout_seconds = timeout_seconds

    async def put(self, item: T):
        """放入元素（乱序）"""
        index = getattr(item, 'chunk_index', None)
        self._buffer[index] = item
        await self._try_flush()

    async def mark_failed(self, index: int, reason: str = ""):
        """标记某个index为失败（跳号）"""
        self._failed_indices.add(index)
        await self._try_flush()

    async def _try_flush(self):
        """尝试将连续的元素推送到内部队列"""
        while True:
            if self._next_expected_index in self._buffer:
                item = self._buffer.pop(self._next_expected_index)
                await self._inner_queue.put(item)  # 背压点
                self._next_expected_index += 1
            elif self._next_expected_index in self._failed_indices:
                self._failed_indices.discard(self._next_expected_index)
                self._next_expected_index += 1  # 跳过失败
            else:
                break

    async def get(self, timeout: Optional[float] = None) -> T:
        return await asyncio.wait_for(self._inner_queue.get(), timeout=timeout)
```

**验证点**:
- 乱序放入，顺序取出
- 失败跳号不阻塞
- 超时自动跳号
- 缓冲区背压

### 3.2 AsyncDualPipeline 并发改造（P0优先级）

**修改文件**: `backend/app/pipelines/async_dual_pipeline.py`

**改造目标**: 将`_fast_loop`从串行改为并发

```python
async def _fast_loop(self, chunks: List[AudioChunk], ...):
    """FastWorker 并发循环（改造后）"""
    from app.utils.sequenced_queue import SequencedAsyncQueue

    # CPU并发信号量
    semaphore = asyncio.Semaphore(max(1, multiprocessing.cpu_count() - 2))

    async def process_chunk(i: int, chunk: AudioChunk):
        """处理单个chunk（并发执行）"""
        try:
            async with semaphore:
                ctx = ProcessingContext(
                    job_id=self.job_id,
                    chunk_index=i,
                    audio_chunk=chunk,
                    ...
                )
                await self.fast_worker.process(ctx)
                await self.queue_inter.put(ctx)
        except asyncio.CancelledError:
            await self.queue_inter.mark_failed(i, "cancelled")
            raise
        except Exception as e:
            await self.queue_inter.mark_failed(i, str(e))

    # 并发启动所有任务
    tasks = [asyncio.create_task(process_chunk(i, chunk)) for i, chunk in enumerate(chunks)]
    await asyncio.gather(*tasks, return_exceptions=True)

    # 发送结束信号
    await self.queue_inter.put_direct(ProcessingContext(is_end=True))
```

**修改`__init__`**:

```python
def __init__(self, job_id: str, queue_maxsize: int = 5, ...):
    from app.utils.sequenced_queue import SequencedAsyncQueue

    # 替换普通队列为智能序列化队列
    self.queue_inter = SequencedAsyncQueue(
        maxsize=queue_maxsize,
        max_buffer_size=100,
        timeout_seconds=60.0
    )
    self.queue_final = asyncio.Queue(maxsize=queue_maxsize)
```

### 3.3 GPU资源协调器（P1优先级）

**目标文件**: `backend/app/services/gpu_coordinator.py` (新建)

**核心功能**:
- Demucs独占锁（GPU密集型）
- Whisper并发限制
- CPU并发控制（FastWorker）

```python
class GPUCoordinator:
    def __init__(
        self,
        demucs_concurrent: int = 1,
        whisper_concurrent: int = 1,
        cpu_concurrent: Optional[int] = None
    ):
        self._demucs_semaphore = asyncio.Semaphore(demucs_concurrent)
        self._whisper_semaphore = asyncio.Semaphore(whisper_concurrent)
        self._cpu_semaphore = asyncio.Semaphore(
            cpu_concurrent or max(1, multiprocessing.cpu_count() - 2)
        )

    @asynccontextmanager
    async def acquire_demucs(self):
        """获取Demucs资源（GPU独占）"""
        async with self._demucs_semaphore:
            yield

    @asynccontextmanager
    async def acquire_whisper(self):
        """获取Whisper资源"""
        async with self._whisper_semaphore:
            yield
```

**集成点**:
- `fuse_breaker_v2.py:execute_upgrade()` - 使用`acquire_demucs()`
- `slow_worker.py` - 使用`acquire_whisper()`

### 3.4 FuseBreakerV2 配置扩展（P1优先级）

**修改文件**: `backend/app/services/fuse_breaker_v2.py`

**新增参数**:

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `allow_mdx_extra` | bool | False | 是否允许升级到MDX_EXTRA |
| `weight_strategy` | str | "max" | 多标签权重策略（max/sum） |

**多标签加权实现**:

```python
def _calculate_weighted_confidence(self, confidence: float, sv_result: dict) -> float:
    # 支持多标签
    event_tags = sv_result.get('event_tags', [])
    if not event_tags:
        single_tag = sv_result.get('event_tag')
        event_tags = [single_tag] if single_tag else []

    if not event_tags:
        return confidence

    valid_tags = [t for t in event_tags if t in self.event_weights]
    if not valid_tags:
        return confidence

    if self.weight_strategy == "max":
        weight = max(self.event_weights[t] for t in valid_tags)
    elif self.weight_strategy == "sum":
        weight = min(2.0, sum(self.event_weights[t] for t in valid_tags))
    else:
        weight = max(self.event_weights[t] for t in valid_tags)

    return confidence * (1 + weight)

def _get_next_level(self, chunk: AudioChunk) -> Optional[SeparationLevel]:
    current = chunk.separation_level
    if current == SeparationLevel.NONE:
        return SeparationLevel.HTDEMUCS
    if current == SeparationLevel.HTDEMUCS:
        if self.allow_mdx_extra:
            return SeparationLevel.MDX_EXTRA
        return None  # 不允许升级
    return None
```

### 3.5 FuseMetrics 监控指标（P2优先级）

**目标文件**: `backend/app/services/fuse_metrics.py` (新建)

**核心指标**:
- 决策统计（total_decisions, accept_count, upgrade_count）
- 按模型统计（htdemucs_triggers, mdx_extra_triggers）
- 延迟统计（sensevoice_latencies, demucs_latencies）
- 标签分布（tag_distribution）

---

## 4. 数据流视图

```mermaid
graph TD
    Input[VAD切分 Chunk 0..N] --> FW_Distributor

    subgraph "FastWorker (CPU并发层)"
        FW_Distributor --并发分发--> T0[Task 0 (触发熔断/慢)]
        FW_Distributor --并发分发--> T1[Task 1 (简单/快)]
        FW_Distributor --并发分发--> T2[Task 2 (简单/快)]

        T0 --耗时5s--> SQ_Input
        T1 --耗时0.1s--> SQ_Input
        T2 --耗时0.1s--> SQ_Input
    end

    subgraph "Queue Inter (智能序列化层)"
        SQ_Input[SequencedQueue.put] --> Buffer{检查 Index}
        Buffer --是 next_index--> InnerQ[内部有序队列]
        Buffer --非 next_index--> Hold[暂存区 _buffer]
        Hold --等待前序--> Buffer
    end

    InnerQ --有序输出 Chunk 0,1,2...--> SW

    subgraph "SlowWorker (GPU顺序层)"
        SW[SlowWorker] --> BufferPool[WhisperBufferPool]
        BufferPool --拼接长音频--> Whisper[Whisper推理]
    end

    Whisper --> Alignment[对齐与输出]
```

---

## 5. 实施计划

### Phase 1: 乱序执行核心（P0）

| 任务 | 文件 | 说明 |
|------|------|------|
| 实现SequencedAsyncQueue | `backend/app/utils/sequenced_queue.py` | 新建 |
| 改造AsyncDualPipeline | `backend/app/pipelines/async_dual_pipeline.py` | 并发+SequencedQueue |
| 单元测试 | `backend/tests/test_sequenced_queue.py` | 新建 |

**验证点**:
- 乱序放入顺序取出
- 失败跳号不阻塞
- 背压传导正确

### Phase 2: GPU资源协调（P1）

| 任务 | 文件 | 说明 |
|------|------|------|
| 实现GPUCoordinator | `backend/app/services/gpu_coordinator.py` | 新建 |
| 集成到FuseBreakerV2 | `backend/app/services/fuse_breaker_v2.py` | execute_upgrade |
| 集成到SlowWorker | `backend/app/pipelines/workers/slow_worker.py` | Whisper推理 |

### Phase 3: 配置扩展（P1）

| 任务 | 文件 | 说明 |
|------|------|------|
| 添加allow_mdx_extra | `backend/app/services/fuse_breaker_v2.py` | 限制升级路径 |
| 添加weight_strategy | `backend/app/services/fuse_breaker_v2.py` | 多标签加权 |
| 配置模型扩展 | `backend/app/models/job_models.py` | FuseBreakerConfig |

### Phase 4: 监控集成（P2）

| 任务 | 文件 | 说明 |
|------|------|------|
| 实现FuseMetrics | `backend/app/services/fuse_metrics.py` | 新建 |
| 集成到FastWorker | `backend/app/pipelines/workers/fast_worker.py` | 记录指标 |
| SSE推送 | - | 可选 |

---

## 6. 配置参数汇总

| 参数 | 默认值 | 说明 | 所属模块 | 状态 |
|------|--------|------|----------|------|
| `max_retry` | 2 | 最大熔断重试次数 | FuseBreakerV2 | 已实现 |
| `confidence_threshold` | 0.5 | 置信度阈值 | FuseBreakerV2 | 已实现 |
| `auto_upgrade` | True | 自动跳级到MDX_EXTRA | FuseBreakerV2 | 已实现 |
| `queue_maxsize` | 5 | 队列背压上限 | AsyncDualPipeline | 已实现 |
| `allow_mdx_extra` | False | 允许升级到MDX_EXTRA | FuseBreakerV2 | **待实现** |
| `weight_strategy` | "max" | 多标签权重策略 | FuseBreakerV2 | **待实现** |
| `max_concurrent` | CPU-2 | FastWorker并发数 | AsyncDualPipeline | **待实现** |
| `max_buffer_size` | 100 | 乱序缓冲区上限 | SequencedQueue | **待实现** |
| `timeout_seconds` | 60.0 | 单chunk超时 | SequencedQueue | **待实现** |
| `demucs_concurrent` | 1 | Demucs并发数 | GPUCoordinator | **待实现** |
| `whisper_concurrent` | 1 | Whisper并发数 | GPUCoordinator | **待实现** |

---

## 7. 测试清单

### 7.1 SequencedQueue 测试

```python
# backend/tests/test_sequenced_queue.py

@pytest.mark.asyncio
async def test_out_of_order_put_in_order_get():
    """乱序放入，顺序取出"""
    queue = SequencedAsyncQueue(maxsize=10)
    await queue.put(MockContext(2))  # 先放2
    await queue.put(MockContext(0))  # 再放0
    await queue.put(MockContext(1))  # 最后放1

    # 应该顺序取出 0, 1, 2
    assert (await queue.get()).chunk_index == 0
    assert (await queue.get()).chunk_index == 1
    assert (await queue.get()).chunk_index == 2

@pytest.mark.asyncio
async def test_failed_index_skip():
    """失败索引跳过"""
    queue = SequencedAsyncQueue(maxsize=10)
    await queue.put(MockContext(0))
    await queue.mark_failed(1, "test")  # 标记1失败
    await queue.put(MockContext(2))

    # 应该取出 0, 2（跳过1）
    assert (await queue.get()).chunk_index == 0
    assert (await queue.get()).chunk_index == 2
```

### 7.2 并发加速测试

```python
@pytest.mark.asyncio
async def test_parallel_speedup():
    """并行加速测试"""
    chunk_count = 10
    process_time = 0.1

    # 串行: ~1秒
    # 并行: ~0.1秒（理论）
    # 加速比应 > 2
```

---

## 8. 相关文档

- `/llmdoc/architecture/fuse-breaker-v2.md` - 熔断决策器架构
- `/llmdoc/architecture/fast-worker.md` - 快流推理架构
- `/llmdoc/architecture/separation-stage.md` - 人声分离阶段
- `/llmdoc/reference/data-models-expansion.md` - 数据模型扩展
- `/docs/迁移到新架构/人声分离和乱序执行.md` - 原始设计文档
