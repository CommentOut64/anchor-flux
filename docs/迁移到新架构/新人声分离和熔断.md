这是为您梳理的 **AnchorFlux v3.0 最终版处理全流程**。此流程结合了频谱预判、事件感知熔断和分级人声分离，旨在实现性能与质量的最优平衡。

---

### 一、 全流程逻辑概览

整个流程分为三个阶段：**预处理阶段** -> **初次推理阶段** -> **熔断决策与执行阶段**。

#### 1. 预处理阶段 (Media Prep)

* **动作**：对音频进行快速频谱分析（Spectrum Analysis）。
* **目的**：不再用于推荐模型，仅作为 **“免检通行证”**。
* **结果**：标记 `spectrum_clean` (True/False)。如果是 True，后续无论 SenseVoice 结果如何，直接跳过熔断检查（信任物理特征）。

#### 2. 初次推理阶段 (First Pass)

* **动作**：FastWorker 调用 SenseVoice 进行推理。
* **输出**：获得 `confidence` (置信度) 和 `event_tags` (如 BGM, Noise)。

#### 3. 熔断决策阶段 (Fuse Decision)

* **核心算法**：**加权置信度**。


* **判断逻辑**：
1. 如果 `spectrum_clean` 为 True -> **ACCEPT** (不熔断)。
2. 如果 `Score` > 阈值 (0.5) -> **ACCEPT** (质量达标)。
3. 如果 `Score` < 阈值 且 无干扰标签 -> **ACCEPT** (单纯人声难识别，分离无用)。
4. 如果 `Score` < 阈值 且 有干扰标签 -> **TRIGGER FUSE** (触发熔断)。



#### 4. 熔断执行阶段 (Execution)

* **Level 1**：调用 `htdemucs` (shifts=1)。
* **Level 2 (可选)**：如果用户开启 `allow_mdx_extra` 且 Level 1 失败，调用 `mdx_extra`。

---

### 二、 详细场景与处理逻辑表

| 场景 | 频谱分析 | SenseVoice 结果 | 加权分计算 | 决策 | 执行动作 |
| --- | --- | --- | --- | --- | --- |
| **A. 纯净口播** | Clean | Conf=0.9, No Tags | 0.9 * (1-0) = **0.9** | **通过** | 直接输出 |
| **B. 难识别口音** | Clean | Conf=0.4, No Tags | 0.4 * (1-0) = **0.4** | **通过** | **不分离** (无环境音，分离无效，交给Whisper脑补) |
| **C. 强BGM干扰** | Noisy | Conf=0.6, Tag=[BGM] | 0.6 * (1-1.0) = **0.0** | **熔断** | **分离** (htdemucs) -> 重试 |
| **D. 轻度噪音声** | Noisy | Conf=0.6, Tag=[Noise] | 0.6 * (1-0.8) = **0.12** | **熔断** | **分离** (htdemucs) -> 重试 |
| **E. 频谱误判** | Clean (误) | Conf=0.5, Tag=[BGM] | **跳过检查** | **通过** | 信任频谱结果 (为了性能牺牲极少Corner Case) |

---

### 三、 代码修改指南

请按照以下步骤修改对应的文件。

#### 1. 修改 `backend/app/services/fuse_breaker.py` (核心大脑)

**目标**：实现加权置信度算法，引入 `allow_mdx_extra` 和 `spectrum_clean` 参数。

```python
# 修改 should_fuse 方法签名和逻辑
    def should_fuse(
        self,
        chunk_state: ChunkProcessState,
        confidence: float,
        event_tags: List[str],      # 传入标签列表
        is_spectrum_clean: bool,    # 传入频谱分析结果
        allow_mdx_extra: bool = False # 配置开关
    ) -> FuseDecision:
        
        # 0. 频谱分诊“免检”机制
        if is_spectrum_clean:
             return FuseDecision(action=FuseAction.ACCEPT, reason="频谱分诊判定为纯净，跳过熔断")

        # 定义权重
        TAG_WEIGHTS = {
            'BGM': 1.0, 'Music': 0.9, 'Noise': 0.8, 'Applause': 0.6
        }
        
        # 1. 计算最大权重
        max_weight = 0.0
        found_tag = None
        for tag in event_tags:
            if tag in TAG_WEIGHTS:
                w = TAG_WEIGHTS[tag]
                if w > max_weight:
                    max_weight = w
                    found_tag = tag
        
        # 2. 计算加权置信度
        weighted_conf = confidence * (1.0 - max_weight)
        
        # 3. 判定通过
        if weighted_conf >= self.fuse_confidence_threshold:
             return FuseDecision(action=FuseAction.ACCEPT, reason=f"加权置信度 {weighted_conf:.2f} 达标")

        # 4. 判定是否需要分离 (低分 + 有干扰标签)
        if max_weight == 0.0:
             return FuseDecision(action=FuseAction.ACCEPT, reason="低置信度但无干扰标签，判定为难识别语音")

        # 5. 检查升级路径 (硬编码 htdemucs 逻辑)
        current_level = chunk_state.separation_level
        
        # 如果还没分离过 -> htdemucs
        if current_level == SeparationLevel.NONE:
            return FuseDecision(
                action=FuseAction.UPGRADE_SEPARATION,
                next_separation_level=SeparationLevel.HTDEMUCS
            )
            
        # 如果已经 htdemucs 了 -> 检查是否允许 mdx_extra
        if current_level == SeparationLevel.HTDEMUCS:
            if allow_mdx_extra:
                return FuseDecision(
                    action=FuseAction.UPGRADE_SEPARATION,
                    next_separation_level=SeparationLevel.MDX_EXTRA
                )
            else:
                return FuseDecision(action=FuseAction.ACCEPT, reason="已达分离上限 (htdemucs)")
                
        return FuseDecision(action=FuseAction.ACCEPT, reason="已达最高等级")

```

#### 2. 修改 `backend/app/services/media_prep_service.py` (去复杂化)

**目标**：删除模型推荐逻辑，只保留纯净度判断。

```python
# 找到 analyze_spectrum 或类似方法
# 修改为只返回简单的 bool，不再返回推荐模型字符串

def analyze_chunk_spectrum(self, audio_chunk) -> bool:
    """
    分析频谱是否纯净
    Returns: True (Clean), False (Noisy)
    """
    # ... 原有的 librosa 分析代码 ...
    # 只要判断 bgm_ratio < threshold 即可
    return is_clean

```

#### 3. 修改 `backend/app/pipelines/workers/fast_worker.py` (执行循环)

**目标**：在循环中正确调用 FuseBreaker。

```python
    async def process(self, ctx: ProcessingContext):
        # ... 获取配置 ...
        allow_mdx = ctx.config.allow_mdx_extra # 假设配置在这里
        
        # 熔断循环
        while True:
            # 1. 推理
            sv_result = await self._run_sensevoice(ctx.audio_chunk)
            
            # 2. 提取信息
            conf = sv_result.get('confidence', 1.0)
            tags = sv_result.get('event_tags', [])
            
            # 3. 熔断决策
            decision = self.fuse_breaker.should_fuse(
                chunk_state=ctx.chunk_state,
                confidence=conf,
                event_tags=tags,
                is_spectrum_clean=ctx.spectrum_info.is_clean, # 假设预处理结果在这里
                allow_mdx_extra=allow_mdx
            )
            
            if decision.action == FuseAction.ACCEPT:
                ctx.sv_result = sv_result
                break
                
            # 4. 执行升级 (分离)
            # 硬编码 shifts=1，不再动态调整
            ctx.chunk_state = await self.fuse_breaker.execute_upgrade(
                chunk_state=ctx.chunk_state,
                next_level=decision.next_separation_level,
                demucs_service=self.demucs_service,
                shifts=1  # <--- 关键修改：统一为 1
            )
            
            # 更新 chunk 音频用于下一轮推理
            ctx.audio_chunk.audio = ctx.chunk_state.current_audio

```

#### 4. 配置项 (User Config)

在前端设置或后端 Config 中增加：

* `Separation`:
* `Enable MDX Extra`: Switch (Default: Off)



---

### 总结

这个修改方案彻底移除了之前“为了智能而智能”的复杂模型推荐逻辑，转而采用**“快速筛选 + 暴力兜底”**的工程化思路：

1. **快**：频谱干净直接过。
2. **稳**：只要有 BGM 干扰且识别差，统一上 `htdemucs`。
3. **强**：只有用户允许，才上 `mdx_extra` 救急。