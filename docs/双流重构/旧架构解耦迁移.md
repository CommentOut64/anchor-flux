好的，wgh，这是一个很好的决定。让我深入分析旧架构中有价值的功能模块，以便进行合理解耦。

帮我深入分析旧架构 `_process_video_sensevoice` 方法中的所有功能模块，以便解耦迁移到新架构。

重点分析 `backend/app/services/transcription_service.py` 中的：

1. `_process_video_sensevoice` 方法的完整流程（约5000+行），拆解出每个独立的功能模块：
   - 音频提取
   - BGM检测
   - 人声分离（Demucs）
   - VAD切分
   - 频谱分诊
   - SenseVoice转录
   - Whisper补刀（SMART_PATCH模式）
   - Whisper缓冲池（DEEP_LISTEN模式）
   - 幻觉检测
   - LLM校对/翻译
   - SRT生成

2. 旧架构中哪些模块在新架构（AsyncDualPipeline）中已有对应实现

3. 旧架构中哪些模块是新架构缺失的，需要迁移

4. 旧架构中的熔断器（CircuitBreaker）机制是如何工作的

5. 旧架构中的 checkpoint 断点续传机制

6. 分析 `solution_matrix.py` 中的 `SolutionConfig` 是如何控制各模块开关的

请给出详细的模块清单和依赖关系图

wgh，根据深入分析，这里是完整的架构迁移方案：

---

## 旧架构功能模块解耦清单

### 一、模块对比总览

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                           旧架构 vs 新架构 功能对比                           │
├─────────────────────────┬───────────────────┬───────────────────────────────┤
│        功能模块          │     旧架构状态     │         新架构状态             │
├─────────────────────────┼───────────────────┼───────────────────────────────┤
│ 音频提取                 │ _extract_audio    │ AudioProcessingPipeline       │
│ VAD切分                  │ _memory_vad_split │ ChunkEngine                   │
│ Post-VAD合并             │ _merge_vad_segments│ ChunkEngine                  │
├─────────────────────────┼───────────────────┼───────────────────────────────┤
│ 频谱分诊                 │ AudioSpectrum...  │ **缺失 - 需迁移**             │
│ 人声分离(Demucs)         │ DemucsService     │ **缺失 - 需迁移**             │
│ 熔断回溯机制             │ FuseBreaker       │ **缺失 - 需迁移**             │
├─────────────────────────┼───────────────────┼───────────────────────────────┤
│ SenseVoice转录           │ _sensevoice...    │ FastWorker                    │
│ 分句                     │ _split_sentences  │ SentenceSplitter              │
│ Whisper补刀              │ 逐句补刀          │ SlowWorker                    │
│ 幻觉检测(四道防线)        │ 完整实现          │ SlowWorker (部分)             │
│ 双流对齐                 │ 无                │ AlignmentWorker               │
├─────────────────────────┼───────────────────┼───────────────────────────────┤
│ Whisper缓冲池            │ DEEP_LISTEN模式   │ **缺失 - 需迁移**             │
│ LLM校对                  │ TODO未实现        │ **缺失 - 需新建**             │
│ LLM翻译                  │ TODO未实现        │ **缺失 - 需新建**             │
├─────────────────────────┼───────────────────┼───────────────────────────────┤
│ Checkpoint断点续传       │ _save_checkpoint  │ **缺失 - 需迁移**             │
│ SRT生成                  │ _generate_subtitle│ **缺失 - 需迁移**             │
│ SSE进度推送              │ 完整实现          │ 已迁移                        │
└─────────────────────────┴───────────────────┴───────────────────────────────┘
```

---

### 二、需要解耦迁移的核心模块

#### **P0 - 必须迁移（流水线完整性）**

| 模块         | 源位置                                          | 迁移目标               | 复杂度 |
| ------------ | ----------------------------------------------- | ---------------------- | ------ |
| **频谱分诊** | `audio_spectrum_classifier.py`                  | 新建 `DiagnosisStage`  | 中     |
| **人声分离** | `demucs_service.py`                             | 新建 `SeparationStage` | 高     |
| **熔断回溯** | `fuse_breaker.py` + `circuit_breaker_models.py` | 集成到 `FastWorker`    | 高     |

#### **P1 - 应该迁移（功能完整性）**

| 模块              | 源位置                               | 迁移目标                 | 复杂度 |
| ----------------- | ------------------------------------ | ------------------------ | ------ |
| **Whisper缓冲池** | `whisper_buffer_pool.py`             | `SlowWorker` 可选模式    | 高     |
| **Checkpoint**    | `transcription_service.py:1341-1416` | 新建 `CheckpointManager` | 中     |
| **SRT生成**       | `transcription_service.py:4178-4227` | 新建 `SRTGenerator`      | 低     |

#### **P2 - 可选迁移（增强功能）**

| 模块        | 源位置 | 迁移目标                   | 复杂度 |
| ----------- | ------ | -------------------------- | ------ |
| **LLM校对** | 未实现 | 新建 `LLMRefinementStage`  | 高     |
| **LLM翻译** | 未实现 | 新建 `LLMTranslationStage` | 高     |

---

### 三、解耦后的新架构设计

```
                    ┌─────────────────────────────────┐
                    │         VideoInput              │
                    └─────────────┬───────────────────┘
                                  │
                    ┌─────────────▼───────────────────┐
                    │    AudioProcessingPipeline      │
                    │    (音频提取 + VAD + 合并)       │
                    │    [已实现]                      │
                    └─────────────┬───────────────────┘
                                  │ List[AudioChunk]
                                  │
          ┌───────────────────────┼───────────────────────┐
          │                       │                       │
          ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│ DiagnosisStage  │    │ SeparationStage │    │ (可选跳过)      │
│ 频谱分诊         │───▶│ 人声分离        │    │                 │
│ [需新建]         │    │ [需新建]        │    │                 │
└─────────────────┘    └────────┬────────┘    └─────────────────┘
                                │
                    ┌───────────▼────────────────────┐
                    │     AsyncDualPipeline           │
                    │     (三级异步流水线)             │
                    │     [已实现，需增强]             │
                    ├────────────────────────────────┤
                    │                                │
                    │  ┌──────────────────────────┐  │
                    │  │ FastWorker (CPU)         │  │
                    │  │ + 熔断回溯循环 [需集成]   │  │
                    │  │ SenseVoice → 分句 → SSE  │  │
                    │  └────────────┬─────────────┘  │
                    │               │ Queue1         │
                    │  ┌────────────▼─────────────┐  │
                    │  │ SlowWorker (GPU)         │  │
                    │  │ + 缓冲池模式 [需集成]     │  │
                    │  │ Whisper → 幻觉检测       │  │
                    │  └────────────┬─────────────┘  │
                    │               │ Queue2         │
                    │  ┌────────────▼─────────────┐  │
                    │  │ AlignmentWorker (CPU)    │  │
                    │  │ 双流对齐 → 分句 → SSE    │  │
                    │  │ [已实现]                  │  │
                    │  └──────────────────────────┘  │
                    │                                │
                    └───────────────┬────────────────┘
                                    │ List[Sentence]
                                    │
                    ┌───────────────▼────────────────┐
                    │     RefinementPipeline         │
                    │     (后处理增强流水线)          │
                    │     [需新建]                    │
                    ├────────────────────────────────┤
                    │  LLMProofreadStage (可选)      │
                    │  LLMTranslateStage (可选)      │
                    └───────────────┬────────────────┘
                                    │
                    ┌───────────────▼────────────────┐
                    │     OutputPipeline             │
                    │     (输出生成流水线)            │
                    │     [需新建]                    │
                    ├────────────────────────────────┤
                    │  SRTGenerator                  │
                    │  CheckpointManager             │
                    └───────────────┬────────────────┘
                                    │
                    ┌───────────────▼────────────────┐
                    │         SRT Output             │
                    └────────────────────────────────┘
```

---

### 四、各模块解耦详细方案

#### **模块 1: 频谱分诊 (DiagnosisStage)**

```python
# backend/app/pipelines/stages/diagnosis_stage.py (新建)

class DiagnosisStage:
    """频谱分诊阶段 - 决定每个 Chunk 是否需要人声分离"""
  
    def __init__(self, spectrum_threshold: float = 0.35):
        self.classifier = AudioSpectrumClassifier()
        self.threshold = spectrum_threshold
  
    async def process(self, chunks: List[AudioChunk]) -> List[DiagnosedChunk]:
        """批量分诊所有 Chunk"""
        diagnoses = self.classifier.diagnose_chunks(
            chunks, threshold=self.threshold
        )
        return [
            DiagnosedChunk(chunk=c, diagnosis=d) 
            for c, d in zip(chunks, diagnoses)
        ]
```

**依赖文件**:
- `audio_spectrum_classifier.py` - 直接复用，无需修改

---

#### **模块 2: 人声分离 (SeparationStage)**

```python
# backend/app/pipelines/stages/separation_stage.py (新建)

class SeparationStage:
    """人声分离阶段 - 根据分诊结果执行分离"""
  
    def __init__(self, strategy: str = 'auto'):
        self.demucs_service = get_demucs_service()
        self.strategy = strategy  # off/auto/force_on
  
    async def process(
        self, 
        diagnosed_chunks: List[DiagnosedChunk]
    ) -> List[ProcessedChunk]:
        """根据策略执行分离"""
        results = []
        for dc in diagnosed_chunks:
            if self._should_separate(dc):
                separated = await self.demucs_service.separate_chunk(
                    dc.chunk, model=dc.diagnosis.recommended_model
                )
                results.append(ProcessedChunk(
                    chunk=separated,
                    original_chunk=dc.chunk,  # 保留原始用于熔断回溯
                    separation_level=SeparationLevel.from_model(model)
                ))
            else:
                results.append(ProcessedChunk(
                    chunk=dc.chunk,
                    original_chunk=dc.chunk,
                    separation_level=SeparationLevel.NONE
                ))
        return results
```

**依赖文件**:
- `demucs_service.py` - 直接复用
- `circuit_breaker_models.py` 中的 `SeparationLevel` - 需提取

---

#### **模块 3: 熔断回溯 (集成到 FastWorker)**

```python
# backend/app/pipelines/workers/fast_worker.py (修改)

class FastWorker:
    def __init__(self, ..., enable_fusing: bool = True):
        self.fuse_breaker = FuseBreaker() if enable_fusing else None
        self.demucs_service = get_demucs_service()
  
    async def process(self, ctx: ProcessingContext):
        """带熔断回溯的处理流程"""
        max_retries = 1
      
        for retry in range(max_retries + 1):
            # SenseVoice 转录
            sv_result = await self._run_sensevoice(ctx.current_audio)
            ctx.sv_result = sv_result
          
            # 熔断决策
            if self.fuse_breaker:
                decision = self.fuse_breaker.should_fuse(
                    confidence=sv_result.get('confidence', 1.0),
                    event_tag=sv_result.get('event_tag'),
                    separation_level=ctx.separation_level,
                    retry_count=retry
                )
              
                if decision.action == FuseAction.ACCEPT:
                    break
                elif decision.action == FuseAction.UPGRADE_SEPARATION:
                    # 回溯到原始音频，升级分离
                    ctx.current_audio = await self._upgrade_separation(
                        ctx.original_audio, 
                        target_level=decision.target_level
                    )
                    ctx.separation_level = decision.target_level
                    continue
            else:
                break
      
        # 分句和推送
        await self._split_and_push(ctx)
```

**依赖文件**:
- `fuse_breaker.py` - 需解耦为独立服务
- `circuit_breaker_models.py` - `FuseAction`, `SeparationLevel` 等

---

#### **模块 4: Whisper 缓冲池 (SlowWorker 可选模式)**

```python
# backend/app/pipelines/workers/slow_worker.py (修改)

class SlowWorker:
    def __init__(self, ..., mode: str = 'per_chunk'):
        """
        mode: 
          - 'per_chunk': 逐 Chunk 推理 (sv_whisper_patch)
          - 'buffered': 缓冲池模式 (sv_whisper_dual/DEEP_LISTEN)
        """
        self.mode = mode
        if mode == 'buffered':
            self.buffer_service = WhisperBufferService()
  
    async def process(self, ctx: ProcessingContext):
        if self.mode == 'per_chunk':
            # 原有逻辑
            await self._process_single_chunk(ctx)
        else:
            # 缓冲池模式
            await self._process_with_buffer(ctx)
  
    async def _process_with_buffer(self, ctx: ProcessingContext):
        """缓冲池模式处理"""
        # 添加到缓冲池
        self.buffer_service.add_chunk(ctx)
      
        # 检查是否触发处理
        if self.buffer_service.should_flush():
            results = await self.buffer_service.flush_and_process()
            for result_ctx in results:
                # 设置 whisper_result
                result_ctx.whisper_result = result_ctx.buffer_result
```

**依赖文件**:
- `whisper_buffer_pool.py` - 直接复用

---

#### **模块 5: Checkpoint 管理器**

```python
# backend/app/pipelines/checkpoint_manager.py (新建)

class CheckpointManager:
    """断点续传管理器"""
  
    def __init__(self, job_id: str, checkpoint_dir: Path):
        self.job_id = job_id
        self.checkpoint_path = checkpoint_dir / f"{job_id}_checkpoint.json"
  
    async def save(self, state: PipelineState):
        """原子保存 checkpoint"""
        temp_path = self.checkpoint_path.with_suffix('.tmp')
      
        data = {
            'job_id': self.job_id,
            'timestamp': time.time(),
            'processed_chunks': state.processed_chunk_indices,
            'sentences': [s.to_dict() for s in state.sentences],
            'original_settings': state.settings.to_dict(),
        }
      
        # 原子写入
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
      
        temp_path.rename(self.checkpoint_path)
  
    async def load(self) -> Optional[PipelineState]:
        """加载 checkpoint"""
        if not self.checkpoint_path.exists():
            return None
      
        with open(self.checkpoint_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
      
        return PipelineState.from_dict(data)
```

---

#### **模块 6: SRT 生成器**

```python
# backend/app/services/srt_generator.py (新建，从旧代码提取)

class SRTGenerator:
    """SRT 字幕生成器"""
  
    @staticmethod
    def generate(
        sentences: List[Sentence],
        output_path: Path,
        bilingual: bool = False,
        target_language: str = None
    ) -> Path:
        """从句子列表生成 SRT 文件"""
        srt_content = []
      
        for i, sentence in enumerate(sentences, 1):
            start = SRTGenerator._format_timestamp(sentence.start)
            end = SRTGenerator._format_timestamp(sentence.end)
          
            text = sentence.text
            if bilingual and sentence.translation:
                text = f"{sentence.text}\n{sentence.translation}"
          
            srt_content.append(f"{i}\n{start} --> {end}\n{text}\n")
      
        output_path.write_text('\n'.join(srt_content), encoding='utf-8')
        return output_path
```

---

### 五、配置统一方案

废除旧版配置后，统一使用新版配置结构：

```python
# 废除
class SenseVoiceSettings:  # 删除
class DemucsSettings:      # 删除

# 保留并完善
@dataclass
class JobSettings:
    preset_id: str = "balanced"
    preprocessing: PreprocessingConfig   # 替代 DemucsSettings
    transcription: TranscriptionConfig   # 替代 SenseVoiceSettings
    refinement: RefinementConfig
    compute: ComputeConfig
  
    # 删除这些旧字段
    # demucs: DemucsSettings  ← 删除
    # sensevoice: SenseVoiceSettings  ← 删除
```

---

### 六、迁移执行顺序

```
Phase 1: 基础设施 (1-2天)
├── 创建 ConfigAdapter (临时兼容层)
├── 修复 job_queue_service.py 流水线选择
└── 统一配置访问

Phase 2: 前处理流水线 (2-3天)
├── 新建 DiagnosisStage
├── 新建 SeparationStage
└── 集成到 AudioProcessingPipeline

Phase 3: 核心流水线增强 (3-4天)
├── FastWorker 集成熔断回溯
├── SlowWorker 支持缓冲池模式
└── 完善 ProcessingContext

Phase 4: 后处理流水线 (2-3天)
├── 新建 CheckpointManager
├── 新建 SRTGenerator
└── 预留 LLM 增强接口

Phase 5: 清理废弃代码 (1-2天)
├── 删除 _process_video_sensevoice
├── 删除 SenseVoiceSettings / DemucsSettings
├── 删除 旧版配置兼容代码
└── 更新文档
```

---

你想从哪个 Phase 开始？我建议先从 **Phase 1** 开始，因为它能立即修复当前的配置路由问题，让你马上能正确使用新架构。