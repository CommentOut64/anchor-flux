# 频谱分诊、人声分离、熔断回溯迁移方案 - 激进式重构

## 文档信息

- **方案类型**: 方案B - 激进式重构
- **创建日期**: 2025-12-18
- **目标**: 将旧架构的频谱分诊、人声分离、熔断回溯三大机制迁移到新架构，实现高内聚低耦合
- **默认模式**: 每chunk频谱分诊按需分离
- **用户选择**: 支持前端选择分离模式

---

## 一、方案概述

### 1.1 核心目标

1. **统一预处理流程**: 创建PreprocessingPipeline统一管理所有预处理步骤
2. **高内聚低耦合**: 通过Stage模式解耦各个处理步骤
3. **支持两种模式**:
   - 每chunk频谱分诊按需分离（默认）
   - 全局分离模式（用户可选）
4. **增强熔断回溯**: max_fuse_retry=2，第二次自动升级模型
5. **前端可配置**: 用户可在前端选择分离模式和熔断策略

### 1.2 架构设计原则

- **单一职责**: 每个Stage只负责一个功能
- **依赖注入**: 通过构造函数注入依赖
- **配置驱动**: 所有行为通过配置控制
- **可测试性**: 每个Stage可独立单元测试
- **可观测性**: 完整的日志和SSE事件推送

### 1.3 迁移策略

**激进式重构**:
- 彻底重构预处理流程
- 创建新的Pipeline和Stage
- 保留旧代码作为参考，但不再使用
- 一次性切换到新架构

---

## 二、核心架构设计

### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                    PreprocessingPipeline                        │
│                    (预处理流水线)                                │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ Stage 1: AudioExtractionStage                            │  │
│  │ 音频提取 + VAD切分                                        │  │
│  │ 输入: video_path                                          │  │
│  │ 输出: List[AudioChunk] (原始音频)                         │  │
│  └────────────────────┬─────────────────────────────────────┘  │
│                       │                                         │
│  ┌────────────────────▼─────────────────────────────────────┐  │
│  │ Stage 2: SpectralTriageStage                            │  │
│  │ 频谱分诊 - 为每个chunk标记是否需要分离                    │  │
│  │ 输入: List[AudioChunk]                                   │  │
│  │ 输出: List[AudioChunk] (带needs_separation标记)          │  │
│  └────────────────────┬─────────────────────────────────────┘  │
│                       │                                         │
│  ┌────────────────────▼─────────────────────────────────────┐  │
│  │ Stage 3: SeparationStage                                │  │
│  │ 人声分离 - 根据模式和标记执行分离                         │  │
│  │ 模式1: 全局分离 (整轨分离)                               │  │
│  │ 模式2: 按需分离 (仅分离标记的chunk)                       │  │
│  │ 输入: List[AudioChunk]                                   │  │
│  │ 输出: List[AudioChunk] (分离后的音频)                     │  │
│  └────────────────────┬─────────────────────────────────────┘  │
│                       │                                         │
│                       ▼                                         │
│              List[AudioChunk]                                   │
│              (准备好进入转录流水线)                              │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────────┐
│                    AsyncDualPipeline                            │
│                    (转录流水线)                                  │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │ FastWorker (集成熔断回溯)                                 │  │
│  │ SenseVoice推理 + 熔断决策 + 升级分离                      │  │
│  │ max_fuse_retry=2, 第二次自动升级模型                      │  │
│  └────────────────────┬─────────────────────────────────────┘  │
│                       │                                         │
│  ┌────────────────────▼─────────────────────────────────────┐  │
│  │ SlowWorker                                               │  │
│  │ Whisper推理 + 幻觉检测                                    │  │
│  └────────────────────┬─────────────────────────────────────┘  │
│                       │                                         │
│  ┌────────────────────▼─────────────────────────────────────┐  │
│  │ AlignmentWorker                                          │  │
│  │ 双流对齐 + 三级降级                                       │  │
│  └──────────────────────────────────────────────────────────┘  │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 数据流设计

```
视频文件
  ↓
AudioExtractionStage: 提取音频 + VAD切分
  ↓
List[AudioChunk] (原始音频)
  ↓
SpectralTriageStage: 频谱分诊
  ↓
List[AudioChunk] (带needs_separation和recommended_model标记)
  ↓
SeparationStage: 人声分离
  ├─ 模式1: 全局分离 → 整轨分离 → 重新VAD切分
  └─ 模式2: 按需分离 → 仅分离标记的chunk
  ↓
List[AudioChunk] (分离后的音频)
  ↓
AsyncDualPipeline: 转录流水线
  ↓
FastWorker: SenseVoice推理
  ├─ 置信度检查
  ├─ 熔断决策
  └─ 升级分离 (如果需要)
  ↓
SlowWorker: Whisper推理
  ↓
AlignmentWorker: 双流对齐
  ↓
最终字幕
```

---

## 三、核心数据结构设计

### 3.1 AudioChunk扩展

```python
# backend/app/services/audio/chunk_engine.py

@dataclass
class AudioChunk:
    """音频片段 - 扩展版"""

    # 原有字段
    index: int
    start: float
    end: float
    audio: np.ndarray
    sample_rate: int

    # 新增字段 - 频谱分诊相关
    needs_separation: bool = False  # 是否需要人声分离
    recommended_model: Optional[str] = None  # 推荐模型 (htdemucs/mdx_extra)
    spectrum_diagnosis: Optional[SpectrumDiagnosis] = None  # 完整的分诊结果

    # 新增字段 - 分离状态相关
    is_separated: bool = False  # 是否已分离
    separation_level: SeparationLevel = SeparationLevel.NONE  # 分离级别
    original_audio: Optional[np.ndarray] = None  # 原始音频（用于熔断回溯）

    # 新增字段 - 熔断回溯相关
    fuse_retry_count: int = 0  # 熔断重试次数
    last_confidence: float = 1.0  # 上次转录的置信度
```

### 3.2 SeparationLevel枚举

```python
# backend/app/models/circuit_breaker_models.py

class SeparationLevel(str, Enum):
    """分离级别"""
    NONE = "none"  # 未分离
    HTDEMUCS = "htdemucs"  # 轻度分离
    MDX_EXTRA = "mdx_extra"  # 重度分离

    def can_upgrade(self) -> bool:
        """是否可以升级"""
        return self != SeparationLevel.MDX_EXTRA

    def next_level(self) -> Optional['SeparationLevel']:
        """下一个级别"""
        if self == SeparationLevel.NONE:
            return SeparationLevel.HTDEMUCS
        elif self == SeparationLevel.HTDEMUCS:
            return SeparationLevel.MDX_EXTRA
        return None
```

### 3.3 PreprocessingConfig配置

```python
# backend/app/models/job_models.py

@dataclass
class PreprocessingConfig:
    """预处理配置"""

    # 人声分离配置
    enable_demucs: bool = True  # 是否启用人声分离
    separation_mode: str = 'on_demand'  # 分离模式: 'global' or 'on_demand'
    demucs_model: Optional[str] = None  # 指定模型（None表示自动选择）
    demucs_shifts: int = 1  # Demucs shifts参数

    # 频谱分诊配置
    enable_spectral_triage: bool = True  # 是否启用频谱分诊
    spectrum_threshold: float = 0.35  # 频谱分诊阈值

    # 熔断回溯配置
    enable_fuse_breaker: bool = True  # 是否启用熔断回溯
    fuse_max_retry: int = 2  # 最大重试次数
    fuse_confidence_threshold: float = 0.5  # 置信度阈值
    fuse_auto_upgrade: bool = True  # 第二次重试是否自动升级模型

    # VAD配置
    vad_method: str = 'silero'  # VAD方法
    vad_threshold: float = 0.5  # VAD阈值
```

---

## 四、Stage详细设计

### 4.1 SpectralTriageStage (频谱分诊阶段)

**职责**: 为每个AudioChunk进行频谱分析，判断是否需要人声分离，并推荐合适的模型

**输入**: `List[AudioChunk]` (原始音频)

**输出**: `List[AudioChunk]` (带needs_separation和recommended_model标记)

**核心逻辑**:
```python
# backend/app/pipelines/stages/spectral_triage_stage.py

class SpectralTriageStage:
    """频谱分诊阶段"""

    def __init__(self,
                 classifier: Optional[AudioSpectrumClassifier] = None,
                 threshold: float = 0.35):
        self.classifier = classifier or get_spectrum_classifier()
        self.threshold = threshold
        self.logger = logging.getLogger(__name__)

    async def process(self, chunks: List[AudioChunk]) -> List[AudioChunk]:
        """批量分诊所有chunk"""
        self.logger.info(f"开始频谱分诊，共 {len(chunks)} 个chunk")

        # 批量分诊
        diagnoses = self.classifier.diagnose_chunks(
            chunks=[c.audio for c in chunks],
            sr=chunks[0].sample_rate if chunks else 16000,
            threshold=self.threshold
        )

        # 为每个chunk添加分诊结果
        for chunk, diagnosis in zip(chunks, diagnoses):
            chunk.needs_separation = diagnosis.need_separation
            chunk.recommended_model = diagnosis.recommended_model
            chunk.spectrum_diagnosis = diagnosis

        # 统计
        need_sep_count = sum(1 for c in chunks if c.needs_separation)
        self.logger.info(
            f"频谱分诊完成: {need_sep_count}/{len(chunks)} 个chunk需要分离"
        )

        return chunks
```

**优化点**:
1. 支持并行处理（使用asyncio.gather）
2. 添加缓存机制（避免重复分诊）
3. 支持自适应阈值（根据音频长度调整）

---

### 4.2 SeparationStage (人声分离阶段)

**职责**: 根据分离模式和频谱分诊结果，执行人声分离

**输入**: `List[AudioChunk]` (带needs_separation标记)

**输出**: `List[AudioChunk]` (分离后的音频)

**支持两种模式**:
1. **全局分离模式** (global): 整轨分离，然后重新VAD切分
2. **按需分离模式** (on_demand): 仅分离标记的chunk

**核心逻辑**:
```python
# backend/app/pipelines/stages/separation_stage.py

class SeparationStage:
    """人声分离阶段"""

    def __init__(self,
                 mode: str = 'on_demand',
                 demucs_service: Optional[DemucsService] = None):
        self.mode = mode  # 'global' or 'on_demand'
        self.demucs_service = demucs_service or get_demucs_service()
        self.logger = logging.getLogger(__name__)

    async def process(self,
                      chunks: List[AudioChunk],
                      audio_path: Optional[str] = None) -> List[AudioChunk]:
        """执行人声分离"""
        if self.mode == 'global':
            return await self._process_global(chunks, audio_path)
        else:
            return await self._process_on_demand(chunks)

    async def _process_global(self,
                               chunks: List[AudioChunk],
                               audio_path: str) -> List[AudioChunk]:
        """全局分离模式"""
        self.logger.info("执行全局人声分离")

        # 整轨分离
        separated_path = await self.demucs_service.separate_vocals(
            audio_path=audio_path,
            model='htdemucs'  # 默认使用htdemucs
        )

        # 重新VAD切分
        # TODO: 调用VAD服务重新切分

        return chunks

    async def _process_on_demand(self,
                                  chunks: List[AudioChunk]) -> List[AudioChunk]:
        """按需分离模式"""
        need_sep_chunks = [c for c in chunks if c.needs_separation]
        self.logger.info(f"按需分离: {len(need_sep_chunks)}/{len(chunks)} 个chunk")

        for chunk in need_sep_chunks:
            # 保存原始音频（用于熔断回溯）
            chunk.original_audio = chunk.audio.copy()

            # 执行分离
            model = chunk.recommended_model or 'htdemucs'
            separated_audio = await self._separate_chunk(
                chunk.audio,
                chunk.sample_rate,
                model
            )

            # 更新chunk
            chunk.audio = separated_audio
            chunk.is_separated = True
            chunk.separation_level = SeparationLevel(model)

        return chunks

    async def _separate_chunk(self,
                               audio: np.ndarray,
                               sr: int,
                               model: str) -> np.ndarray:
        """分离单个chunk"""
        # 调用DemucsService
        separated = await self.demucs_service.separate_chunk(
            audio=audio,
            sr=sr,
            model=model
        )
        return separated
```

**优化点**:
1. 支持批量分离（减少模型加载次数）
2. 添加分离质量检查
3. 支持分离失败的降级策略

---

### 4.3 FuseBreakerStage (熔断回溯阶段)

**职责**: 在FastWorker中集成熔断回溯机制，当SenseVoice转录质量低时自动升级分离模型

**关键改进**:
1. **max_fuse_retry=2**: 允许完整的升级路径（NONE → HTDEMUCS → MDX_EXTRA）
2. **自动升级**: 第二次重试自动升级到更强的模型
3. **动态阈值**: 根据语言类型调整置信度阈值
4. **事件标签权重**: 不同标签有不同的触发权重

**核心逻辑**:
```python
# backend/app/services/fuse_breaker.py (优化版)

class FuseBreakerV2:
    """熔断决策器 V2 - 增强版"""

    def __init__(self,
                 max_retry: int = 2,
                 confidence_threshold: float = 0.5,
                 auto_upgrade: bool = True):
        self.max_retry = max_retry
        self.confidence_threshold = confidence_threshold
        self.auto_upgrade = auto_upgrade
        self.logger = logging.getLogger(__name__)

        # 事件标签权重
        self.event_weights = {
            'BGM': 1.0,      # 最高优先级
            'Music': 0.9,
            'Noise': 0.8,
            'Applause': 0.6  # 较低优先级
        }

    def should_fuse(self,
                    chunk: AudioChunk,
                    sv_result: dict) -> FuseDecision:
        """熔断决策"""
        confidence = sv_result.get('confidence', 1.0)
        event_tag = sv_result.get('event_tag')

        # 检查是否达到重试上限
        if chunk.fuse_retry_count >= self.max_retry:
            return FuseDecision(
                action=FuseAction.ACCEPT,
                reason="已达最大重试次数"
            )

        # 检查置信度
        if confidence >= self.confidence_threshold:
            return FuseDecision(
                action=FuseAction.ACCEPT,
                reason=f"置信度足够 ({confidence:.2f})"
            )

        # 检查事件标签
        if not event_tag or event_tag not in self.event_weights:
            return FuseDecision(
                action=FuseAction.ACCEPT,
                reason="无背景干扰标签"
            )

        # 计算加权置信度
        weight = self.event_weights[event_tag]
        weighted_confidence = confidence * (1 + weight)

        if weighted_confidence >= self.confidence_threshold:
            return FuseDecision(
                action=FuseAction.ACCEPT,
                reason=f"加权置信度足够 ({weighted_confidence:.2f})"
            )

        # 触发熔断升级
        next_level = self._get_next_level(chunk)
        if next_level is None:
            return FuseDecision(
                action=FuseAction.ACCEPT,
                reason="已达最高分离级别"
            )

        return FuseDecision(
            action=FuseAction.UPGRADE_SEPARATION,
            target_level=next_level,
            reason=f"置信度低 ({confidence:.2f}) + {event_tag}标签"
        )

    def _get_next_level(self, chunk: AudioChunk) -> Optional[SeparationLevel]:
        """获取下一个分离级别"""
        current = chunk.separation_level

        # 第一次重试：NONE → HTDEMUCS
        if current == SeparationLevel.NONE:
            return SeparationLevel.HTDEMUCS

        # 第二次重试：自动升级到最高级别
        if self.auto_upgrade and chunk.fuse_retry_count == 1:
            return SeparationLevel.MDX_EXTRA

        # 否则按顺序升级
        return current.next_level()

    async def execute_upgrade(self,
                              chunk: AudioChunk,
                              target_level: SeparationLevel,
                              demucs_service: DemucsService) -> AudioChunk:
        """执行升级分离"""
        self.logger.info(
            f"Chunk {chunk.index}: 升级分离 "
            f"{chunk.separation_level} → {target_level}"
        )

        # 使用原始音频
        if chunk.original_audio is None:
            raise ValueError("原始音频不存在，无法回溯")

        # 执行分离
        model = target_level.value
        separated_audio = await demucs_service.separate_chunk(
            audio=chunk.original_audio,
            sr=chunk.sample_rate,
            model=model
        )

        # 更新chunk
        chunk.audio = separated_audio
        chunk.separation_level = target_level
        chunk.fuse_retry_count += 1

        return chunk
```

**集成到FastWorker**:
```python
# backend/app/pipelines/workers/fast_worker.py (修改版)

class FastWorker:
    """快流推理Worker - 集成熔断回溯"""

    def __init__(self,
                 config: PreprocessingConfig,
                 sensevoice_executor: SenseVoiceExecutor,
                 demucs_service: DemucsService):
        self.config = config
        self.sensevoice_executor = sensevoice_executor
        self.demucs_service = demucs_service

        # 初始化熔断决策器
        if config.enable_fuse_breaker:
            self.fuse_breaker = FuseBreakerV2(
                max_retry=config.fuse_max_retry,
                confidence_threshold=config.fuse_confidence_threshold,
                auto_upgrade=config.fuse_auto_upgrade
            )
        else:
            self.fuse_breaker = None

    async def process(self, ctx: ProcessingContext):
        """处理单个chunk - 带熔断回溯"""
        chunk = ctx.audio_chunk

        # 熔断循环
        while True:
            # SenseVoice推理
            sv_result = await self.sensevoice_executor.execute(
                audio=chunk.audio,
                sr=chunk.sample_rate
            )
            ctx.sv_result = sv_result

            # 熔断决策
            if self.fuse_breaker:
                decision = self.fuse_breaker.should_fuse(chunk, sv_result)

                if decision.action == FuseAction.ACCEPT:
                    # 接受结果，退出循环
                    break
                elif decision.action == FuseAction.UPGRADE_SEPARATION:
                    # 升级分离，继续循环
                    chunk = await self.fuse_breaker.execute_upgrade(
                        chunk=chunk,
                        target_level=decision.target_level,
                        demucs_service=self.demucs_service
                    )
                    continue
            else:
                # 未启用熔断，直接接受
                break

        # 分句和推送
        await self._split_and_push(ctx)
```

---

## 五、PreprocessingPipeline完整实现

### 5.1 Pipeline主类

```python
# backend/app/pipelines/preprocessing_pipeline.py

class PreprocessingPipeline:
    """预处理流水线 - 统一管理所有预处理步骤"""

    def __init__(self, config: PreprocessingConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # 初始化各个Stage
        self.audio_extraction_stage = AudioExtractionStage(
            vad_method=config.vad_method,
            vad_threshold=config.vad_threshold
        )

        if config.enable_spectral_triage:
            self.spectral_triage_stage = SpectralTriageStage(
                threshold=config.spectrum_threshold
            )
        else:
            self.spectral_triage_stage = None

        if config.enable_demucs:
            self.separation_stage = SeparationStage(
                mode=config.separation_mode
            )
        else:
            self.separation_stage = None

    async def process(self,
                      video_path: str,
                      job_state: Optional[JobState] = None) -> List[AudioChunk]:
        """执行完整的预处理流程"""
        self.logger.info(f"开始预处理: {video_path}")

        # Stage 1: 音频提取 + VAD切分
        chunks = await self.audio_extraction_stage.process(
            video_path=video_path,
            job_state=job_state
        )
        self.logger.info(f"音频提取完成: {len(chunks)} 个chunk")

        # Stage 2: 频谱分诊
        if self.spectral_triage_stage:
            chunks = await self.spectral_triage_stage.process(chunks)
            self.logger.info("频谱分诊完成")

        # Stage 3: 人声分离
        if self.separation_stage:
            chunks = await self.separation_stage.process(
                chunks=chunks,
                audio_path=video_path
            )
            self.logger.info("人声分离完成")

        self.logger.info(f"预处理完成: {len(chunks)} 个chunk准备就绪")
        return chunks
```

### 5.2 集成到TranscriptionService

```python
# backend/app/services/transcription_service.py (修改)

class TranscriptionService:
    """转录服务 - 使用新的PreprocessingPipeline"""

    async def process_video_v2(self,
                               job_id: str,
                               settings: JobSettings) -> dict:
        """使用新架构处理视频"""
        job_state = self.job_states[job_id]

        # 1. 预处理阶段
        preprocessing_pipeline = PreprocessingPipeline(
            config=settings.preprocessing
        )
        chunks = await preprocessing_pipeline.process(
            video_path=job_state.video_path,
            job_state=job_state
        )

        # 2. 转录阶段
        dual_pipeline = AsyncDualPipeline(
            job_id=job_id,
            config=settings,
            chunks=chunks
        )
        results = await dual_pipeline.run()

        # 3. 后处理阶段
        # ...

        return results
```

---

## 六、配置系统设计

### 6.1 前端配置界面

**新增配置选项**:

```typescript
// frontend/src/types/transcription.ts

interface PreprocessingConfig {
  // 人声分离配置
  enableDemucs: boolean;  // 是否启用人声分离
  separationMode: 'global' | 'on_demand';  // 分离模式
  demucsModel?: string;  // 指定模型（可选）

  // 频谱分诊配置
  enableSpectralTriage: boolean;  // 是否启用频谱分诊
  spectrumThreshold: number;  // 频谱分诊阈值

  // 熔断回溯配置
  enableFuseBreaker: boolean;  // 是否启用熔断回溯
  fuseMaxRetry: number;  // 最大重试次数
  fuseConfidenceThreshold: number;  // 置信度阈值
  fuseAutoUpgrade: boolean;  // 第二次重试是否自动升级
}
```

### 6.2 前端UI设计

**分离模式选择器**:
```vue
<!-- frontend/src/components/editor/SeparationModeSelector.vue -->

<template>
  <div class="separation-mode-selector">
    <h3>人声分离模式</h3>

    <el-radio-group v-model="config.separationMode">
      <el-radio label="on_demand">
        <div class="mode-option">
          <strong>按需分离（推荐）</strong>
          <p>仅对检测到背景音乐的片段进行分离，速度快</p>
        </div>
      </el-radio>

      <el-radio label="global">
        <div class="mode-option">
          <strong>全局分离</strong>
          <p>对整个音频进行分离，质量高但速度慢</p>
        </div>
      </el-radio>
    </el-radio-group>

    <el-divider />

    <h3>高级选项</h3>

    <el-form-item label="启用频谱分诊">
      <el-switch v-model="config.enableSpectralTriage" />
      <span class="help-text">
        自动检测背景音乐，决定是否需要分离
      </span>
    </el-form-item>

    <el-form-item label="启用熔断回溯">
      <el-switch v-model="config.enableFuseBreaker" />
      <span class="help-text">
        转录质量低时自动升级分离模型
      </span>
    </el-form-item>

    <el-form-item
      v-if="config.enableFuseBreaker"
      label="最大重试次数">
      <el-input-number
        v-model="config.fuseMaxRetry"
        :min="1"
        :max="3" />
    </el-form-item>

    <el-form-item
      v-if="config.enableFuseBreaker"
      label="自动升级模型">
      <el-switch v-model="config.fuseAutoUpgrade" />
      <span class="help-text">
        第二次重试时自动升级到最强模型
      </span>
    </el-form-item>
  </div>
</template>
```

### 6.3 预设方案集成

**扩展现有预设**:
```typescript
// frontend/src/config/presets.ts

const PREPROCESSING_PRESETS = {
  // 极速模式：不分离
  fast: {
    enableDemucs: false,
    enableSpectralTriage: false,
    enableFuseBreaker: false
  },

  // 平衡模式：按需分离 + 熔断回溯
  balanced: {
    enableDemucs: true,
    separationMode: 'on_demand',
    enableSpectralTriage: true,
    enableFuseBreaker: true,
    fuseMaxRetry: 2,
    fuseAutoUpgrade: true
  },

  // 质量模式：全局分离 + 熔断回溯
  quality: {
    enableDemucs: true,
    separationMode: 'global',
    enableSpectralTriage: true,
    enableFuseBreaker: true,
    fuseMaxRetry: 2,
    fuseAutoUpgrade: true
  }
};
```

---

## 七、实施步骤

### 第1周：核心Stage实现

**Day 1-2: 数据结构和基础类**
- [ ] 扩展AudioChunk数据结构
- [ ] 创建SeparationLevel枚举
- [ ] 创建PreprocessingConfig配置类
- [ ] 创建FuseDecision数据类

**Day 3-4: SpectralTriageStage**
- [ ] 实现SpectralTriageStage类
- [ ] 集成AudioSpectrumClassifier
- [ ] 添加批量处理支持
- [ ] 编写单元测试

**Day 5: SeparationStage**
- [ ] 实现SeparationStage类
- [ ] 实现全局分离模式
- [ ] 实现按需分离模式
- [ ] 编写单元测试

### 第2周：熔断回溯和Pipeline集成

**Day 1-2: FuseBreakerV2**
- [ ] 实现FuseBreakerV2类
- [ ] 实现事件标签权重机制
- [ ] 实现自动升级逻辑
- [ ] 编写单元测试

**Day 3-4: FastWorker集成**
- [ ] 修改FastWorker集成熔断回溯
- [ ] 实现熔断循环逻辑
- [ ] 添加日志和SSE事件
- [ ] 编写集成测试

**Day 5: PreprocessingPipeline**
- [ ] 实现PreprocessingPipeline类
- [ ] 集成所有Stage
- [ ] 修改TranscriptionService
- [ ] 编写集成测试

### 第3周：配置系统和前端集成

**Day 1-2: 后端配置**
- [ ] 扩展PreprocessingConfig
- [ ] 添加配置验证
- [ ] 更新API接口
- [ ] 编写配置测试

**Day 3-4: 前端UI**
- [ ] 创建SeparationModeSelector组件
- [ ] 集成到TaskListView
- [ ] 更新预设方案
- [ ] 编写前端测试

**Day 5: 文档和清理**
- [ ] 更新架构文档
- [ ] 更新API文档
- [ ] 清理旧代码
- [ ] 代码审查

---

## 八、测试计划

### 8.1 单元测试

**SpectralTriageStage测试**:
```python
# tests/test_spectral_triage_stage.py

async def test_spectral_triage_stage():
    """测试频谱分诊阶段"""
    stage = SpectralTriageStage()

    # 创建测试chunk
    chunks = [
        AudioChunk(index=0, audio=clean_audio, ...),
        AudioChunk(index=1, audio=music_audio, ...),
        AudioChunk(index=2, audio=noise_audio, ...)
    ]

    # 执行分诊
    result = await stage.process(chunks)

    # 验证结果
    assert result[0].needs_separation == False  # 纯净音频
    assert result[1].needs_separation == True   # 音乐
    assert result[1].recommended_model == 'htdemucs'
    assert result[2].needs_separation == True   # 噪音
```

**SeparationStage测试**:
```python
# tests/test_separation_stage.py

async def test_separation_stage_on_demand():
    """测试按需分离模式"""
    stage = SeparationStage(mode='on_demand')

    # 创建测试chunk（带分诊标记）
    chunks = [
        AudioChunk(needs_separation=False, ...),
        AudioChunk(needs_separation=True, recommended_model='htdemucs', ...)
    ]

    # 执行分离
    result = await stage.process(chunks)

    # 验证结果
    assert result[0].is_separated == False
    assert result[1].is_separated == True
    assert result[1].separation_level == SeparationLevel.HTDEMUCS
```

**FuseBreakerV2测试**:
```python
# tests/test_fuse_breaker_v2.py

def test_fuse_breaker_decision():
    """测试熔断决策"""
    breaker = FuseBreakerV2(max_retry=2, auto_upgrade=True)

    # 测试场景1：置信度足够
    chunk = AudioChunk(fuse_retry_count=0, ...)
    sv_result = {'confidence': 0.8, 'event_tag': 'BGM'}
    decision = breaker.should_fuse(chunk, sv_result)
    assert decision.action == FuseAction.ACCEPT

    # 测试场景2：置信度低 + BGM标签
    sv_result = {'confidence': 0.3, 'event_tag': 'BGM'}
    decision = breaker.should_fuse(chunk, sv_result)
    assert decision.action == FuseAction.UPGRADE_SEPARATION
    assert decision.target_level == SeparationLevel.HTDEMUCS

    # 测试场景3：第二次重试自动升级
    chunk.fuse_retry_count = 1
    chunk.separation_level = SeparationLevel.HTDEMUCS
    decision = breaker.should_fuse(chunk, sv_result)
    assert decision.target_level == SeparationLevel.MDX_EXTRA
```

### 8.2 集成测试

**完整流程测试**:
```python
# tests/test_preprocessing_pipeline_integration.py

async def test_full_preprocessing_pipeline():
    """测试完整预处理流程"""
    config = PreprocessingConfig(
        enable_demucs=True,
        separation_mode='on_demand',
        enable_spectral_triage=True,
        enable_fuse_breaker=True,
        fuse_max_retry=2
    )

    pipeline = PreprocessingPipeline(config)

    # 执行预处理
    chunks = await pipeline.process('test_video.mp4')

    # 验证结果
    assert len(chunks) > 0
    assert all(hasattr(c, 'needs_separation') for c in chunks)
    assert any(c.is_separated for c in chunks)  # 至少有一个被分离
```

### 8.3 性能测试

**测试指标**:
1. 预处理总耗时
2. 频谱分诊耗时
3. 人声分离耗时
4. 熔断回溯触发率
5. 内存占用峰值

**测试场景**:
1. 纯净人声视频（无BGM）
2. 轻度BGM视频
3. 重度BGM视频
4. 长视频（>30分钟）

---

## 九、风险评估与应对

### 9.1 技术风险

**风险1：性能下降**
- **描述**: 多层抽象可能导致性能损失
- **概率**: 中
- **影响**: 中
- **应对**:
  - 添加性能监控
  - 优化热点代码
  - 使用异步并行处理

**风险2：熔断回溯过度触发**
- **描述**: 熔断阈值设置不当，导致过度升级
- **概率**: 中
- **影响**: 高（增加处理时间）
- **应对**:
  - 基于实际数据调整阈值
  - 添加熔断统计和监控
  - 支持用户自定义阈值

**风险3：模型加载失败**
- **描述**: mdx_extra模型加载失败或显存不足
- **概率**: 低
- **影响**: 高
- **应对**:
  - 添加降级策略（回退到htdemucs）
  - 显存检查和预警
  - 支持模型预加载

### 9.2 业务风险

**风险4：用户体验下降**
- **描述**: 新架构复杂度增加，用户不理解配置选项
- **概率**: 中
- **影响**: 中
- **应对**:
  - 提供清晰的UI说明
  - 使用合理的默认值
  - 添加预设方案

**风险5：向后兼容性问题**
- **描述**: 旧任务无法使用新架构
- **概率**: 低
- **影响**: 中
- **应对**:
  - 保留旧架构作为备选
  - 添加版本标识
  - 支持配置迁移

### 9.3 项目风险

**风险6：开发周期延长**
- **描述**: 激进式重构工作量大，可能延期
- **概率**: 中
- **影响**: 中
- **应对**:
  - 分阶段实施
  - 每个阶段独立测试
  - 及时调整计划

---

## 十、总结

### 10.1 方案优势

1. **高内聚低耦合**: 通过Stage模式实现清晰的职责分离
2. **易于扩展**: 添加新的预处理步骤只需添加新Stage
3. **配置灵活**: 支持多种分离模式和熔断策略
4. **用户友好**: 前端提供清晰的配置界面
5. **性能优化**: 按需分离模式减少不必要的处理

### 10.2 关键决策

1. **默认模式**: 每chunk频谱分诊按需分离
2. **熔断策略**: max_fuse_retry=2，第二次自动升级
3. **模型选择**: 频谱分诊推荐，熔断回溯升级
4. **架构模式**: PreprocessingPipeline + Stage模式

### 10.3 后续优化方向

1. 添加更多频谱特征（MFCC、Chroma等）
2. 使用机器学习模型优化分诊准确率
3. 实现分离质量评估和自动降级
4. 添加分离缓存机制
5. 支持自定义分离模型

---

## 附录

### A. 相关文档

- [旧架构解耦迁移清单](./旧架构解耦迁移.md)
- [频谱分诊调查报告](../llmdoc/agent/audio_spectrum_classifier_investigation_report.md)
- [人声分离调查报告](../llmdoc/agent/demucs_service_legacy_architecture_investigation.md)
- [熔断回溯调查报告](../llmdoc/agent/fuse_breaker_architecture_investigation_report.md)
- [新架构管线调查报告](../llmdoc/agent/new_pipeline_architecture_investigation_report.md)

### B. 关键文件清单

**新增文件**:
- `backend/app/pipelines/preprocessing_pipeline.py`
- `backend/app/pipelines/stages/spectral_triage_stage.py`
- `backend/app/pipelines/stages/separation_stage.py`
- `backend/app/services/fuse_breaker_v2.py`
- `frontend/src/components/editor/SeparationModeSelector.vue`

**修改文件**:
- `backend/app/services/audio/chunk_engine.py` (扩展AudioChunk)
- `backend/app/models/circuit_breaker_models.py` (添加SeparationLevel)
- `backend/app/models/job_models.py` (扩展PreprocessingConfig)
- `backend/app/pipelines/workers/fast_worker.py` (集成熔断回溯)
- `backend/app/services/transcription_service.py` (使用新Pipeline)

### C. 配置示例

**默认配置（按需分离）**:
```json
{
  "preprocessing": {
    "enable_demucs": true,
    "separation_mode": "on_demand",
    "enable_spectral_triage": true,
    "spectrum_threshold": 0.35,
    "enable_fuse_breaker": true,
    "fuse_max_retry": 2,
    "fuse_confidence_threshold": 0.5,
    "fuse_auto_upgrade": true
  }
}
```

**全局分离配置**:
```json
{
  "preprocessing": {
    "enable_demucs": true,
    "separation_mode": "global",
    "enable_spectral_triage": false,
    "enable_fuse_breaker": true,
    "fuse_max_retry": 2,
    "fuse_auto_upgrade": true
  }
}
```

**极速模式（不分离）**:
```json
{
  "preprocessing": {
    "enable_demucs": false,
    "enable_spectral_triage": false,
    "enable_fuse_breaker": false
  }
}
```

---

**文档结束**
