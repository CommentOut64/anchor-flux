# 双流重构优化方案 V3.1.0

> **基于现有 V3.0 架构的渐进式优化**
> **目标**：提升吞吐量、防止资源卡顿、保持代码简洁性

---

## 1. 执行摘要

### 1.1 当前问题 (V3.0 架构)

| 问题 | 根因 | 影响 |
|------|------|------|
| **CPU-GPU 串行执行** | `_process_chunk()` 中 SenseVoice 和 Whisper 顺序执行 | 吞吐量仅 50%，GPU 空闲时 CPU 忙，CPU 空闲时 GPU 忙 |
| **资源卡顿风险** | ONNX Runtime 默认吃掉所有 CPU 核心 | Whisper CUDA 调度线程无核可用，导致卡顿 |
| **内存溢出风险** | 无队列背压，长视频时所有 Chunk 同时加载 | 可能导致 OOM |
| **缺少幻觉防御** | 已修复 (上次对话)，但需在流水线中集成 | Whisper 可能重复 prompt 或输出下划线 |

### 1.2 优化目标

1. **吞吐量提升 50%+**：通过错位并行，让 SenseVoice 处理 Chunk N+1 时，Whisper 同时处理 Chunk N
2. **消除卡顿风险**：限制 ONNX CPU 使用，为 Whisper 预留调度核心
3. **防止 OOM**：通过队列背压控制并发度
4. **保持代码质量**：不引入重型框架，最小化改动

### 1.3 方案概览

采用 **三级流水线架构**（生产者-消费者模型），数据单向流动：

```
AudioChunk → [FastWorker (CPU)]
               ↓ Queue1 (maxsize=5)
             [SlowWorker (GPU)]
               ↓ Queue2 (maxsize=5)
             [AlignmentWorker (CPU)]
               ↓ 完成
```

---

## 2. 架构设计

### 2.1 核心概念：ProcessingContext

**设计决策**：引入统一的上下文对象替代散乱的参数传递

```python
# backend/app/schemas/pipeline_context.py
from dataclasses import dataclass, field
from typing import Optional, List, Any

@dataclass
class ProcessingContext:
    """流水线处理上下文"""
    # 基础信息
    job_id: str
    chunk_index: int
    audio_chunk: Any  # AudioChunk 对象

    # 阶段产物
    sv_result: Optional[dict] = None      # FastWorker 产出
    whisper_result: Optional[dict] = None # SlowWorker 产出
    final_sentences: List[Any] = field(default_factory=list)  # AlignmentWorker 产出

    # 控制信号
    is_end: bool = False                  # 结束流标记
    error: Optional[Exception] = None     # 异常携带
```

**优势**：
- 避免参数爆炸
- 便于异常传播
- 易于调试（一个对象包含完整上下文）

### 2.2 三大 Worker

#### FastWorker (CPU 快流)

**职责**：
1. 执行 SenseVoice ONNX 推理
2. **立即**调用 SSE 推送草稿（确保用户体验）
3. 提取 Prompt 关键信息

**关键实现**：
```python
# backend/app/pipelines/workers/fast_worker.py
class FastWorker:
    async def process(self, ctx: ProcessingContext):
        # 1. SenseVoice 推理
        sv_result = await self.sensevoice_executor.execute(...)
        ctx.sv_result = sv_result

        # 2. 分句
        draft_sentences = self._split_sentences(sv_result, ...)

        # 3. 立即推送草稿（关键：不等待 Whisper）
        self.subtitle_manager.add_draft_sentences(
            ctx.chunk_index, draft_sentences
        )
```

**资源限制（关键！）**：
```python
# backend/app/services/inference/sensevoice_executor.py
import multiprocessing
import onnxruntime as ort

def load_model(self):
    # 保留 2 个核心给操作系统和 Whisper 调度
    total_cores = multiprocessing.cpu_count()
    intra_op_threads = max(1, total_cores - 2)

    sess_options = ort.SessionOptions()
    sess_options.intra_op_num_threads = intra_op_threads  # 最关键参数
    sess_options.inter_op_num_threads = 1

    self.model = ort.InferenceSession(
        ..., sess_options,
        providers=['CPUExecutionProvider']
    )
```

#### SlowWorker (GPU 慢流)

**职责**：
1. 基于 SV 结果构建 Whisper Prompt
2. 执行 Whisper CUDA 推理
3. **应用幻觉防御**（集成上次对话的修复）

**关键实现**：
```python
# backend/app/pipelines/workers/slow_worker.py
class SlowWorker:
    async def process(self, ctx: ProcessingContext):
        # 1. 构建安全 Prompt（关键词提取策略）
        prompt = self._build_safe_prompt(ctx.sv_result)

        # 2. Whisper 推理
        whisper_result = await self.whisper_executor.execute(
            audio=ctx.audio_chunk.audio,
            initial_prompt=prompt,
            condition_on_previous_text=False  # 防止双重提示词增益
        )

        # 3. 幻觉检测
        if self._is_hallucination(whisper_result, prompt):
            self.logger.warning("检测到幻觉，回退到 SenseVoice")
            whisper_result['text'] = ctx.sv_result['text_clean']

        ctx.whisper_result = whisper_result

    def _is_hallucination(self, result, prompt) -> bool:
        """检测 Whisper 幻觉（下划线、重复 prompt）"""
        text = result.get('text', '')
        if not text:
            return False

        # 检测 1：下划线占比 > 30%
        underscore_ratio = text.count('_') / max(len(text), 1)
        if underscore_ratio > 0.3:
            return True

        # 检测 2：重复 prompt 内容（相似度 > 80%）
        if prompt:
            prompt_words = set(prompt.split())
            text_words = set(text.split())
            if len(prompt_words) > 0:
                overlap_ratio = len(prompt_words & text_words) / len(prompt_words)
                if overlap_ratio > 0.8:
                    return True

        return False
```

#### AlignmentWorker (CPU 对齐层)

**职责**：
1. 执行双流对齐（三级降级策略）
2. 分句 + 语义分组
3. 推送定稿
4. 写入 SRT 文件（追加模式）

**关键实现**：
```python
# backend/app/pipelines/workers/alignment_worker.py
class AlignmentWorker:
    async def process(self, ctx: ProcessingContext):
        # 1. 双流对齐（三级降级）
        final_sentences, alignment_level = await self._align_and_fallback(
            ctx.whisper_result, ctx.sv_result, ctx.audio_chunk
        )

        # 2. 推送定稿（Chunk 级别批量替换）
        self.subtitle_manager.replace_chunk(
            ctx.chunk_index, final_sentences
        )

        # 3. 追加写入 SRT（无需锁，因为是串行处理）
        self._append_to_srt(final_sentences, ctx.job_id)

        ctx.final_sentences = final_sentences
```

### 2.3 流水线控制器

**职责**：编排生命周期，处理异常传播

```python
# backend/app/pipelines/async_dual_pipeline.py
class AsyncDualPipeline:
    def __init__(self, config, sse_manager):
        self.queue_inter = asyncio.Queue(maxsize=5)  # FastWorker → SlowWorker
        self.queue_final = asyncio.Queue(maxsize=5)  # SlowWorker → AlignmentWorker

        self.fast_worker = FastWorker(config, sse_manager)
        self.slow_worker = SlowWorker(config)
        self.align_worker = AlignmentWorker(config, sse_manager)

        self.errors = []  # 收集运行时错误

    async def run(self, job_id: str, audio_chunks: list):
        # 启动三个并行任务
        t_fast = asyncio.create_task(self._fast_loop(job_id, audio_chunks))
        t_slow = asyncio.create_task(self._slow_loop())
        t_align = asyncio.create_task(self._align_loop())

        # 等待所有任务结束（return_exceptions=True 确保一个挂了不会立刻抛出）
        results = await asyncio.gather(t_fast, t_slow, t_align, return_exceptions=True)

        # 检查是否有异常
        for res in results:
            if isinstance(res, Exception):
                raise res  # 抛出给 JobQueueService 处理

        if self.errors:
            raise self.errors[0]

    async def _fast_loop(self, job_id, chunks):
        try:
            for i, chunk in enumerate(chunks):
                ctx = ProcessingContext(job_id, i, chunk)
                await self.fast_worker.process(ctx)
                await self.queue_inter.put(ctx)

            # 发送结束信号
            await self.queue_inter.put(ProcessingContext(..., is_end=True))
        except Exception as e:
            self.errors.append(e)
            await self.queue_inter.put(ProcessingContext(..., is_end=True, error=e))

    async def _slow_loop(self):
        try:
            while True:
                ctx = await self.queue_inter.get()
                if ctx.is_end or ctx.error:
                    await self.queue_final.put(ctx)  # 透传结束/错误信号
                    break

                await self.slow_worker.process(ctx)
                await self.queue_final.put(ctx)
        except Exception as e:
            self.errors.append(e)
            await self.queue_final.put(ProcessingContext(..., is_end=True, error=e))

    async def _align_loop(self):
        try:
            while True:
                ctx = await self.queue_final.get()
                if ctx.is_end:
                    if ctx.error:
                        raise ctx.error  # 如果在上游发现错误，这里终止
                    break

                await self.align_worker.process(ctx)
        except Exception as e:
            self.errors.append(e)
```

**异常处理保证**：
- 任何 Worker 抛出异常都会被 `gather()` 捕获
- `JobQueueService` 的 `try...except` 块会执行标准错误处理（更新数据库、通知前端）
- 文件写入并发安全（AlignmentWorker 串行处理 queue_final）

---

## 3. 与现有架构的对比

### 3.1 代码位置映射

| 现有 V3.0 | 重构 V3.1.0 | 变化 |
|-----------|-------------|------|
| `DualAlignmentPipeline._process_chunk()` | 拆分为 3 个 Worker | 逻辑解耦 |
| `_run_sensevoice()` | `FastWorker.process()` | 复用，增加 SSE 推送 |
| `_run_whisper()` | `SlowWorker.process()` | 复用，增加幻觉检测 |
| `_align_and_fallback()` | `AlignmentWorker.process()` | 复用，增加 SRT 写入 |
| `DualAlignmentPipeline.run()` | `AsyncDualPipeline.run()` | 串行 → 流水线 |

### 3.2 性能对比（理论估算）

假设：
- SenseVoice 推理：1秒/Chunk
- Whisper 推理：2秒/Chunk
- 对齐+分句：0.5秒/Chunk
- 总共 10 个 Chunk

**V3.0 串行执行**：
```
Chunk 0: SV(1s) + Whisper(2s) + Align(0.5s) = 3.5s
Chunk 1: SV(1s) + Whisper(2s) + Align(0.5s) = 3.5s
...
总耗时 = 10 * 3.5s = 35s
```

**V3.1.0 流水线执行**：
```
t=0s:    Chunk 0 → FastWorker
t=1s:    Chunk 0 → SlowWorker,    Chunk 1 → FastWorker
t=2s:    Chunk 0 → AlignWorker,   Chunk 1 → SlowWorker,  Chunk 2 → FastWorker
t=2.5s:  Chunk 0 完成,            Chunk 1 → SlowWorker,  Chunk 2 → FastWorker
t=3s:    ...
总耗时 ≈ 3.5s (启动延迟) + 9 * 2s (流水线稳定期) = 21.5s
```

**提升**：35s → 21.5s，性能提升 **38.6%**

### 3.3 关键差异

| 维度 | V3.0 | V3.1.0 |
|------|------|--------|
| **并发模型** | 串行处理 Chunk | 流水线并行处理 |
| **CPU 限制** | ❌ 无 | ✅ ONNX SessionOptions |
| **队列背压** | ❌ 无 | ✅ asyncio.Queue(maxsize=5) |
| **幻觉防御** | ⚠️ 需手动集成 | ✅ 内置于 SlowWorker |
| **代码复杂度** | 中等（800行） | 中等（分3个文件，各300行） |

---

## 4. 实施计划

### Phase 1: 基础设施搭建 (1天)

**目标**：建立流水线基础，不改变现有逻辑

1. **创建数据类**：
   ```bash
   touch backend/app/schemas/pipeline_context.py
   ```

2. **修改 SenseVoice Executor（关键！）**：
   ```python
   # backend/app/services/inference/sensevoice_executor.py
   # 在 load_model() 中增加 CPU 线程限制
   ```

3. **验证 CPU 限制**：
   ```bash
   # 运行单 SenseVoice 任务，观察任务管理器
   # CPU 占用应留有 2-4 个核心的空余
   ```

### Phase 2: Worker 拆分 (2天)

**目标**：搬运代码到 Worker，不改逻辑

1. **创建 Worker 目录**：
   ```bash
   mkdir -p backend/app/pipelines/workers
   touch backend/app/pipelines/workers/__init__.py
   touch backend/app/pipelines/workers/fast_worker.py
   touch backend/app/pipelines/workers/slow_worker.py
   touch backend/app/pipelines/workers/alignment_worker.py
   ```

2. **FastWorker**：
   - 从 `DualAlignmentPipeline._run_sensevoice()` 复制推理逻辑
   - 从 `_split_sentences()` 复制分句逻辑
   - 调用 `subtitle_manager.add_draft_sentences()` 推送草稿

3. **SlowWorker**：
   - 从 `_run_whisper()` 复制推理逻辑
   - 从 `_build_whisper_prompt()` 复制 Prompt 构建
   - **新增**：集成幻觉检测逻辑（参考 2.2 节）

4. **AlignmentWorker**：
   - 从 `_align_and_fallback()` 复制对齐逻辑
   - 调用 `subtitle_manager.replace_chunk()` 推送定稿
   - **新增**：追加写入 SRT 文件

5. **单元测试**：
   ```python
   # tests/test_workers.py
   async def test_fast_worker():
       ctx = ProcessingContext(...)
       await fast_worker.process(ctx)
       assert ctx.sv_result is not None
   ```

### Phase 3: 流水线组装 (1天)

1. **创建 AsyncDualPipeline**：
   ```bash
   touch backend/app/pipelines/async_dual_pipeline.py
   ```

2. **实现三级流水线**（参考 2.3 节代码）

3. **集成到 JobQueueService**：
   ```python
   # backend/app/services/job_queue_service.py

   async def _run_dual_alignment_pipeline(self, job: 'JobState', preset_id: str):
       # 旧代码（保留注释）：
       # dual_pipeline = get_dual_alignment_pipeline(...)
       # results = await dual_pipeline.run(audio_result.chunks)

       # 新代码：
       from app.pipelines.async_dual_pipeline import AsyncDualPipeline
       async_pipeline = AsyncDualPipeline(...)
       await async_pipeline.run(job.job_id, audio_result.chunks)
   ```

### Phase 4: 集成测试 (2天)

1. **功能测试**：
   - 跑 1 个短视频（30秒），确认 SRT 内容与 V3.0 一致
   - 检查 SSE 事件（草稿、定稿）是否正常推送

2. **压力测试**：
   - 跑 1 个长视频（10分钟），监控：
     - 显存：确保 SenseVoice 没跑去 GPU
     - 内存：确保队列背压生效（内存不会直线上升）
     - CPU：确保留有 2-4 个核心空余（Whisper 调度不卡顿）

3. **异常测试**：
   - 中途停止任务（模拟取消/暂停），验证状态正确
   - 强制 OOM（输入超长视频），验证队列背压是否生效

4. **幻觉测试**：
   - 使用上次对话中的问题视频（`p02-80.mp4`）
   - 确认 SRT 中没有重复文本和下划线

### Phase 5: 清理与文档 (0.5天)

1. **删除旧代码**：
   ```bash
   # 保留 DualAlignmentPipeline 作为降级方案（V3.0 兼容）
   # 可在配置中添加 use_async_pipeline=True/False 开关
   ```

2. **更新文档**：
   - 更新 `llmdoc/architecture/dual-alignment-pipeline.md`
   - 新增 `llmdoc/guides/debugging-pipeline.md`（排查卡顿问题指南）

---

## 5. 风险与应对

### 5.1 风险评估

| 风险 | 概率 | 影响 | 应对措施 |
|------|------|------|----------|
| **CPU 限制过激** | 中 | 中 | 提供配置参数 `cpu_reserve_cores=2`，可调整 |
| **队列背压过小** | 低 | 低 | 提供配置参数 `queue_maxsize=5`，可调整 |
| **异常传播不完整** | 低 | 高 | Phase 4 详细测试，确保所有异常路径覆盖 |
| **幻觉检测误杀** | 中 | 中 | 记录详细日志，提供 `enable_hallucination_check=True` 开关 |
| **SRT 文件损坏** | 低 | 高 | 使用追加模式 + 临时文件 + rename 原子写入 |

### 5.2 降级方案

**如果 V3.1.0 出现严重问题**：
1. 保留 V3.0 代码（`DualAlignmentPipeline`）
2. 在 `JobQueueService` 中添加配置开关：
   ```python
   use_async_pipeline = config.get('USE_ASYNC_PIPELINE', False)
   ```
3. 用户可随时回退到 V3.0

---

## 6. 预期收益

### 6.1 性能收益

- **吞吐量**：提升 30-50%（取决于 SV/Whisper 耗时比）
- **首帧时间**：草稿推送时间不变（FastWorker 立即推送）
- **内存峰值**：降低 50%（队列背压限制并发度）

### 6.2 稳定性收益

- **消除卡顿**：CPU 预留核心，Whisper 调度不再被 ONNX 阻塞
- **防止 OOM**：队列背压自动限流，长视频不会内存溢出
- **幻觉防御**：内置检测逻辑，减少 Whisper 输出污染

### 6.3 维护性收益

- **代码解耦**：3 个 Worker 职责清晰，易于单独测试
- **易于扩展**：新增阶段只需增加 Worker 和队列
- **调试友好**：ProcessingContext 包含完整上下文，易于排查问题

---

## 7. 参考资料

### 7.1 相关文档

- `llmdoc/architecture/whisper-migration.md` - Whisper 迁移架构
- `llmdoc/architecture/sensevoice-presets.md` - SenseVoice 预设系统
- `llmdoc/architecture/sse-events.md` - SSE 事件系统
- `backend/app/services/text_normalizer.py` - 文本清洗器（已集成下划线清理）
- `backend/app/services/streaming_subtitle.py` - 流式字幕管理器（已支持 Chunk 级别推送）

### 7.2 关键修复记录

- **Whisper 幻觉修复**（2025-12-13）：
  - 增强 `TextNormalizer.clean()` 移除下划线
  - 修改 `get_context_window()` 使用 `text_clean`
  - 添加 `condition_on_previous_text=False`
  - 添加幻觉检测逻辑（下划线占比、prompt 重复）

### 7.3 技术参考

- **ONNX Runtime SessionOptions**：https://onnxruntime.ai/docs/api/python/api_summary.html#sessionoptions
- **asyncio.Queue 背压**：https://docs.python.org/3/library/asyncio-queue.html
- **流水线模式**：https://refactoring.guru/design-patterns/pipeline

---

## 8. 总结

V3.1.0 重构方案是在现有 V3.0 架构基础上的渐进式优化，核心改动集中在：

1. **架构升级**：串行执行 → 三级流水线（错位并行）
2. **资源管理**：增加 CPU 限制和队列背压
3. **质量提升**：集成幻觉防御和异常处理

**关键成功因素**：
- Phase 1 的 CPU 限制是防止卡顿的核心
- Phase 4 的详细测试是确保稳定性的关键
- 保留 V3.0 作为降级方案，确保风险可控

**预期时间**：6.5 天（1+2+1+2+0.5）

**预期收益**：性能提升 30-50%，稳定性显著改善，代码可维护性提升

---

**文档版本**：V3.1.0
**创建日期**：2025-12-13
**作者**：Claude Code
**基于**：双流重构草稿 V3.1.0 + 现有 V3.0 架构分析
