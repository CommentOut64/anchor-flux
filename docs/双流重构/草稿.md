# 双流重构方案：三段式异步流水线与防卡顿配置 (V3.1.0)

## 1. 核心目标

1. **解耦与清理**：将 `DualAlignmentPipeline` 中混杂的逻辑拆分为三个独立的 Worker，消除“回调地狱”和状态混乱。
2. **物理并行**：实现 SenseVoice（CPU 快流）与 Whisper（GPU 慢流）的错位并行执行，最大化吞吐量。
3. **防卡顿与 OOM**：通过队列背压（Backpressure）和 CPU 亲和性设置，防止内存溢出和系统卡死。
4. **体验保障**：确保“快流”草稿秒级上屏，不受“慢流”阻塞。

------

## 2. 架构设计：三级流水线 (The Three-Stage Pipeline)

采用 **生产者-消费者** 模型，数据包（Context）在三个 Worker 之间单向流动。

### 2.1 数据流拓扑

```
graph LR
    AudioChunk --> [FastWorker\n(CPU: VAD+SenseVoice)] 
    --> |Queue Inter (Max=5)| [SlowWorker\n(GPU: Whisper)]
    --> |Queue Final (Max=5)| [AlignmentWorker\n(CPU: Align+File)]
```

### 2.2 核心组件定义

#### A. 统一上下文 (ProcessingContext)

这是唯一在管道中流动的对象，替代散乱的参数传递。

```Python
# backend/app/schemas/pipeline_context.py
from dataclasses import dataclass, field
from typing import Optional, List, Any

@dataclass
class ProcessingContext:
    # 基础信息
    job_id: str
    chunk_index: int
    audio_chunk: Any  # AudioChunk 对象
    
    # 阶段产物
    sv_result: Optional[dict] = None      # FastWorker 产出
    whisper_result: Optional[dict] = None # SlowWorker 产出
    final_sentences: List[Any] = None     # AlignmentWorker 产出
    
    # 控制信号
    is_end: bool = False                  # 结束流标记
    error: Optional[Exception] = None     # 异常携带
```

#### B. 三大 Worker (无状态执行者)

1. **FastWorker (CPU)**
   - **输入**：`AudioChunk`
   - **职责**：
     1. 执行 SenseVoice 推理 (ONNX)。
     2. **立即**调用 `sse_manager` 推送草稿（保证用户体验）。
     3. 提取 Prompt 关键信息（如末尾文本）。
   - **输出**：填充 `sv_result` 的 Context。
2. **SlowWorker (GPU)**
   - **输入**：含 SV 结果的 Context。
   - **职责**：
     1. 基于 SV 结果构建 Whisper Prompt。
     2. 执行 Whisper 推理 (CUDA)。
   - **输出**：填充 `whisper_result` 的 Context。
3. **AlignmentWorker (CPU)**
   - **输入**：含双流结果的 Context。
   - **职责**：
     1. 执行双流对齐与降级仲裁。
     2. 调用 `sse_manager` 推送定稿。
     3. 写入 SRT 文件（追加模式）。
   - **输出**：完成状态 / 错误日志。

------

## 3. 防卡顿与稳定性配置 (关键)

为了防止 CPU 满载导致 GPU 调度阻塞或系统卡顿，必须实施以下配置。

### 3.1 队列背压 (Backpressure)

在 Pipeline 初始化时限制队列长度。如果 GPU 处理不过来，队列满载后 CPU 会自动暂停，防止内存爆炸。

- `queue_inter = asyncio.Queue(maxsize=5)`
- `queue_final = asyncio.Queue(maxsize=5)`

### 3.2 CPU 亲和性限制 (SenseVoice)

原理：ONNX Runtime 默认会吃掉所有 CPU 核心，导致 Whisper 的 CUDA 调度线程无核可用。

修改位置：backend/app/services/sensevoice_onnx_service.py



```Python
import multiprocessing
import onnxruntime as ort

def load_model(self):
    # 保留 2 个核心给操作系统和 Whisper 调度
    total_cores = multiprocessing.cpu_count()
    intra_op_threads = max(1, total_cores - 2)

    sess_options = ort.SessionOptions()
    # 限制算子内部并行度 (最关键的参数)
    sess_options.intra_op_num_threads = intra_op_threads 
    # 限制算子间并行度 (通常设为 1 即可)
    sess_options.inter_op_num_threads = 1
    
    # 强制使用 CPU Provider
    self.model = ort.InferenceSession(..., sess_options, providers=['CPUExecutionProvider'])
```

------

## 4. 详细代码实现规范

### 4.1 Pipeline 控制器

该类负责编排生命周期，并处理异常传播。



```Python
# backend/app/pipelines/async_dual_pipeline.py

class AsyncDualPipeline:
    def __init__(self, config, sse_manager):
        self.queue_inter = asyncio.Queue(maxsize=5)
        self.queue_final = asyncio.Queue(maxsize=5)
        
        # 实例化 Workers (逻辑封装在各自类中)
        self.fast_worker = FastWorker(config, sse_manager)
        self.slow_worker = SlowWorker(config)
        self.align_worker = AlignmentWorker(config, sse_manager)
        
        self.errors = [] # 收集运行时错误

    async def run(self, job_id: str, audio_chunks: list):
        # 启动三个并行任务
        t_fast = asyncio.create_task(self._fast_loop(job_id, audio_chunks))
        t_slow = asyncio.create_task(self._slow_loop())
        t_align = asyncio.create_task(self._align_loop())
        
        # 等待所有任务结束
        # return_exceptions=True 确保一个挂了不会立刻抛出，允许我们处理善后
        results = await asyncio.gather(t_fast, t_slow, t_align, return_exceptions=True)
        
        # 检查是否有异常
        for res in results:
            if isinstance(res, Exception):
                raise res # 抛出给 JobQueueService 处理
        
        if self.errors:
            raise self.errors[0]

    async def _fast_loop(self, job_id, chunks):
        try:
            for i, chunk in enumerate(chunks):
                ctx = ProcessingContext(job_id, i, chunk)
                # 业务逻辑：推理 + 推送草稿
                # 使用 await 释放事件循环，让 SSE 即使在 CPU 密集时也能发送
                await self.fast_worker.process(ctx) 
                await self.queue_inter.put(ctx)
            
            # 发送结束信号
            await self.queue_inter.put(ProcessingContext(..., is_end=True))
        except Exception as e:
            self.errors.append(e)
            # 发生错误也要发送结束信号，防止下游死锁
            await self.queue_inter.put(ProcessingContext(..., is_end=True, error=e))

    async def _slow_loop(self):
        try:
            while True:
                ctx = await self.queue_inter.get()
                if ctx.is_end or ctx.error:
                    await self.queue_final.put(ctx) # 透传结束/错误信号
                    break
                
                # 业务逻辑：Prompt + Whisper 推理
                await self.slow_worker.process(ctx)
                await self.queue_final.put(ctx)
        except Exception as e:
            self.errors.append(e)
            await self.queue_final.put(ProcessingContext(..., is_end=True, error=e))

    async def _align_loop(self):
        try:
            while True:
                ctx = await self.queue_final.get()
                if ctx.is_end:
                    if ctx.error: raise ctx.error #如果在上游发现错误，这里终止
                    break
                
                # 业务逻辑：对齐 + 推送定稿 + 写文件
                await self.align_worker.process(ctx)
        except Exception as e:
            self.errors.append(e)
            # 对齐层是最后一层，不需要再 put 队列，直接记录错误
```

### 4.2 异常处理与状态同步策略

针对你提出的“实现细节风险”，采用以下策略：

1. **SSE 状态一致性**：
   - `FastWorker` 在调用 `sse_manager.add_draft` 时，直接使用 `ctx.chunk_index`。因为 Context 是随数据流动的，序号永远不会错乱。
2. **JobQueueService 异常感知**：
   - Pipeline 的 `run` 方法使用了 `asyncio.gather` 并检查结果。如果任何一个 Worker 内部抛出异常（如显存不足、文件写入失败），异常会被 `run` 方法重新 raise。
   - `JobQueueService` 的 `try...except` 块会捕获这个异常，执行标准的 `_handle_job_error` 流程（更新数据库状态为 FAILED，通知前端）。
3. **文件写入并发安全**：
   - 虽然 `AlignmentWorker` 是串行处理 `queue_final` 的（一次取一个），因此写 SRT 文件本身是**线程安全**的，不需要加锁。

------

## 5. 分阶段实施计划

为了最低风险地完成迁移，建议按以下步骤执行：

### Phase 1: 基础设施搭建 (1天)

1. 创建 `pipeline_context.py` 定义数据类。
2. 创建 `sensevoice_onnx_service.py` 的新分支，**修改 `load_model` 增加 CPU 线程限制**（这是防卡顿的前提）。
3. 验证：运行单 SenseVoice 任务，观察任务管理器 CPU 占用是否留有空余。

### Phase 2: 逻辑拆分 (2天)

**只搬运代码，不改逻辑。**

1. 创建 `backend/app/pipelines/workers/` 目录。
2. **FastWorker**: 从 `DualAlignmentPipeline` 复制 `_run_sensevoice` 和草稿推送逻辑。
3. **SlowWorker**: 复制 `_run_whisper` 逻辑。
4. **AlignmentWorker**: 复制 `_align_and_fallback` 和文件写入逻辑。
5. **验证**：编写单元测试，模拟传入 Context，确保 Worker 能正确输出结果。

### Phase 3: 流水线组装 (1天)

1. 编写 `AsyncDualPipeline` 类（参考 4.1 代码）。

2. 在 `job_queue_service.py` 中，保留旧调用代码的注释，切换为新 Pipeline 的调用。

   

   ```Python
   # old: await self.dual_pipeline.run(...)
   # new: await self.async_dual_pipeline.run(...)
   ```

### Phase 4: 集成测试 (2天)

1. **功能测试**：跑一个短视频，确认 SRT 内容与旧版一致。
2. **压力测试**：
   - 监控显存：确保 SenseVoice 没跑去 GPU。
   - 监控内存：确保长视频不会导致内存直线上升（验证背压 `maxsize` 是否生效）。
   - 断网/中断测试：在任务中间手动停止，验证 `JobQueueService` 是否能正确捕获错误状态。

### Phase 5: 清理 (0.5天)

1. 删除旧的 `DualAlignmentPipeline` 类及其辅助函数。
2. 清理 `transcription_service.py` 中不再被引用的代码。

------

## 6. 总结

这套方案是目前性价比最高的选择。它通过**物理资源隔离（CPU/GPU）和逻辑解耦（三级流水线）**，在不引入重型框架的前提下解决了代码混乱和并发效率问题。严格按照 Phase 1 的 CPU 配置和 Phase 3 的队列限制执行，可以彻底规避卡顿风险。