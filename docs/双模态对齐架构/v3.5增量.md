# Video-to-SRT V3.5 架构新增项清单

## 1. 字符级归一化对齐算法（Character-Level Normalization）

**问题背景**：中英混合场景下，Whisper输出"Hello世界"，SenseVoice输出"hello 世界"，词级对齐会失败。

 

**V3.5方案**：



- 统一归一化到**字符级别**进行对齐

- 归一化规则：

  ```python
  def normalize_for_alignment(text):
      # 1. 转小写
      text = text.lower()
      # 2. 移除所有空格和标点
      text = re.sub(r'[\s\p{P}]+', '', text)
      # 3. 统一Unicode规范化（NFC）
      text = unicodedata.normalize('NFC', text)
      return text
  ```

- 对齐完成后，使用**Whisper原始文本**（保留大小写、标点）作为最终输出

- SenseVoice仅提供时间戳锚点

**实现位置**：`backend/app/services/alignment/alignment_service.py`



------

## 2. 显存分层策略（Memory Tiering Strategy）

**问题背景**：不同显存容量的GPU需要不同的资源调度策略。

 

**V3.5方案**：三档配置策略



| 显存档位           | Demucs策略   | SenseVoice设备       | Whisper模型    | 并发策略 |
| ------------------ | ------------ | -------------------- | -------------- | -------- |
| **High (>8GB)**    | 整轨GPU分离  | CPU (force_cpu=True) | Large-v3 (GPU) | 串行     |
| **Medium (4-8GB)** | 5分钟分块GPU | CPU (force_cpu=True) | Medium (GPU)   | 串行     |
| **Low (<4GB)**     | 跳过或CPU    | CPU                  | Small (GPU)    | 串行     |

**关键参数**：



```python
# SenseVoice强制CPU推理，释放GPU给Whisper
sensevoice_config = {
    "device": "cpu",
    "force_cpu": True,  # 新增参数
    "num_threads": 4
}
```

**实现位置**：`backend/app/core/resource_manager.py`



------

## 3. 矩阵式预设系统（Matrix Presets）

**问题背景**：原3预设方案（Fast/Standard/Pro）灵活性不足。

 

**V3.5方案**：基础层 + 增强层的矩阵组合



### 基础层（Base Layer）

- **Fast**：SenseVoice Only（无Whisper）
- **Pro**：SenseVoice (CPU) + Whisper Large-v3 (GPU)

### 增强层（Enhancement Layer）

- **LLM Proofread**：启用LLM语义校对
- **LLM Translate**：启用LLM翻译

### 组合示例

```python
presets = {
    "fast": {"base": "fast", "enhancements": []},
    "pro": {"base": "pro", "enhancements": []},
    "pro_proof": {"base": "pro", "enhancements": ["llm_proofread"]},
    "pro_trans": {"base": "pro", "enhancements": ["llm_translate"]},
    "pro_full": {"base": "pro", "enhancements": ["llm_proofread", "llm_translate"]}
}
```

**实现位置**：`backend/app/pipelines/presets.py`



------

## 4. Whisper时间戳回退机制（Whisper Timestamps Fallback）

**问题背景**：Whisper的word_timestamps会显著降低推理速度。

 

**V3.5方案**：



- **默认关闭** `word_timestamps=False`
- 仅在对齐失败时启用作为回退方案
- 触发条件：对齐成功率 < 30%

```python
# 第一次尝试：不启用word_timestamps
whisper_result = whisper.transcribe(audio, word_timestamps=False)
alignment_rate = aligner.align(whisper_result.text, sv_tokens)

if alignment_rate < 0.3:
    # 回退：启用word_timestamps
    whisper_result = whisper.transcribe(audio, word_timestamps=True)
    # 直接使用Whisper的时间戳，放弃SenseVoice
    return whisper_result.words
```

**实现位置**：`backend/app/pipelines/dual_alignment_pipeline.py`



------

## 5. 分层质量阈值（Tiered Quality Thresholds）

**问题背景**：需要明确的质量评估标准和用户反馈机制。

 

**V3.5方案**：三档阈值



| 对齐成功率 | 状态    | 前端表现            | 后端行为              |
| ---------- | ------- | ------------------- | --------------------- |
| **>70%**   | Success | 正常黑色文本        | 正常推送              |
| **30-70%** | Warning | 黄色高亮 + 警告图标 | 推送 + 警告标记       |
| **<30%**   | Fail    | 灰色删除线          | 触发Whisper时间戳回退 |

**SSE事件扩展**：



```python
payload = {
    "target_temp_id": chunk_id,
    "text": final_text,
    "words": aligned_words,
    "quality": {
        "alignment_rate": 0.65,  # 对齐成功率
        "status": "warning",      # success/warning/fail
        "message": "部分词语对齐失败，建议人工检查"
    }
}
```

**实现位置**：`backend/app/services/alignment/alignment_service.py`



------

## 6. MVP路线图调整（Skip Linear Interpolation）

**问题背景**：原方案中的线性插值（Gap填补）算法复杂度高，且效果有限。

 

**V3.5方案**：



- **跳过线性插值**，直接实现Needleman-Wunsch对齐算法
- 对于无法对齐的词，直接标记为"低置信度"，由前端黄色高亮提示
- 降低MVP实现复杂度，加快上线速度

**调整后的实施路线**：



1. Phase 1：实现Needleman-Wunsch核心算法（无插值）
2. Phase 2：集成静音区硬约束
3. Phase 3：前端质量反馈UI
4. Phase 4（可选）：后续迭代时再考虑高级插值算法

------

## 7. Demucs策略修正（Chunk-Level On-Demand）

**问题背景**：原方案提出"整轨分离"，但实测发现长视频（>1小时）会导致内存溢出。

 

**V3.5方案**：



- **保持现有的分块按需分离策略**
- 优化点：将分块大小从30秒调整为**5分钟**
- 原因：
  - 减少Demucs模型加载次数（从120次降至12次）
  - 保留足够上下文，提升分离质量
  - 避免长视频OOM风险

```python
# 调整后的分块策略
chunk_size = 300  # 5分钟 = 300秒
demucs_chunks = split_audio_by_duration(audio, chunk_size)
```

**实现位置**：`backend/app/services/audio/chunk_engine.py`



------

## 8. Prompt工程修正（Context Buffer Correction）

**问题背景**：原方案错误地使用SenseVoice草稿作为上下文。

 

**V3.5修正**：



- **主提示**：使用**上一句Whisper精修文本**（不是SenseVoice草稿）
- **辅提示**：从SenseVoice草稿中**提取关键词**（NER），不是整句

```python
# 在DualAlignmentPipeline中维护上下文缓冲区
self.previous_whisper_text = ""

# 每次Whisper推理时
prompt = f"{self.previous_whisper_text} Glossary: {', '.join(keywords)}"
whisper_result = whisper.transcribe(audio, initial_prompt=prompt)

# 更新缓冲区（用Whisper结果，不是SenseVoice）
self.previous_whisper_text = whisper_result.text[-200:]  # 保留最后200字符
```

**实现位置**：`backend/app/pipelines/dual_alignment_pipeline.py`



------

## 9. NER关键词提取（Keyword Extraction Only）

**问题背景**：原方案将SenseVoice整句作为Prompt，会导致Whisper"抄作业"。

 

**V3.5方案**：



- 仅从SenseVoice草稿中提取**人名、地名、专有名词**

- 使用简单规则：

  ```python
  def extract_keywords(sv_text):
      # 1. 提取连续大写字母（英文专有名词）
      keywords = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', sv_text)
      # 2. 提取中文人名（简单规则：姓氏+1-2字）
      keywords += re.findall(r'[赵钱孙李周吴郑王...][一-龥]{1,2}', sv_text)
      return list(set(keywords))
  ```

- 将关键词拼接到Prompt的Glossary部分

**实现位置**：`backend/app/services/inference/sensevoice_executor.py`



------

## 10. 静音区硬约束预处理（Silence Constraints Preprocessing）

**问题背景**：SenseVoice时间戳可能溢出到VAD确定的静音区。

 

**V3.5方案**：



- 在对齐算法**之前**，先对SenseVoice时间戳进行硬约束校正

- 规则：

  ```python
  def apply_silence_constraints(sv_tokens, silence_ranges):
      for token in sv_tokens:
          for silence_start, silence_end in silence_ranges:
              # 如果词的起始点在静音区，吸附到静音区边界
              if silence_start <= token['start'] <= silence_end:
                  token['start'] = silence_end
              # 如果词的结束点在静音区，吸附到静音区边界
              if silence_start <= token['end'] <= silence_end:
                  token['end'] = silence_startreturn sv_tokens
  ```

**实现位置**：`backend/app/services/alignment/alignment_service.py`



------

## 11. SSE事件扩展（Quality Feedback Events）

**新增事件字段**：



```python
# subtitle.overwrite事件扩展
{
    "target_temp_id": "chunk_5",
    "text": "Hello world",
    "words": [...],
    "quality": {
        "alignment_rate": 0.85,
        "status": "success",  # success/warning/fail
        "fallback_used": False,  # 是否使用了Whisper时间戳回退
        "message": null
    }
}
```

**实现位置**：`backend/app/services/streaming/sse_publisher.py`



------

## 12. 前端质量反馈UI（Quality Indicators）

**新增UI元素**：



- 对齐成功率 < 70%的字幕显示黄色背景
- 鼠标悬停显示质量详情tooltip
- 提供"重新处理"按钮（触发Whisper时间戳回退）

**实现位置**：`frontend/src/components/SubtitleEditor.vue`



------

## 总结：V3.5相对于V3.0的12项关键改进

1. **字符级归一化** - 解决中英混合对齐问题
2. **显存分层策略** - 适配不同硬件配置
3. **矩阵式预设** - 提升配置灵活性
4. **Whisper时间戳回退** - 性能与质量平衡
5. **分层质量阈值** - 明确质量标准
6. **跳过线性插值** - 降低MVP复杂度
7. **Demucs分块优化** - 避免长视频OOM
8. **Prompt工程修正** - 使用Whisper精修文本
9. **NER关键词提取** - 避免Whisper抄作业
10. **静音区硬约束** - 提升时间戳精度
11. **SSE质量反馈** - 增强用户感知
12. **前端质量UI** - 可视化质量指标

这些改进项都是**增量式**的，可以在V3.0基础架构上逐步集成，无需推倒重来。