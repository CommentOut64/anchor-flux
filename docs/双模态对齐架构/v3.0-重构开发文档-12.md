## 12. LLM校对与翻译接口设计

### 12.1 LLM服务接口

**文件**: `backend/app/services/llm/llm_service.py`

```python
from abc import ABC, abstractmethod
from typing import List, Optional
from app.models.confidence_models import AlignedSubtitle

class LLMProvider(ABC):
    """LLM 提供商抽象基类"""

    @abstractmethod
    async def proofread(
        self,
        subtitle: AlignedSubtitle,
        language: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """校对字幕"""
        pass

    @abstractmethod
    async def translate(
        self,
        subtitle: AlignedSubtitle,
        source_lang: str,
        target_lang: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """翻译字幕"""
        pass


class OpenAIProvider(LLMProvider):
    """OpenAI GPT 提供商"""

    def __init__(self, api_key: str, model: str = "gpt-4"):
        self.api_key = api_key
        self.model = model
        self.client = OpenAI(api_key=api_key)

    async def proofread(
        self,
        subtitle: AlignedSubtitle,
        language: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """校对字幕"""
        # 构建提示词
        prompt = self._build_proofread_prompt(subtitle, language, context)

        # 调用 LLM
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个专业的字幕校对专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )

        # 解析结果
        corrected_text = response.choices[0].message.content

        # 保留时间戳，仅更新文本
        corrected_subtitle = AlignedSubtitle(
            text=corrected_text,
            start=subtitle.start,
            end=subtitle.end,
            words=subtitle.words,  # 保留原始字级时间戳
            sensevoice_text=subtitle.sensevoice_text,
            whisper_text=subtitle.whisper_text
        )

        return corrected_subtitle

    def _build_proofread_prompt(
        self,
        subtitle: AlignedSubtitle,
        language: str,
        context: Optional[List[AlignedSubtitle]]
    ) -> str:
        """构建校对提示词"""
        prompt = f"""请校对以下{language}字幕，修正错别字、语法错误和标点符号。

原始文本（SenseVoice）: {subtitle.sensevoice_text}
对齐文本（Whisper）: {subtitle.whisper_text}
当前文本: {subtitle.text}

"""

        # 添加上下文
        if context:
            prompt += "上下文字幕:\n"
            for ctx in context[-3:]:  # 最近3条
                prompt += f"- {ctx.text}\n"

        prompt += """
要求:
1. 仅修正明显的错误，不要改变原意
2. 保持口语化风格
3. 直接返回修正后的文本，不要解释
"""

        return prompt

    async def translate(
        self,
        subtitle: AlignedSubtitle,
        source_lang: str,
        target_lang: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """翻译字幕"""
        prompt = self._build_translate_prompt(subtitle, source_lang, target_lang, context)

        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "你是一个专业的字幕翻译专家。"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5
        )

        translated_text = response.choices[0].message.content

        # 创建翻译后的字幕（保留时间戳）
        translated_subtitle = AlignedSubtitle(
            text=translated_text,
            start=subtitle.start,
            end=subtitle.end,
            words=[],  # 翻译后字级时间戳失效
            sensevoice_text=subtitle.sensevoice_text,
            whisper_text=subtitle.whisper_text
        )

        return translated_subtitle

    def _build_translate_prompt(
        self,
        subtitle: AlignedSubtitle,
        source_lang: str,
        target_lang: str,
        context: Optional[List[AlignedSubtitle]]
    ) -> str:
        """构建翻译提示词"""
        lang_map = {
            "zh": "中文",
            "en": "英文",
            "ja": "日文",
            "ko": "韩文"
        }

        prompt = f"""请将以下{lang_map.get(source_lang, source_lang)}字幕翻译成{lang_map.get(target_lang, target_lang)}。

原文: {subtitle.text}

"""

        if context:
            prompt += "上下文:\n"
            for ctx in context[-3:]:
                prompt += f"- {ctx.text}\n"

        prompt += """
要求:
1. 保持字幕的简洁性
2. 符合目标语言的表达习惯
3. 直接返回翻译结果，不要解释
"""

        return prompt


class ClaudeProvider(LLMProvider):
    """Anthropic Claude 提供商"""

    def __init__(self, api_key: str, model: str = "claude-3-sonnet-20240229"):
        self.api_key = api_key
        self.model = model
        self.client = Anthropic(api_key=api_key)

    async def proofread(self, subtitle, language, context=None):
        # 类似 OpenAI 实现
        pass

    async def translate(self, subtitle, source_lang, target_lang, context=None):
        # 类似 OpenAI 实现
        pass


class LLMService:
    """LLM 服务统一接口"""

    def __init__(self, provider: LLMProvider):
        self.provider = provider
        self.logger = logging.getLogger(__name__)

    async def proofread_subtitle(
        self,
        subtitle: AlignedSubtitle,
        language: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """校对字幕"""
        try:
            corrected = await self.provider.proofread(subtitle, language, context)
            self.logger.info(f"字幕校对完成: {subtitle.text} -> {corrected.text}")
            return corrected
        except Exception as e:
            self.logger.error(f"字幕校对失败: {e}")
            return subtitle  # 失败时返回原字幕

    async def translate_subtitle(
        self,
        subtitle: AlignedSubtitle,
        source_lang: str,
        target_lang: str,
        context: Optional[List[AlignedSubtitle]] = None
    ) -> AlignedSubtitle:
        """翻译字幕"""
        try:
            translated = await self.provider.translate(
                subtitle, source_lang, target_lang, context
            )
            self.logger.info(f"字幕翻译完成: {subtitle.text} -> {translated.text}")
            return translated
        except Exception as e:
            self.logger.error(f"字幕翻译失败: {e}")
            return subtitle
```

### 12.2 LLM集成到流水线

**文件**: `backend/app/pipelines/dual_alignment_pipeline.py`

```python
class DualAlignmentPipeline:
    def __init__(
        self,
        sv_executor: SenseVoiceExecutor,
        whisper_executor: WhisperExecutor,
        aligner: AlignmentService,
        sse_publisher: SSEPublisher,
        llm_service: Optional[LLMService] = None  # 可选的 LLM 服务
    ):
        self.sv_executor = sv_executor
        self.whisper_executor = whisper_executor
        self.aligner = aligner
        self.sse_publisher = sse_publisher
        self.llm_service = llm_service
        self.logger = logging.getLogger(__name__)

    async def run(
        self,
        job_id: str,
        chunks: List[AudioChunk],
        config: JobConfig
    ):
        context_subtitles = []  # 保存上下文

        for i, chunk in enumerate(chunks):
            chunk_id = f"{job_id}_chunk_{i}"

            # 1. SenseVoice 推理
            sv_result = await self.sv_executor.transcribe(...)

            # 2. 推送草稿
            await self.sse_publisher.publish_draft(...)

            # 3. Whisper 推理
            whisper_result = await self.whisper_executor.transcribe(...)

            # 4. 对齐
            final_subtitle = await self.aligner.align(...)

            # 5. 可选: LLM 校对
            if config.enable_llm_proofread and self.llm_service:
                final_subtitle = await self.llm_service.proofread_subtitle(
                    subtitle=final_subtitle,
                    language=config.language,
                    context=context_subtitles  # 传递上下文
                )

                # 推送 LLM 校对事件
                await self.sse_publisher.publish_signal(
                    job_id=job_id,
                    signal_type="llm_proofread",
                    data={"chunk_id": chunk_id}
                )

            # 6. 可选: LLM 翻译
            if config.enable_llm_translate and self.llm_service:
                translated_subtitle = await self.llm_service.translate_subtitle(
                    subtitle=final_subtitle,
                    source_lang=config.language,
                    target_lang=config.target_language,
                    context=context_subtitles
                )

                # 推送翻译事件
                await self.sse_publisher.publish_signal(
                    job_id=job_id,
                    signal_type="llm_translate",
                    data={
                        "chunk_id": chunk_id,
                        "translated_text": translated_subtitle.text
                    }
                )

            # 7. 推送定稿
            await self.sse_publisher.publish_overwrite(...)

            # 8. 保存到上下文
            context_subtitles.append(final_subtitle)
            if len(context_subtitles) > 5:  # 只保留最近5条
                context_subtitles.pop(0)
```

### 12.3 LLM配置

**文件**: `backend/app/core/config.py`

```python
class Settings(BaseSettings):
    # LLM 配置
    LLM_PROVIDER: str = "openai"  # openai/claude/local
    LLM_API_KEY: Optional[str] = None
    LLM_MODEL: str = "gpt-4"
    LLM_ENABLE_PROOFREAD: bool = False
    LLM_ENABLE_TRANSLATE: bool = False
    LLM_MAX_CONTEXT: int = 5  # 最多使用多少条上下文
```

### 12.4 前端LLM功能开关

**文件**: `frontend/src/components/editor/LLMSettings.vue`

```vue
<template>
  <div class="llm-settings">
    <h3>LLM 增强功能</h3>

    <div class="setting-item">
      <label>
        <input type="checkbox" v-model="settings.enableProofread" />
        启用 LLM 校对
      </label>
      <p class="description">使用 AI 修正错别字和语法错误</p>
    </div>

    <div class="setting-item">
      <label>
        <input type="checkbox" v-model="settings.enableTranslate" />
        启用 LLM 翻译
      </label>
      <p class="description">自动翻译字幕到目标语言</p>
    </div>

    <div v-if="settings.enableTranslate" class="setting-item">
      <label>目标语言:</label>
      <select v-model="settings.targetLanguage">
        <option value="zh">中文</option>
        <option value="en">英文</option>
        <option value="ja">日文</option>
        <option value="ko">韩文</option>
      </select>
    </div>

    <div class="setting-item">
      <label>LLM 提供商:</label>
      <select v-model="settings.provider">
        <option value="openai">OpenAI GPT-4</option>
        <option value="claude">Anthropic Claude</option>
        <option value="local">本地模型</option>
      </select>
    </div>

    <div v-if="settings.provider !== 'local'" class="setting-item">
      <label>API Key:</label>
      <input
        type="password"
        v-model="settings.apiKey"
        placeholder="输入 API Key"
      />
    </div>
  </div>
</template>

<script setup>
import { reactive } from 'vue'

const settings = reactive({
  enableProofread: false,
  enableTranslate: false,
  targetLanguage: 'zh',
  provider: 'openai',
  apiKey: ''
})

defineExpose({ settings })
</script>
```